/local1/borito1907/anaconda3/envs/watermark/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
CUDA extension not installed.
CUDA extension not installed.
[nltk_data] Downloading package punkt to /home/borito1907/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
/local1/borito1907/anaconda3/envs/watermark/lib/python3.10/runpy.py:126: RuntimeWarning: 'mutators.sentence' found in sys.modules after import of package 'mutators', but prior to execution of 'mutators.sentence'; this may result in unpredictable behaviour
  warn(RuntimeWarning(msg))
CUDA_VISIBLE_DEVICES: 1,2
WORLD_SIZE: 2
{'type': 'sentence', 'use_system_profile': True, 'system_profile': 'You are a copy editor tasked to enforce text quality.', 'num_retries': 5, 'model_name_or_path': 'TheBloke/Mixtral-8x7B-Instruct-v0.1-GPTQ', 'model_cache_dir': '${model_cache_dir}', 'revision': 'main', 'device_map': '${generator_args.device_map}', 'trust_remote_code': '${generator_args.trust_remote_code}', 'max_new_tokens': '${generator_args.max_new_tokens}', 'do_sample': '${generator_args.do_sample}', 'temperature': '${generator_args.temperature}', 'top_p': '${generator_args.top_p}', 'top_k': '${generator_args.top_k}', 'repetition_penalty': '${generator_args.repetition_penalty}', 'use_pydantic_parser': True}
[2024-05-28 12:10:57,943][__main__][INFO] - Type of pipeline was: <class 'NoneType'>
[2024-05-28 12:10:57,943][__main__][INFO] - Initializing a new Text Mutator pipeline from cfg...
[2024-05-28 12:10:57,943][model_builders.pipeline][INFO] - Initializing TheBloke/Mixtral-8x7B-Instruct-v0.1-GPTQ
/local1/borito1907/anaconda3/envs/watermark/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/local1/borito1907/anaconda3/envs/watermark/lib/python3.10/site-packages/transformers/modeling_utils.py:4371: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead
  warnings.warn(
[2024-05-28 12:10:59,781][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2024-05-28 12:11:09,929][__main__][INFO] - Sentence to rephrase: The One Ring represents the ultimate form of power, as it allows its possessor to dominate and rule over the entire world.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
