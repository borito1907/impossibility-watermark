/local1/borito1907/anaconda3/envs/watermark/lib/python3.12/site-packages/transformers/utils/hub.py:122: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
[nltk_data] Downloading package punkt to /home/borito1907/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[2024-05-23 12:05:08,679][__main__][INFO] - Starting to watermark...
[2024-05-23 12:05:08,682][__main__][INFO] - Prompt: Write a 250 word essay on the role of power and its impact on characters in the Lord of the Rings series. How does the ring symbolize power, and what does Tolkien suggest about the nature of power? Only respond with the essay.
[2024-05-23 12:05:08,682][__main__][INFO] - Getting the watermarker...
[2024-05-23 12:05:08,682][watermarker][INFO] - Using device: cuda
[2024-05-23 12:05:08,682][root][INFO] - Device: auto
[2024-05-23 12:05:08,682][model_builders.pipeline][INFO] - Initializing facebook/opt-1.3b
[2024-05-23 12:05:09,119][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2024-05-23 12:05:10,801][semstamp][INFO] - {'max_new_tokens': 1024, 'do_sample': True, 'temperature': 1.0, 'top_p': 0.95, 'top_k': 40, 'repetition_penalty': 1.1, 'bad_words_ids': [[50118]], 'min_new_tokens': 245}
[2024-05-23 12:05:10,801][semstamp][INFO] - Initializing embedder model.
[2024-05-23 12:05:10,801][sentence_transformers.SentenceTransformer][INFO] - Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v1
[2024-05-23 12:05:11,640][sentence_transformers.SentenceTransformer][INFO] - Use pytorch device_name: cuda
[2024-05-23 12:05:11,673][semstamp][INFO] - Finished initializing embedder model.
initializing random projection LSH model
loading SBERT base model...
[2024-05-23 12:05:11,675][__main__][INFO] - Got the watermarker. Generating watermarked text...
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s]
[2024-05-23 12:05:12,670][semstamp][INFO] - Candidate text:  Your prompt is:  > Tolkien portrays all characters well – though there are minor differences – but there are several ‘bad guys’ who, in the movies and books, were created as villains and then turned into heroes.
[2024-05-23 12:05:12,671][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 154.57it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 167.51it/s]
[2024-05-23 12:05:12,689][semstamp][INFO] - LSH Candidate: 5
[2024-05-23 12:05:12,689][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:12,854][semstamp][INFO] - Candidate text:  This can be as short or as long as you like!
[2024-05-23 12:05:12,854][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 132.87it/s]
[2024-05-23 12:05:13,157][semstamp][INFO] - Candidate text:  For bonus points, include your own favorite version of this essay and have your friend read it to you aloud.
[2024-05-23 12:05:13,157][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 160.80it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.29it/s]
[2024-05-23 12:05:13,172][semstamp][INFO] - LSH Candidate: 5
[2024-05-23 12:05:13,173][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:13,449][semstamp][INFO] - Candidate text:  Your essay should focus on a single character from each book whose behavior changes at different points throughout the books.
[2024-05-23 12:05:13,449][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.33it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.73it/s]
[2024-05-23 12:05:13,464][semstamp][INFO] - LSH Candidate: 7
[2024-05-23 12:05:13,464][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:13,777][semstamp][INFO] - Candidate text:  The focus will be on Lord Elvish, and how we as a society perceive the importance of power.  
[2024-05-23 12:05:13,777][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.06it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.33it/s]
[2024-05-23 12:05:13,792][semstamp][INFO] - LSH Candidate: 5
[2024-05-23 12:05:13,792][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:14,070][semstamp][INFO] - Candidate text:  You can do this either within two days and you'll have an idea what you're talking about already.
[2024-05-23 12:05:14,070][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.59it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.75it/s]
[2024-05-23 12:05:14,085][semstamp][INFO] - LSH Candidate: 5
[2024-05-23 12:05:14,085][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:14,374][semstamp][INFO] - Candidate text:  The best thing you could do is to try to pick a topic where they would have been mentioned or important.
[2024-05-23 12:05:14,374][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 169.00it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.67it/s]
[2024-05-23 12:05:14,389][semstamp][INFO] - LSH Candidate: 5
[2024-05-23 12:05:14,389][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:14,690][semstamp][INFO] - Candidate text:  Also, if you have an opinion about Harry Potter (either good or bad) please post it here as well!
[2024-05-23 12:05:14,691][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.38it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.85it/s]
[2024-05-23 12:05:14,706][semstamp][INFO] - LSH Candidate: 7
[2024-05-23 12:05:14,706][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:14,897][semstamp][INFO] - Candidate text:  Your grade will be based on how well written and organized it is!
[2024-05-23 12:05:14,897][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 165.61it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.19it/s]
[2024-05-23 12:05:14,912][semstamp][INFO] - LSH Candidate: 5
[2024-05-23 12:05:14,912][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:15,101][semstamp][INFO] - Candidate text:   The only character that doesn't have a POV is Frodo.
[2024-05-23 12:05:15,102][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.58it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.17it/s]
[2024-05-23 12:05:15,116][semstamp][INFO] - LSH Candidate: 1
[2024-05-23 12:05:15,117][semstamp][INFO] - Candidate text falls within the semantic partition.
[2024-05-23 12:05:15,361][semstamp][INFO] - Candidate text:  You can do this with each chapter, or for every character within any scene.  
[2024-05-23 12:05:15,361][semstamp][INFO] - Accept Mask: tensor([6, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.53it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.12it/s]
[2024-05-23 12:05:15,376][semstamp][INFO] - LSH Candidate: 5
[2024-05-23 12:05:15,376][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:16,023][semstamp][INFO] - Candidate text:  And Sam's point of view isn't even all that great, I find I always look back when it says "Sam" as more of his voice and less of Frodo's, like how I tend to write Sam much more than Frodo.
[2024-05-23 12:05:16,023][semstamp][INFO] - Accept Mask: tensor([6, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 138.02it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 147.37it/s]
[2024-05-23 12:05:16,040][semstamp][INFO] - LSH Candidate: 7
[2024-05-23 12:05:16,041][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:16,346][semstamp][INFO] - Candidate text:  I think you can say something about how his actions are ultimately responsible for Bilbo's journey to find the Ring.
[2024-05-23 12:05:16,346][semstamp][INFO] - Accept Mask: tensor([6, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 169.53it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.66it/s]
[2024-05-23 12:05:16,361][semstamp][INFO] - LSH Candidate: 5
[2024-05-23 12:05:16,361][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:16,953][semstamp][INFO] - Candidate text:   Other than that you could write about why Peter Jackson chose to portray this story the way he did and analyze the motivations behind the scenes decisions made by him, I'm sure there are lots of articles in the internet about it.
[2024-05-23 12:05:16,953][semstamp][INFO] - Accept Mask: tensor([6, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 101.42it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 149.25it/s]
[2024-05-23 12:05:16,973][semstamp][INFO] - LSH Candidate: 7
[2024-05-23 12:05:16,973][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:17,392][semstamp][INFO] - Candidate text:  His story ends with him getting killed by Saruman (who I'm told was an extremely evil person, but I've never read anything to indicate this). 
[2024-05-23 12:05:17,392][semstamp][INFO] - Accept Mask: tensor([6, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 166.51it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.44it/s]
[2024-05-23 12:05:17,407][semstamp][INFO] - LSH Candidate: 7
[2024-05-23 12:05:17,407][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:17,787][semstamp][INFO] - Candidate text:   And even then most are more "voice based", meaning they don't get to hear his thoughts and they only know bits and pieces. 
[2024-05-23 12:05:17,787][semstamp][INFO] - Accept Mask: tensor([6, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 167.99it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.12it/s]
[2024-05-23 12:05:17,802][semstamp][INFO] - LSH Candidate: 0
[2024-05-23 12:05:17,802][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:18,082][semstamp][INFO] - Candidate text:  You choose one to write it for and make an outline first, then go crazy with that concept. 
[2024-05-23 12:05:18,083][semstamp][INFO] - Accept Mask: tensor([6, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.03it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.65it/s]
[2024-05-23 12:05:18,098][semstamp][INFO] - LSH Candidate: 7
[2024-05-23 12:05:18,098][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:18,306][semstamp][INFO] - Candidate text:  (He narrates all of LOTR when he's at home.) 
[2024-05-23 12:05:18,306][semstamp][INFO] - Accept Mask: tensor([6, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.26it/s]
[2024-05-23 12:05:18,458][semstamp][INFO] - Candidate text:  Everything else is all 3rd person POV. 
[2024-05-23 12:05:18,458][semstamp][INFO] - Accept Mask: tensor([6, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 164.64it/s]
[2024-05-23 12:05:18,647][semstamp][INFO] - Candidate text:  I don't think we'll be seeing him this season. 
[2024-05-23 12:05:18,647][semstamp][INFO] - Accept Mask: tensor([6, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.78it/s]
[2024-05-23 12:05:19,010][semstamp][INFO] - Candidate text:  I'm so bored with the topic, but it's one I enjoy writing because it challenges me to think about characters in different ways.
[2024-05-23 12:05:19,010][semstamp][INFO] - Accept Mask: tensor([6, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.66it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.90it/s]
[2024-05-23 12:05:19,025][semstamp][INFO] - LSH Candidate: 5
[2024-05-23 12:05:19,025][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:19,214][semstamp][INFO] - Candidate text:  How do you think he's supposed to make his opinion known?
[2024-05-23 12:05:19,214][semstamp][INFO] - Accept Mask: tensor([6, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.79it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.61it/s]
[2024-05-23 12:05:19,229][semstamp][INFO] - LSH Candidate: 4
[2024-05-23 12:05:19,229][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:19,510][semstamp][INFO] - Candidate text:   Other characters get POV later, but this is the way it will go for all his life. 
[2024-05-23 12:05:19,510][semstamp][INFO] - Accept Mask: tensor([6, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.13it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.35it/s]
[2024-05-23 12:05:19,525][semstamp][INFO] - LSH Candidate: 7
[2024-05-23 12:05:19,525][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:20,043][semstamp][INFO] - Candidate text:  (Not sure why he has to be POV, though…) Write about why Frodo’s role was as the Ringbearer could change or even save his life from time and time again!
[2024-05-23 12:05:20,043][semstamp][INFO] - Accept Mask: tensor([6, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.62it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.92it/s]
[2024-05-23 12:05:20,058][semstamp][INFO] - LSH Candidate: 3
[2024-05-23 12:05:20,058][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:20,169][semstamp][INFO] - Candidate text:  What would you do about this?
[2024-05-23 12:05:20,169][semstamp][INFO] - Accept Mask: tensor([6, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 167.91it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.08it/s]
[2024-05-23 12:05:20,184][semstamp][INFO] - LSH Candidate: 7
[2024-05-23 12:05:20,184][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:20,540][semstamp][INFO] - Candidate text:  Everyone else has multiple perspectives of life/events to fill, so I can see the argument for including them all in the paper. 
[2024-05-23 12:05:20,540][semstamp][INFO] - Accept Mask: tensor([6, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 169.45it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.14it/s]
[2024-05-23 12:05:20,555][semstamp][INFO] - LSH Candidate: 5
[2024-05-23 12:05:20,555][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:20,711][semstamp][INFO] - Candidate text:  Everyone else has one whether they wanted to or not.
[2024-05-23 12:05:20,712][semstamp][INFO] - Accept Mask: tensor([6, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.63it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.84it/s]
[2024-05-23 12:05:20,726][semstamp][INFO] - LSH Candidate: 4
[2024-05-23 12:05:20,727][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:21,137][semstamp][INFO] - Candidate text:   Also don't forget to give examples of other characters having great powers with less POV because they're more important and interesting as a character that way. 
[2024-05-23 12:05:21,137][semstamp][INFO] - Accept Mask: tensor([6, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 166.29it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.97it/s]
[2024-05-23 12:05:21,152][semstamp][INFO] - LSH Candidate: 5
[2024-05-23 12:05:21,152][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:21,846][semstamp][INFO] - Candidate text:   And since Tolkien's *LOTR* were all told from his perspective, I think it's fair game to use Frodo from *Lord of the Rings*, not Samwise Gamgee (although I do find Frodo's stories and actions really helpful). 
[2024-05-23 12:05:21,846][semstamp][INFO] - Accept Mask: tensor([6, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 136.87it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 146.28it/s]
[2024-05-23 12:05:21,864][semstamp][INFO] - LSH Candidate: 7
[2024-05-23 12:05:21,864][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:22,021][semstamp][INFO] - Candidate text:  I thought I was going to choke up writing it.
[2024-05-23 12:05:22,021][semstamp][INFO] - Accept Mask: tensor([6, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.16it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.20it/s]
[2024-05-23 12:05:22,036][semstamp][INFO] - LSH Candidate: 6
[2024-05-23 12:05:22,036][semstamp][INFO] - Candidate text falls within the semantic partition.
[2024-05-23 12:05:22,136][semstamp][INFO] - Candidate text:  So far not choking. 
[2024-05-23 12:05:22,136][semstamp][INFO] - Accept Mask: tensor([0, 3], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 161.52it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.82it/s]
[2024-05-23 12:05:22,151][semstamp][INFO] - LSH Candidate: 4
[2024-05-23 12:05:22,151][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:22,296][semstamp][INFO] - Candidate text:  Thanks for listening :)  Edit: Spelling.
[2024-05-23 12:05:22,296][semstamp][INFO] - Accept Mask: tensor([0, 3], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.95it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.01it/s]
[2024-05-23 12:05:22,311][semstamp][INFO] - LSH Candidate: 1
[2024-05-23 12:05:22,311][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:22,518][semstamp][INFO] - Candidate text:  A little kid with a sword is now my new favorite character in fiction!
[2024-05-23 12:05:22,519][semstamp][INFO] - Accept Mask: tensor([0, 3], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 169.38it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.55it/s]
[2024-05-23 12:05:22,534][semstamp][INFO] - LSH Candidate: 7
[2024-05-23 12:05:22,534][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:22,878][semstamp][INFO] - Candidate text:   Edit: also, you should do an analysis on how all these "bad" guys are made "unbaddable".
[2024-05-23 12:05:22,878][semstamp][INFO] - Accept Mask: tensor([0, 3], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.76it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.28it/s]
[2024-05-23 12:05:22,893][semstamp][INFO] - LSH Candidate: 5
[2024-05-23 12:05:22,893][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:23,000][semstamp][INFO] - Candidate text:  And then I found out why.
[2024-05-23 12:05:23,000][semstamp][INFO] - Accept Mask: tensor([0, 3], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.91it/s]
[2024-05-23 12:05:23,319][semstamp][INFO] - Candidate text:  It's not even that funny, just hard to imagine someone living so free as he did in Middle Earth. "
[2024-05-23 12:05:23,319][semstamp][INFO] - Accept Mask: tensor([0, 3], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 169.06it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.34it/s]
[2024-05-23 12:05:23,334][semstamp][INFO] - LSH Candidate: 7
[2024-05-23 12:05:23,334][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:23,543][semstamp][INFO] - Candidate text:  I really think he's one the most important characters in fantasy literature. 
[2024-05-23 12:05:23,543][semstamp][INFO] - Accept Mask: tensor([0, 3], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.92it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.91it/s]
[2024-05-23 12:05:23,558][semstamp][INFO] - LSH Candidate: 5
[2024-05-23 12:05:23,558][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:23,939][semstamp][INFO] - Candidate text:  It's an odd character to write about because Frodo isn't the leader of the ringwraiths, Saruman and Aragorn are.
[2024-05-23 12:05:23,940][semstamp][INFO] - Accept Mask: tensor([0, 3], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 166.05it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.89it/s]
[2024-05-23 12:05:23,955][semstamp][INFO] - LSH Candidate: 7
[2024-05-23 12:05:23,955][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:24,088][semstamp][INFO] - Candidate text:  Just keep writing for the sake of writing.
[2024-05-23 12:05:24,088][semstamp][INFO] - Accept Mask: tensor([0, 3], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 165.72it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.90it/s]
[2024-05-23 12:05:24,104][semstamp][INFO] - LSH Candidate: 5
[2024-05-23 12:05:24,104][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:24,199][semstamp][INFO] - Candidate text:  Thanks for being an inspiration!
[2024-05-23 12:05:24,199][semstamp][INFO] - Accept Mask: tensor([0, 3], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.55it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.61it/s]
[2024-05-23 12:05:24,214][semstamp][INFO] - LSH Candidate: 1
[2024-05-23 12:05:24,214][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:24,572][semstamp][INFO] - Candidate text:  It wasn't until I had finished and read the book several times with commentary from friends that I realized it should've been his POV.
[2024-05-23 12:05:24,572][semstamp][INFO] - Accept Mask: tensor([0, 3], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 166.65it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.81it/s]
[2024-05-23 12:05:24,588][semstamp][INFO] - LSH Candidate: 7
[2024-05-23 12:05:24,588][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:25,008][semstamp][INFO] - Candidate text:  But for the fact that Frodo always chooses justice ahead of himself, even if that means death for a greater good, it made him feel more likeable.
[2024-05-23 12:05:25,008][semstamp][INFO] - Accept Mask: tensor([0, 3], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 165.66it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.75it/s]
[2024-05-23 12:05:25,024][semstamp][INFO] - LSH Candidate: 1
[2024-05-23 12:05:25,024][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:25,318][semstamp][INFO] - Candidate text:  It's such an amazing example as to what you can accomplish with a simple piece of dialogue or narrative structure.
[2024-05-23 12:05:25,318][semstamp][INFO] - Accept Mask: tensor([0, 3], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.57it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.24it/s]
[2024-05-23 12:05:25,333][semstamp][INFO] - LSH Candidate: 5
[2024-05-23 12:05:25,333][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:25,690][semstamp][INFO] - Candidate text:  Also, what's the point of an essay, I don't think any teacher has time for stuff like this... or does he?
[2024-05-23 12:05:25,690][semstamp][INFO] - Accept Mask: tensor([0, 3], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 168.27it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.79it/s]
[2024-05-23 12:05:25,705][semstamp][INFO] - LSH Candidate: 5
[2024-05-23 12:05:25,705][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:25,813][semstamp][INFO] - Candidate text:  Not gonna lie, pretty sad.
[2024-05-23 12:05:25,813][semstamp][INFO] - Accept Mask: tensor([0, 3], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.34it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.70it/s]
[2024-05-23 12:05:25,828][semstamp][INFO] - LSH Candidate: 5
[2024-05-23 12:05:25,828][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:25,948][semstamp][INFO] - Candidate text:  (Spoiler Alert: You can't.)
[2024-05-23 12:05:25,948][semstamp][INFO] - Accept Mask: tensor([0, 3], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.02it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.02it/s]
[2024-05-23 12:05:25,963][semstamp][INFO] - LSH Candidate: 6
[2024-05-23 12:05:25,963][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:26,145][semstamp][INFO] - Candidate text:  The others are awesome, but that one really stuck with me.
[2024-05-23 12:05:26,145][semstamp][INFO] - Accept Mask: tensor([0, 3], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 165.94it/s]
[2024-05-23 12:05:26,315][semstamp][INFO] - Candidate text:  He's so much more relatable than everyone else.
[2024-05-23 12:05:26,316][semstamp][INFO] - Accept Mask: tensor([0, 3], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.91it/s]
[2024-05-23 12:05:26,492][semstamp][INFO] - Candidate text:   What are some ways that power helps or fails characters?
[2024-05-23 12:05:26,493][semstamp][INFO] - Accept Mask: tensor([0, 3], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.29it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.71it/s]
[2024-05-23 12:05:26,507][semstamp][INFO] - LSH Candidate: 5
[2024-05-23 12:05:26,508][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:26,727][semstamp][INFO] - Candidate text:  This was back when I was a virgin and had no clue about this stuff.
[2024-05-23 12:05:26,727][semstamp][INFO] - Accept Mask: tensor([0, 3], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.98it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.42it/s]
[2024-05-23 12:05:26,742][semstamp][INFO] - LSH Candidate: 3
[2024-05-23 12:05:26,742][semstamp][INFO] - Candidate text falls within the semantic partition.
[2024-05-23 12:05:26,931][semstamp][INFO] - Candidate text:  It makes me tear up just thinking about it now.  
[2024-05-23 12:05:26,931][semstamp][INFO] - Accept Mask: tensor([6, 0], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 169.06it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.57it/s]
[2024-05-23 12:05:26,946][semstamp][INFO] - LSH Candidate: 6
[2024-05-23 12:05:26,946][semstamp][INFO] - Candidate text falls within the semantic partition.
[2024-05-23 12:05:27,148][semstamp][INFO] - Candidate text:  And my answer to that would be the same as yours, obviously.
[2024-05-23 12:05:27,148][semstamp][INFO] - Accept Mask: tensor([0, 3], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.66it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.29it/s]
[2024-05-23 12:05:27,163][semstamp][INFO] - LSH Candidate: 3
[2024-05-23 12:05:27,163][semstamp][INFO] - Candidate text falls within the semantic partition.
[2024-05-23 12:05:27,227][semstamp][INFO] - Candidate text:  Sauron.
[2024-05-23 12:05:27,228][semstamp][INFO] - Accept Mask: tensor([6, 0], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.62it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.80it/s]
[2024-05-23 12:05:27,242][semstamp][INFO] - LSH Candidate: 2
[2024-05-23 12:05:27,243][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:27,306][semstamp][INFO] - Candidate text:  Sauron.
[2024-05-23 12:05:27,306][semstamp][INFO] - Accept Mask: tensor([6, 0], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.49it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.69it/s]
[2024-05-23 12:05:27,321][semstamp][INFO] - LSH Candidate: 2
[2024-05-23 12:05:27,321][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:27,673][semstamp][INFO] - Candidate text:  A little more effort because he has more interaction with those around him, but not really much more :) :) :D :) :)!
[2024-05-23 12:05:27,674][semstamp][INFO] - Accept Mask: tensor([6, 0], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 169.49it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.22it/s]
[2024-05-23 12:05:27,689][semstamp][INFO] - LSH Candidate: 0
[2024-05-23 12:05:27,689][semstamp][INFO] - Candidate text falls within the semantic partition.
[2024-05-23 12:05:27,818][semstamp][INFO] - Candidate text:  :) :) :D :) :D!
[2024-05-23 12:05:27,819][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.72it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.73it/s]
[2024-05-23 12:05:27,834][semstamp][INFO] - LSH Candidate: 0
[2024-05-23 12:05:27,834][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:27,874][semstamp][INFO] - Candidate text:  :)
[2024-05-23 12:05:27,874][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.00it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 180.75it/s]
[2024-05-23 12:05:27,889][semstamp][INFO] - LSH Candidate: 1
[2024-05-23 12:05:27,889][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:27,969][semstamp][INFO] - Candidate text:  :D :D
[2024-05-23 12:05:27,969][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.31it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.56it/s]
[2024-05-23 12:05:27,983][semstamp][INFO] - LSH Candidate: 3
[2024-05-23 12:05:27,984][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:28,062][semstamp][INFO] - Candidate text:  :) :) :)!
[2024-05-23 12:05:28,062][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.09it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.67it/s]
[2024-05-23 12:05:28,077][semstamp][INFO] - LSH Candidate: 0
[2024-05-23 12:05:28,077][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:28,168][semstamp][INFO] - Candidate text:  :D :D!
[2024-05-23 12:05:28,168][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.68it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.55it/s]
[2024-05-23 12:05:28,183][semstamp][INFO] - LSH Candidate: 1
[2024-05-23 12:05:28,183][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:28,262][semstamp][INFO] - Candidate text:  :) :) :)!
[2024-05-23 12:05:28,262][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.66it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.03it/s]
[2024-05-23 12:05:28,277][semstamp][INFO] - LSH Candidate: 0
[2024-05-23 12:05:28,277][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:28,343][semstamp][INFO] - Candidate text:  :D!
[2024-05-23 12:05:28,343][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.08it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.87it/s]
[2024-05-23 12:05:28,358][semstamp][INFO] - LSH Candidate: 1
[2024-05-23 12:05:28,358][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:28,955][semstamp][INFO] - Candidate text: <3!!1!one!one!e :DDDDD: )~:>0(:~ ):~)))))!<) D= :'("^"*:)~~~! '
[2024-05-23 12:05:28,955][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 139.24it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 149.53it/s]
[2024-05-23 12:05:28,972][semstamp][INFO] - LSH Candidate: 2
[2024-05-23 12:05:28,973][semstamp][INFO] - Candidate text is more than one sentence.
[2024-05-23 12:05:29,077][semstamp][INFO] - Candidate text:  :) :) :D :P
[2024-05-23 12:05:29,077][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.69it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.16it/s]
[2024-05-23 12:05:29,092][semstamp][INFO] - LSH Candidate: 0
[2024-05-23 12:05:29,092][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:29,158][semstamp][INFO] - Candidate text:  :) :)!
[2024-05-23 12:05:29,158][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.22it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.76it/s]
[2024-05-23 12:05:29,173][semstamp][INFO] - LSH Candidate: 0
[2024-05-23 12:05:29,173][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:29,226][semstamp][INFO] - Candidate text:  :)!
[2024-05-23 12:05:29,226][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.97it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.98it/s]
[2024-05-23 12:05:29,241][semstamp][INFO] - LSH Candidate: 1
[2024-05-23 12:05:29,241][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:29,332][semstamp][INFO] - Candidate text:  Thanks for the contest!
[2024-05-23 12:05:29,332][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.64it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.93it/s]
[2024-05-23 12:05:29,347][semstamp][INFO] - LSH Candidate: 1
[2024-05-23 12:05:29,347][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:29,413][semstamp][INFO] - Candidate text:  Thanks! 
[2024-05-23 12:05:29,413][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.24it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.76it/s]
[2024-05-23 12:05:29,428][semstamp][INFO] - LSH Candidate: 1
[2024-05-23 12:05:29,428][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:29,532][semstamp][INFO] - Candidate text:  :) :) :) :D :)
[2024-05-23 12:05:29,532][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.34it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.81it/s]
[2024-05-23 12:05:29,547][semstamp][INFO] - LSH Candidate: 0
[2024-05-23 12:05:29,547][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:29,651][semstamp][INFO] - Candidate text:  Hahaha :P!
[2024-05-23 12:05:29,651][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.05it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.56it/s]
[2024-05-23 12:05:29,666][semstamp][INFO] - LSH Candidate: 4
[2024-05-23 12:05:29,666][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:29,720][semstamp][INFO] - Candidate text:  :) :-)
[2024-05-23 12:05:29,720][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.90it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.04it/s]
[2024-05-23 12:05:29,735][semstamp][INFO] - LSH Candidate: 0
[2024-05-23 12:05:29,735][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:29,902][semstamp][INFO] - Candidate text: ~:) Hope that helps! :) :D!
[2024-05-23 12:05:29,902][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.52it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.35it/s]
[2024-05-23 12:05:29,917][semstamp][INFO] - LSH Candidate: 1
[2024-05-23 12:05:29,917][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:29,983][semstamp][INFO] - Candidate text:  :D!
[2024-05-23 12:05:29,983][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.92it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 179.06it/s]
[2024-05-23 12:05:29,998][semstamp][INFO] - LSH Candidate: 1
[2024-05-23 12:05:29,998][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:30,077][semstamp][INFO] - Candidate text:   Good luck!
[2024-05-23 12:05:30,077][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.80it/s]
[2024-05-23 12:05:30,188][semstamp][INFO] - Candidate text:  :D:P:D
[2024-05-23 12:05:30,189][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.85it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.35it/s]
[2024-05-23 12:05:30,203][semstamp][INFO] - LSH Candidate: 4
[2024-05-23 12:05:30,204][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:30,333][semstamp][INFO] - Candidate text:  :)  Good answers anyway :) :)!
[2024-05-23 12:05:30,333][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.75it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.83it/s]
[2024-05-23 12:05:30,348][semstamp][INFO] - LSH Candidate: 1
[2024-05-23 12:05:30,348][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:30,414][semstamp][INFO] - Candidate text:  :) :)!
[2024-05-23 12:05:30,414][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.50it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.17it/s]
[2024-05-23 12:05:30,429][semstamp][INFO] - LSH Candidate: 0
[2024-05-23 12:05:30,429][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:30,584][semstamp][INFO] - Candidate text:   Edit: spelling, words and random shit.
[2024-05-23 12:05:30,584][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.46it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.56it/s]
[2024-05-23 12:05:30,599][semstamp][INFO] - LSH Candidate: 1
[2024-05-23 12:05:30,599][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:30,640][semstamp][INFO] - Candidate text:  Enjoy
[2024-05-23 12:05:30,640][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.72it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 184.41it/s]
[2024-05-23 12:05:30,655][semstamp][INFO] - LSH Candidate: 3
[2024-05-23 12:05:30,655][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:30,746][semstamp][INFO] - Candidate text:  :D :D!
[2024-05-23 12:05:30,746][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.67it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.53it/s]
[2024-05-23 12:05:30,761][semstamp][INFO] - LSH Candidate: 1
[2024-05-23 12:05:30,761][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-23 12:05:30,890][semstamp][INFO] - Candidate text:  (just kiddin you!) 
[2024-05-23 12:05:30,890][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches:   0%|          | 0/1 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/local1/borito1907/impossibility-watermark/watermarked_text_generator.py", line 44, in <module>
    test()
  File "/local1/borito1907/anaconda3/envs/watermark/lib/python3.12/site-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
  File "/local1/borito1907/anaconda3/envs/watermark/lib/python3.12/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/local1/borito1907/anaconda3/envs/watermark/lib/python3.12/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/local1/borito1907/anaconda3/envs/watermark/lib/python3.12/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           ^^^^^^
  File "/local1/borito1907/anaconda3/envs/watermark/lib/python3.12/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            ^^^^^^^^^^
  File "/local1/borito1907/anaconda3/envs/watermark/lib/python3.12/site-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
          ^^^^^^^^
  File "/local1/borito1907/anaconda3/envs/watermark/lib/python3.12/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
                       ^^^^^^^^^^^^^^^^^^^^^^^
  File "/local1/borito1907/impossibility-watermark/watermarked_text_generator.py", line 27, in test
    watermarked_text = watermarker.generate(prompt)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local1/borito1907/impossibility-watermark/watermarker.py", line 51, in generate
    completion = self.generate_watermarked_outputs(prompt)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local1/borito1907/impossibility-watermark/semstamp.py", line 204, in generate_watermarked_outputs
    return self._lsh_generate_watermarked_outputs(prompt)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local1/borito1907/impossibility-watermark/semstamp.py", line 214, in _lsh_generate_watermarked_outputs
    response = self.lsh_reject_completion(prompt)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local1/borito1907/impossibility-watermark/semstamp.py", line 153, in lsh_reject_completion
    accepted_text, _ = reject_close_generation(
                       ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local1/borito1907/impossibility-watermark/SemStamp/sampling_lsh_utils.py", line 42, in reject_close_generation
    embeds = lsh_model.get_embeddings(sents)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local1/borito1907/impossibility-watermark/SemStamp/sbert_lsh_model.py", line 101, in get_embeddings
    all_embeddings = self.embedder.encode(
                     ^^^^^^^^^^^^^^^^^^^^^
  File "/local1/borito1907/anaconda3/envs/watermark/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py", line 357, in encode
    out_features = self.forward(features)
                   ^^^^^^^^^^^^^^^^^^^^^^
  File "/local1/borito1907/anaconda3/envs/watermark/lib/python3.12/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/local1/borito1907/anaconda3/envs/watermark/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local1/borito1907/anaconda3/envs/watermark/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local1/borito1907/anaconda3/envs/watermark/lib/python3.12/site-packages/sentence_transformers/models/Transformer.py", line 98, in forward
    output_states = self.auto_model(**trans_features, return_dict=False)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local1/borito1907/anaconda3/envs/watermark/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local1/borito1907/anaconda3/envs/watermark/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local1/borito1907/anaconda3/envs/watermark/lib/python3.12/site-packages/transformers/models/mpnet/modeling_mpnet.py", line 551, in forward
    encoder_outputs = self.encoder(
                      ^^^^^^^^^^^^^
  File "/local1/borito1907/anaconda3/envs/watermark/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local1/borito1907/anaconda3/envs/watermark/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local1/borito1907/anaconda3/envs/watermark/lib/python3.12/site-packages/transformers/models/mpnet/modeling_mpnet.py", line 341, in forward
    layer_outputs = layer_module(
                    ^^^^^^^^^^^^^
  File "/local1/borito1907/anaconda3/envs/watermark/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local1/borito1907/anaconda3/envs/watermark/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local1/borito1907/anaconda3/envs/watermark/lib/python3.12/site-packages/transformers/models/mpnet/modeling_mpnet.py", line 300, in forward
    self_attention_outputs = self.attention(
                             ^^^^^^^^^^^^^^^
  File "/local1/borito1907/anaconda3/envs/watermark/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local1/borito1907/anaconda3/envs/watermark/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local1/borito1907/anaconda3/envs/watermark/lib/python3.12/site-packages/transformers/models/mpnet/modeling_mpnet.py", line 241, in forward
    self_outputs = self.attn(
                   ^^^^^^^^^^
  File "/local1/borito1907/anaconda3/envs/watermark/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local1/borito1907/anaconda3/envs/watermark/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local1/borito1907/anaconda3/envs/watermark/lib/python3.12/site-packages/transformers/models/mpnet/modeling_mpnet.py", line 177, in forward
    attention_scores = torch.matmul(q, k.transpose(-1, -2))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
