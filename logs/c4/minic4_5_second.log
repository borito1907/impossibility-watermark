/local1/borito1907/anaconda3/envs/watermark/lib/python3.12/site-packages/transformers/utils/hub.py:122: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
[nltk_data] Downloading package punkt to /home/borito1907/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[2024-05-24 00:09:54,778][__main__][INFO] - Starting to watermark...
[2024-05-24 00:09:54,781][__main__][INFO] - Prompt: Panicked investors who participated in the mammoth stock sell-off should get back into the market immediately because a lengthy hiatus often results in missing out on gains.
Panicked investors who were prompted by fears and participated in the mammoth stock sell-off should get back into the market immediately, because a lengthy hiatus often results in missing out on gains.
Investors who lost their nerve this week should not wait to get return to the market since some individuals will wind up sitting on the sidelines for too long. Investing in the market straightaway prevents investors from taking part of “another form of market timing,” said Edison Byzyka, vice president of investments for Hefty Wealth Partners in Auburn, Ind.
An investing strategy based on emotions never succeeds since your feelings will “always betray you” and is a fool’s errand, said Matthew Tuttle, portfolio manager of the Tuttle Tactical Management U.S. Core ETF in Stamford, Conn.
If the stock market has a down day, followers of this strategy then believe the following day will also experience losses, he said. On the contrary, these investors also believe that if the market is in the green, the next day’s performance will produce the same positive results.
Dollar cost averaging remains the best method to accumulate wealth over the long haul and individuals should “invest early and often,” said Robert Johnson, president of The American College of Financial Services in Bryn Mawr, Pa.
Selling stocks sounds like a simple decision, but there are caveats, since investors also have to determine when to return to the market. What often happens is that many people only get one of those decisions right and get the other one wrong and end up losing money, he said.
Investors who adhere to the dollar cost averaging strategy can use their money over time to purchase equities at “lower prices if the market does decline for a long period of time,” said Yale Bock, a portfolio manager on Covestor, the online investing marketplace, and president of Y H & C Investments in Las Vegas.
Pursuing an alternative method relies on using all of your capital at one time and having to be accurate about trying to time both the price and market, “which is literally impossible,” he said.
The next step is determining what increments your dollar cost average strategy will follow, depending on your outlook and approach.
“I believe the next six months to a year will be a difficult period of time in energy, so allocating capital at the end of every month to buy the stocks of energy companies we want to own is our approach," Bock said.
Remaining an active investor yields greater returns since on the average, the market always rises. An index of large cap stocks rose 10% per year since 1926, and there have not been any negative 20-year holding periods recorded since then, Johnson said.
Of course, there have been ten-year holding periods that have produced negative returns, such as the years of 1999 through 2008 that included the dotcom bust and the financial crisis resulting in an an average annual return of –1.38%. But that decade was the first negative ten-year holding period since the Great Depression years of 1930 through 1939.
Long-term investors should not forget that the number of positive returns outweighs the down years. In the S&P 500, the benchmark index, there have been 68 positive return years and only 22 negative years since 1926.
Buying additional stocks during a dip in the market can net you more gains than merely sticking with dollar cost averaging since this tactic produces “mediocre performance,” said Sreeni Meka, a portfolio manager on Covestor and a managing member of Lakeland Wealth Management in Lakeland, Tenn.
“If you are an individual stock picker, what is the point of buying equities when fundamentals are off?” he said. “If great opportunities are ahead and the economy is coming out of recession, what is the point sticking to cash and investing only average amount?"
[2024-05-24 00:09:54,781][__main__][INFO] - Getting the watermarker...
[2024-05-24 00:09:54,781][watermarker][INFO] - Using device: cuda
[2024-05-24 00:09:54,782][model_builders.pipeline][INFO] - Initializing MaziyarPanahi/Meta-Llama-3-70B-Instruct-GPTQ
INFO - You passed a model that is compatible with the Marlin int4*fp16 GPTQ kernel but use_marlin is False. We recommend using `use_marlin=True` to use the optimized Marlin kernels for inference. Example: `model = AutoGPTQForCausalLM.from_quantized(..., use_marlin=True)`.
INFO - The layer lm_head is not quantized.
[2024-05-24 00:09:59,898][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2024-05-24 00:10:10,331][auto_gptq.utils.accelerate_utils][WARNING] - Some weights of the model checkpoint at ./local1/borito1907/.cache/models--MaziyarPanahi--Meta-Llama-3-70B-Instruct-GPTQ/snapshots/46c7afccd4f9345a3d43c1468fde1034cf0a0932/model.safetensors were not used when initializing LlamaForCausalLM: set(). This may or may not be an issue - make sure that the checkpoint does not have unnecessary parameters, or that the model definition correctly corresponds to the checkpoint.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
The model 'LlamaGPTQForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FuyuForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].
[2024-05-24 00:10:13,409][semstamp][INFO] - Setting up generating components...
[2024-05-24 00:10:13,412][semstamp][INFO] - {'max_new_tokens': 1024, 'do_sample': True, 'temperature': 1.0, 'top_p': 0.95, 'top_k': 40, 'repetition_penalty': 1.1, 'bad_words_ids': [[198]], 'min_new_tokens': 245}
[2024-05-24 00:10:13,412][semstamp][INFO] - Initializing embedder model.
[2024-05-24 00:10:13,412][sentence_transformers.SentenceTransformer][INFO] - Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v1
[2024-05-24 00:10:14,249][sentence_transformers.SentenceTransformer][INFO] - Use pytorch device_name: cuda
[2024-05-24 00:10:14,313][semstamp][INFO] - Finished initializing embedder model.
initializing random projection LSH model
loading SBERT base model...
[2024-05-24 00:10:14,314][__main__][INFO] - Got the watermarker. Generating watermarked text...
[2024-05-24 00:10:14,314][semstamp][INFO] - Passing the following prompt to the LSH reject completion function:
 Panicked investors who participated in the mammoth stock sell-off should get back into the market immediately because a lengthy hiatus often results in missing out on gains.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  3.18it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:10:18,907][semstamp][INFO] - Candidate text:  Here are  few tips for novice investors to navigate the volatile markets:
1.
[2024-05-24 00:10:18,907][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 151.08it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 167.67it/s]
[2024-05-24 00:10:18,926][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:10:18,927][semstamp][INFO] - Candidate text falls within the semantic partition.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:10:21,119][semstamp][INFO] - Candidate text:  **Re-investing gradually**: Divide your investment corpus into smaller portions and invest them at regular intervals (e.g., every quarter).
[2024-05-24 00:10:21,121][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 133.71it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 166.13it/s]
[2024-05-24 00:10:21,139][semstamp][INFO] - LSH Candidate: 7
[2024-05-24 00:10:21,140][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:10:23,260][semstamp][INFO] - Candidate text:  **Diversification**: Spread your investments across different asset classes like stocks, bonds, gold, and real estate to minimize risk.

[2024-05-24 00:10:23,261][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 149.34it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 169.62it/s]
[2024-05-24 00:10:23,277][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:10:23,277][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:10:25,269][semstamp][INFO] - Candidate text:  **Diversify your portfolio**: Spread your investments across different asset classes, sectors, and geographies to minimize risk.

[2024-05-24 00:10:25,269][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 153.22it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:10:27,205][semstamp][INFO] - Candidate text:  **Diversification is key**: Spread your investments across asset classes, sectors, and geographies to minimize risk.

[2024-05-24 00:10:27,205][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 158.60it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.31it/s]
[2024-05-24 00:10:27,221][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:10:27,221][semstamp][INFO] - Candidate text falls within the semantic partition.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:10:27,880][semstamp][INFO] - Candidate text: 2.
[2024-05-24 00:10:27,880][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 100.19it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.19it/s]
[2024-05-24 00:10:27,900][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:10:27,900][semstamp][INFO] - Candidate text falls within the semantic partition.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:10:31,672][semstamp][INFO] - Candidate text:  **Set a budget**: Decide how much you can invest each month and stick to it, regardless of market conditions.

[2024-05-24 00:10:31,672][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 156.61it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.47it/s]
[2024-05-24 00:10:31,688][semstamp][INFO] - LSH Candidate: 4
[2024-05-24 00:10:31,689][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:10:33,305][semstamp][INFO] - Candidate text:  **Long-term perspective**: Focus on time-tested strategies rather than short-term market fluctuations.

[2024-05-24 00:10:33,305][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 152.58it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.08it/s]
[2024-05-24 00:10:33,321][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:10:33,321][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:10:35,533][semstamp][INFO] - Candidate text:  **Invest regularly**: Use dollar-cost averaging to invest a fixed amount of money at regular intervals, regardless of the market's performance.

[2024-05-24 00:10:35,533][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 154.26it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:10:37,820][semstamp][INFO] - Candidate text:  **Start with a solid foundation**: Allocate a portion of your portfolio to low-risk investments like bonds, CDs, or money market funds.

[2024-05-24 00:10:37,820][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 157.48it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.07it/s]
[2024-05-24 00:10:37,836][semstamp][INFO] - LSH Candidate: 5
[2024-05-24 00:10:37,836][semstamp][INFO] - Candidate text falls within the semantic partition.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:10:38,472][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:10:38,472][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.90it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.80it/s]
[2024-05-24 00:10:38,487][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:10:38,487][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:10:39,121][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:10:39,121][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.04it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.69it/s]
[2024-05-24 00:10:39,136][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:10:39,136][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:10:39,771][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:10:39,771][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.38it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.97it/s]
[2024-05-24 00:10:39,786][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:10:39,786][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:10:40,421][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:10:40,421][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.29it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.62it/s]
[2024-05-24 00:10:40,436][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:10:40,436][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:10:41,070][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:10:41,071][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.40it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.31it/s]
[2024-05-24 00:10:41,085][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:10:41,085][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:10:41,720][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:10:41,720][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.90it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.94it/s]
[2024-05-24 00:10:41,735][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:10:41,735][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:10:42,369][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:10:42,370][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.43it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.09it/s]
[2024-05-24 00:10:42,384][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:10:42,384][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:10:43,019][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:10:43,019][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.06it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.62it/s]
[2024-05-24 00:10:43,034][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:10:43,034][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:10:43,669][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:10:43,669][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.70it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.08it/s]
[2024-05-24 00:10:43,684][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:10:43,684][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:10:44,318][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:10:44,319][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.25it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.60it/s]
[2024-05-24 00:10:44,333][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:10:44,333][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:10:44,968][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:10:44,968][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.73it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.26it/s]
[2024-05-24 00:10:44,983][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:10:44,983][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:10:45,618][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:10:45,618][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.10it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.67it/s]
[2024-05-24 00:10:45,633][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:10:45,633][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:10:46,268][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:10:46,268][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.39it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.28it/s]
[2024-05-24 00:10:46,282][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:10:46,283][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:10:46,917][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:10:46,917][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.82it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.07it/s]
[2024-05-24 00:10:46,932][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:10:46,932][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:10:47,567][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:10:47,567][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.66it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.19it/s]
[2024-05-24 00:10:47,582][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:10:47,582][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:10:48,217][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:10:48,217][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.46it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.45it/s]
[2024-05-24 00:10:48,232][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:10:48,232][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:10:48,866][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:10:48,866][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.32it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.26it/s]
[2024-05-24 00:10:48,881][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:10:48,881][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:10:49,516][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:10:49,516][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.67it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.92it/s]
[2024-05-24 00:10:49,531][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:10:49,531][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:10:50,166][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:10:50,166][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.39it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.63it/s]
[2024-05-24 00:10:50,181][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:10:50,181][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:10:50,817][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:10:50,817][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 168.62it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.98it/s]
[2024-05-24 00:10:50,832][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:10:50,832][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:10:51,467][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:10:51,467][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.77it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.06it/s]
[2024-05-24 00:10:51,482][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:10:51,482][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:10:52,116][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:10:52,117][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 155.12it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.60it/s]
[2024-05-24 00:10:52,132][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:10:52,132][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:10:52,767][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:10:52,767][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.13it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.44it/s]
[2024-05-24 00:10:52,782][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:10:52,782][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:10:53,417][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:10:53,417][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.98it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.89it/s]
[2024-05-24 00:10:53,432][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:10:53,432][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:10:54,067][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:10:54,067][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.48it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.58it/s]
[2024-05-24 00:10:54,082][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:10:54,082][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:10:54,717][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:10:54,717][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.01it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.59it/s]
[2024-05-24 00:10:54,732][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:10:54,732][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:10:55,367][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:10:55,367][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 169.56it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.86it/s]
[2024-05-24 00:10:55,382][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:10:55,383][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:10:56,018][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:10:56,018][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 163.18it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 168.86it/s]
[2024-05-24 00:10:56,034][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:10:56,034][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:10:56,669][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:10:56,669][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.09it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.09it/s]
[2024-05-24 00:10:56,684][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:10:56,684][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:10:57,320][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:10:57,320][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 164.15it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.49it/s]
[2024-05-24 00:10:57,335][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:10:57,336][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:10:57,971][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:10:57,971][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 169.72it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.58it/s]
[2024-05-24 00:10:57,986][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:10:57,986][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:10:58,621][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:10:58,621][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.07it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.30it/s]
[2024-05-24 00:10:58,636][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:10:58,636][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:10:59,271][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:10:59,272][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.09it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.39it/s]
[2024-05-24 00:10:59,286][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:10:59,286][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:10:59,921][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:10:59,922][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.90it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.62it/s]
[2024-05-24 00:10:59,936][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:10:59,936][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:00,573][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:00,573][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 161.49it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.08it/s]
[2024-05-24 00:11:00,589][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:00,589][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:01,225][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:01,225][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 169.89it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.63it/s]
[2024-05-24 00:11:01,240][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:01,240][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:01,876][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:01,876][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.47it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.99it/s]
[2024-05-24 00:11:01,891][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:01,891][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:02,526][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:02,526][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.90it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.99it/s]
[2024-05-24 00:11:02,541][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:02,541][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:03,177][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:03,177][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.43it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.81it/s]
[2024-05-24 00:11:03,192][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:03,192][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:03,826][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:03,827][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.54it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.65it/s]
[2024-05-24 00:11:03,841][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:03,841][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:04,477][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:04,477][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.05it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.44it/s]
[2024-05-24 00:11:04,492][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:04,492][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:05,127][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:05,127][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.52it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.49it/s]
[2024-05-24 00:11:05,142][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:05,142][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:05,777][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:05,778][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.12it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.02it/s]
[2024-05-24 00:11:05,792][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:05,792][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:06,427][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:06,428][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.94it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.82it/s]
[2024-05-24 00:11:06,442][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:06,442][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:07,078][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:07,078][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.84it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.98it/s]
[2024-05-24 00:11:07,093][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:07,093][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:07,728][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:07,728][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.22it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.56it/s]
[2024-05-24 00:11:07,743][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:07,743][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:08,378][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:08,379][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.99it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.82it/s]
[2024-05-24 00:11:08,393][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:08,394][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:09,029][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:09,029][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.57it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.38it/s]
[2024-05-24 00:11:09,044][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:09,044][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:09,679][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:09,679][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.10it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.80it/s]
[2024-05-24 00:11:09,694][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:09,694][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:10,330][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:10,330][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.95it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.48it/s]
[2024-05-24 00:11:10,345][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:10,345][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:10,980][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:10,981][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 159.27it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.25it/s]
[2024-05-24 00:11:10,997][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:10,997][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:11,636][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:11,636][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 157.29it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 167.37it/s]
[2024-05-24 00:11:11,653][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:11,653][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:12,290][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:12,291][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 153.45it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 163.85it/s]
[2024-05-24 00:11:12,308][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:12,308][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:12,955][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:12,956][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 126.08it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 123.61it/s]
[2024-05-24 00:11:12,978][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:12,978][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:13,626][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:13,626][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 115.36it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 132.25it/s]
[2024-05-24 00:11:13,648][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:13,648][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:14,285][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:14,286][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 156.00it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 164.79it/s]
[2024-05-24 00:11:14,302][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:14,302][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:14,938][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:14,938][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 167.04it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.61it/s]
[2024-05-24 00:11:14,953][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:14,953][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:15,589][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:15,589][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.20it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.43it/s]
[2024-05-24 00:11:15,604][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:15,604][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:16,240][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:16,241][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 162.99it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.99it/s]
[2024-05-24 00:11:16,256][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:16,257][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:16,892][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:16,893][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 163.78it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.55it/s]
[2024-05-24 00:11:16,908][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:16,908][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:17,544][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:17,544][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.10it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 179.32it/s]
[2024-05-24 00:11:17,559][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:17,559][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:18,194][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:18,194][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.77it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.67it/s]
[2024-05-24 00:11:18,209][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:18,209][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:18,844][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:18,844][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.02it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 179.04it/s]
[2024-05-24 00:11:18,859][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:18,859][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:19,495][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:19,495][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.23it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 168.05it/s]
[2024-05-24 00:11:19,510][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:19,510][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:20,145][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:20,146][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.46it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.04it/s]
[2024-05-24 00:11:20,160][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:20,160][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:20,796][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:20,796][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.11it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.19it/s]
[2024-05-24 00:11:20,811][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:20,811][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:21,447][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:21,447][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.24it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.59it/s]
[2024-05-24 00:11:21,462][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:21,462][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:22,097][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:22,098][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.03it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.63it/s]
[2024-05-24 00:11:22,112][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:22,113][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:22,748][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:22,748][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.93it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.31it/s]
[2024-05-24 00:11:22,763][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:22,763][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:23,398][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:23,398][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.74it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.84it/s]
[2024-05-24 00:11:23,412][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:23,413][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:24,048][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:24,048][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.79it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.33it/s]
[2024-05-24 00:11:24,063][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:24,063][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:24,698][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:24,699][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.61it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 179.80it/s]
[2024-05-24 00:11:24,713][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:24,713][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:25,349][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:25,349][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.35it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 179.09it/s]
[2024-05-24 00:11:25,363][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:25,363][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:25,998][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:25,999][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.30it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 179.27it/s]
[2024-05-24 00:11:26,013][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:26,013][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:26,649][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:26,649][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 165.10it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.98it/s]
[2024-05-24 00:11:26,664][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:26,664][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:27,299][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:27,299][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.85it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.68it/s]
[2024-05-24 00:11:27,314][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:27,314][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:27,950][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:27,950][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.72it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.69it/s]
[2024-05-24 00:11:27,965][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:27,965][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:28,600][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:28,600][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.61it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.37it/s]
[2024-05-24 00:11:28,615][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:28,615][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:29,251][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:29,251][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.10it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.39it/s]
[2024-05-24 00:11:29,266][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:29,266][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:29,902][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:29,902][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 168.30it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.84it/s]
[2024-05-24 00:11:29,917][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:29,917][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:30,552][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:30,553][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.41it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.22it/s]
[2024-05-24 00:11:30,567][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:30,568][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:31,203][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:31,204][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 168.50it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 182.14it/s]
[2024-05-24 00:11:31,219][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:31,219][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:31,854][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:31,855][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.19it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.76it/s]
[2024-05-24 00:11:31,869][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:31,870][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:32,505][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:32,505][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.88it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.04it/s]
[2024-05-24 00:11:32,520][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:32,520][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:33,155][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:33,155][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.50it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.52it/s]
[2024-05-24 00:11:33,170][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:33,170][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:33,805][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:33,806][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.21it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.09it/s]
[2024-05-24 00:11:33,820][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:33,821][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:34,457][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:34,457][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 156.35it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.88it/s]
[2024-05-24 00:11:34,474][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:34,474][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:35,109][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:35,110][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 169.23it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.33it/s]
[2024-05-24 00:11:35,125][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:35,125][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:35,760][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:35,761][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 167.02it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.22it/s]
[2024-05-24 00:11:35,776][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:35,776][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:36,412][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:36,412][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.29it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.83it/s]
[2024-05-24 00:11:36,427][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:36,427][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:37,062][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:37,062][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.30it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.06it/s]
[2024-05-24 00:11:37,077][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:37,077][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:37,713][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:37,713][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.07it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.79it/s]
[2024-05-24 00:11:37,728][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:37,728][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:38,363][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:38,364][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.28it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.12it/s]
[2024-05-24 00:11:38,378][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:38,378][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:39,014][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:39,014][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.85it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.37it/s]
[2024-05-24 00:11:39,029][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:39,029][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:39,664][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:39,664][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.92it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.74it/s]
[2024-05-24 00:11:39,679][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:39,679][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:40,315][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:40,315][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 168.72it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.73it/s]
[2024-05-24 00:11:40,330][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:40,330][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:40,966][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:40,966][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 168.87it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.76it/s]
[2024-05-24 00:11:40,981][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:40,981][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:41,617][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:41,617][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.88it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.33it/s]
[2024-05-24 00:11:41,632][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:41,632][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:42,268][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:42,268][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.22it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.79it/s]
[2024-05-24 00:11:42,283][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:42,283][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:42,918][semstamp][INFO] - Candidate text: 3.
[2024-05-24 00:11:42,918][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.97it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.43it/s]
[2024-05-24 00:11:42,933][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:11:42,933][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-24 00:11:42,933][semstamp][INFO] - WARNING: desired semantic signature can't be sampled after max_trials 100
[2024-05-24 00:11:42,934][semstamp][INFO] - CONTEXT: Panicked investors who participated in the mammoth stock sell-off should get back into the market immediately because a lengthy hiatus often results in missing out on gains. Here are  few tips for novice investors to navigate the volatile markets:
1. **Diversification is key**: Spread your investments across asset classes, sectors, and geographies to minimize risk.
2. **Start with a solid foundation**: Allocate a portion of your portfolio to low-risk investments like bonds, CDs, or money market funds.

[2024-05-24 00:11:42,934][semstamp][INFO] - NOTE: use regular (non-filtered-by-sig) continuation: 3.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:45,100][semstamp][INFO] - Candidate text:  **Take the emotion out**: Set a budget, automate your investments, and avoid making impulsive decisions based on market fluctuations.

[2024-05-24 00:11:45,100][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 152.38it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 168.95it/s]
[2024-05-24 00:11:45,117][semstamp][INFO] - LSH Candidate: 4
[2024-05-24 00:11:45,117][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:46,950][semstamp][INFO] - Candidate text:  **Set clear goals and timelines**: Define your investment objectives and horizons to avoid emotional decision-making.

[2024-05-24 00:11:46,951][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 149.72it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.35it/s]
[2024-05-24 00:11:46,967][semstamp][INFO] - LSH Candidate: 5
[2024-05-24 00:11:46,967][semstamp][INFO] - Candidate text falls within the semantic partition.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:48,104][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:11:48,104][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 166.30it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:48,745][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:11:48,745][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.28it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:49,385][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:11:49,385][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.70it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:50,025][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:11:50,025][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 167.93it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:50,666][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:11:50,666][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 165.37it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:51,306][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:11:51,306][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.93it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:51,947][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:11:51,947][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 164.79it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:52,588][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:11:52,588][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 167.18it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:53,228][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:11:53,228][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 169.17it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:53,868][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:11:53,868][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.22it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:54,508][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:11:54,508][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 167.96it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:55,149][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:11:55,149][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.69it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:55,789][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:11:55,789][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.99it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:56,429][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:11:56,429][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.72it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:57,069][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:11:57,069][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 169.51it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:57,709][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:11:57,709][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.60it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:58,349][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:11:58,349][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.71it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:58,989][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:11:58,989][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.89it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:11:59,630][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:11:59,630][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 167.14it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:00,271][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:00,271][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 168.60it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:00,911][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:00,911][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 168.86it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:01,551][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:01,552][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.42it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:02,192][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:02,192][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.23it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:02,832][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:02,832][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.39it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:03,472][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:03,473][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.68it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:04,113][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:04,113][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 167.77it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:04,754][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:04,754][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.68it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:05,394][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:05,394][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.01it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:06,034][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:06,035][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.27it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:06,675][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:06,675][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.50it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:07,315][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:07,315][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.50it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:07,955][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:07,955][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.37it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:08,595][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:08,595][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.29it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:09,235][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:09,235][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.51it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:09,875][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:09,875][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.48it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:10,515][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:10,515][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 167.40it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:11,155][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:11,155][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.43it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:11,795][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:11,795][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 160.08it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:12,436][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:12,436][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.54it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:13,076][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:13,076][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.07it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:13,716][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:13,716][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.55it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:14,356][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:14,356][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.63it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:14,996][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:14,996][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.23it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:15,636][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:15,636][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.72it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:16,276][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:16,276][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.50it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:16,916][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:16,916][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.77it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:17,555][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:17,556][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.76it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:18,195][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:18,196][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.95it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:18,836][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:18,836][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 160.35it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:19,487][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:19,487][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 158.92it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:20,129][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:20,129][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 166.57it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:20,769][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:20,769][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 164.96it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:21,410][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:21,410][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 168.65it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:22,050][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:22,050][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 169.84it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:22,691][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:22,691][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 155.27it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:23,332][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:23,332][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.76it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:23,972][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:23,973][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.55it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:24,613][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:24,613][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.41it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:25,253][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:25,253][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.99it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:25,893][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:25,894][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.38it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:26,533][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:26,534][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.09it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:27,173][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:27,174][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.39it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:27,814][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:27,814][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 169.99it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:28,454][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:28,455][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 163.68it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:29,095][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:29,095][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.78it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:29,735][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:29,736][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 161.98it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:30,376][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:30,376][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.02it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:31,016][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:31,016][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.04it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:31,656][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:31,656][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.76it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:32,296][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:32,296][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.45it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:32,935][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:32,936][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.95it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:33,576][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:33,576][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.65it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:34,217][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:34,217][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 160.34it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:34,858][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:34,858][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 163.99it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:35,500][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:35,500][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 168.16it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:36,141][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:36,141][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 167.32it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:36,781][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:36,782][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.63it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:37,421][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:37,422][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.04it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:38,061][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:38,062][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.29it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:38,703][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:38,703][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 168.69it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:39,344][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:39,344][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 169.63it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:39,984][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:39,984][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 164.13it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:40,625][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:40,625][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 167.70it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:41,266][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:41,266][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 169.17it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:41,907][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:41,907][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.23it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:42,547][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:42,547][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.74it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:43,188][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:43,188][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.15it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:43,828][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:43,829][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 165.89it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:44,469][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:44,469][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 164.72it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:45,111][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:45,111][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 157.53it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:45,752][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:45,752][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 167.93it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:46,392][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:46,393][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.90it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:47,033][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:47,033][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.56it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:47,673][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:47,673][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.56it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:48,313][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:48,314][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 158.08it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:48,956][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:48,956][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 159.07it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:49,598][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:49,598][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.51it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:50,238][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:50,239][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 169.05it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:50,879][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:50,879][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.15it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:51,519][semstamp][INFO] - Candidate text: 4.
[2024-05-24 00:12:51,519][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.98it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.18it/s]
[2024-05-24 00:12:51,534][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:12:51,534][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-24 00:12:51,535][semstamp][INFO] - WARNING: desired semantic signature can't be sampled after max_trials 100
[2024-05-24 00:12:51,535][semstamp][INFO] - CONTEXT: Panicked investors who participated in the mammoth stock sell-off should get back into the market immediately because a lengthy hiatus often results in missing out on gains. Here are  few tips for novice investors to navigate the volatile markets:
1. **Diversification is key**: Spread your investments across asset classes, sectors, and geographies to minimize risk.
2. **Start with a solid foundation**: Allocate a portion of your portfolio to low-risk investments like bonds, CDs, or money market funds.
3. **Set clear goals and timelines**: Define your investment objectives and horizons to avoid emotional decision-making.

[2024-05-24 00:12:51,535][semstamp][INFO] - NOTE: use regular (non-filtered-by-sig) continuation: 4.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:55,965][semstamp][INFO] - Candidate text:  **Stay informed but not obsessed**: Keep an eye on market developments without getting caught up in short-term volatility.

[2024-05-24 00:12:55,966][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 149.26it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 169.20it/s]
[2024-05-24 00:12:55,983][semstamp][INFO] - LSH Candidate: 7
[2024-05-24 00:12:55,983][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:12:58,017][semstamp][INFO] - Candidate text:  **Invest regularly**: Adopt a dollar-cost averaging strategy to invest fixed amounts at regular intervals, regardless of market conditions.

[2024-05-24 00:12:58,017][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 160.77it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 169.49it/s]
[2024-05-24 00:12:58,033][semstamp][INFO] - LSH Candidate: 6
[2024-05-24 00:12:58,033][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:01,839][semstamp][INFO] - Candidate text:  **Adopt a dollar-cost averaging strategy**: Invest a fixed amount of money at regular intervals, regardless of market conditions, to reduce timing risks.

[2024-05-24 00:13:01,839][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 158.98it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 167.27it/s]
[2024-05-24 00:13:01,855][semstamp][INFO] - LSH Candidate: 6
[2024-05-24 00:13:01,855][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:03,823][semstamp][INFO] - Candidate text:  **Invest regularly**: Adopt a disciplined approach by investing a fixed amount at regular intervals, regardless of market conditions.

[2024-05-24 00:13:03,823][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 155.71it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 165.84it/s]
[2024-05-24 00:13:03,840][semstamp][INFO] - LSH Candidate: 7
[2024-05-24 00:13:03,840][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:05,875][semstamp][INFO] - Candidate text:  **Invest regularly**: Dollar-cost averaging can help you ride out market fluctuations by investing a fixed amount at regular intervals.

[2024-05-24 00:13:05,875][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 162.63it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.53it/s]
[2024-05-24 00:13:05,891][semstamp][INFO] - LSH Candidate: 6
[2024-05-24 00:13:05,891][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:07,993][semstamp][INFO] - Candidate text:  **Invest regularly**: Take advantage of dollar-cost averaging by investing a fixed amount at regular intervals, regardless of market conditions.

[2024-05-24 00:13:07,993][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 158.05it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 166.22it/s]
[2024-05-24 00:13:08,009][semstamp][INFO] - LSH Candidate: 6
[2024-05-24 00:13:08,009][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:10,243][semstamp][INFO] - Candidate text:  **Dollar-cost average**: Invest a fixed amount of money at regular intervals, regardless of market conditions, to reduce timing risks.

[2024-05-24 00:13:10,244][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 164.03it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.97it/s]
[2024-05-24 00:13:10,259][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:13:10,259][semstamp][INFO] - Candidate text falls within the semantic partition.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:10,963][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:10,963][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.06it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 179.28it/s]
[2024-05-24 00:13:10,977][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:10,977][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:11,679][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:11,679][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.54it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 179.21it/s]
[2024-05-24 00:13:11,693][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:11,694][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:12,396][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:12,396][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.28it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.82it/s]
[2024-05-24 00:13:12,410][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:12,410][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:13,113][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:13,113][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 167.88it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.49it/s]
[2024-05-24 00:13:13,128][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:13,129][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:13,830][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:13,831][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.56it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.87it/s]
[2024-05-24 00:13:13,845][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:13,846][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:14,547][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:14,548][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.10it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.70it/s]
[2024-05-24 00:13:14,562][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:14,563][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:15,265][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:15,265][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 167.74it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.16it/s]
[2024-05-24 00:13:15,280][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:15,280][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:15,982][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:15,982][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.59it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.42it/s]
[2024-05-24 00:13:15,997][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:15,997][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:16,699][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:16,699][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.73it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.71it/s]
[2024-05-24 00:13:16,714][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:16,714][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:17,416][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:17,417][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.34it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.68it/s]
[2024-05-24 00:13:17,431][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:17,431][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:18,135][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:18,135][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.14it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 179.38it/s]
[2024-05-24 00:13:18,150][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:18,150][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:18,852][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:18,852][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.79it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.75it/s]
[2024-05-24 00:13:18,867][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:18,867][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:19,569][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:19,569][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.43it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.48it/s]
[2024-05-24 00:13:19,584][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:19,584][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:20,287][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:20,287][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.41it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.78it/s]
[2024-05-24 00:13:20,302][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:20,303][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:21,006][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:21,006][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.60it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.02it/s]
[2024-05-24 00:13:21,020][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:21,021][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:21,723][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:21,723][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.71it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.59it/s]
[2024-05-24 00:13:21,738][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:21,738][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:22,440][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:22,440][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.33it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.76it/s]
[2024-05-24 00:13:22,454][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:22,455][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:23,157][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:23,157][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.51it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.82it/s]
[2024-05-24 00:13:23,171][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:23,172][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:23,874][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:23,874][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.76it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.22it/s]
[2024-05-24 00:13:23,888][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:23,889][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:24,591][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:24,591][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.62it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.13it/s]
[2024-05-24 00:13:24,606][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:24,606][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:25,309][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:25,310][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.35it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.53it/s]
[2024-05-24 00:13:25,324][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:25,324][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:26,027][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:26,027][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.16it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 179.80it/s]
[2024-05-24 00:13:26,041][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:26,042][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:26,744][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:26,744][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.56it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.49it/s]
[2024-05-24 00:13:26,759][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:26,759][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:27,461][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:27,461][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.70it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.73it/s]
[2024-05-24 00:13:27,476][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:27,476][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:28,178][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:28,178][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 168.92it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.58it/s]
[2024-05-24 00:13:28,193][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:28,193][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:28,896][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:28,896][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.64it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.69it/s]
[2024-05-24 00:13:28,911][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:28,911][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:29,613][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:29,613][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.50it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.19it/s]
[2024-05-24 00:13:29,628][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:29,628][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:30,330][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:30,330][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.89it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.54it/s]
[2024-05-24 00:13:30,345][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:30,345][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:31,048][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:31,049][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 160.26it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.20it/s]
[2024-05-24 00:13:31,064][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:31,064][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:31,767][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:31,767][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.92it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 180.01it/s]
[2024-05-24 00:13:31,781][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:31,782][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:32,484][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:32,484][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.54it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 180.38it/s]
[2024-05-24 00:13:32,499][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:32,499][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:33,201][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:33,201][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.71it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.23it/s]
[2024-05-24 00:13:33,216][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:33,216][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:33,918][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:33,918][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.54it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.74it/s]
[2024-05-24 00:13:33,933][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:33,933][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:34,635][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:34,636][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.24it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.85it/s]
[2024-05-24 00:13:34,651][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:34,651][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:35,353][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:35,353][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.80it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.50it/s]
[2024-05-24 00:13:35,367][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:35,368][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:36,070][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:36,070][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.53it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.16it/s]
[2024-05-24 00:13:36,085][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:36,085][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:36,788][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:36,788][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.89it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.77it/s]
[2024-05-24 00:13:36,802][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:36,803][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:37,506][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:37,506][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.06it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.50it/s]
[2024-05-24 00:13:37,520][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:37,521][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:38,223][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:38,223][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.40it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.16it/s]
[2024-05-24 00:13:38,238][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:38,238][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:38,940][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:38,941][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.72it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.33it/s]
[2024-05-24 00:13:38,956][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:38,956][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:39,658][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:39,658][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 168.22it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.30it/s]
[2024-05-24 00:13:39,673][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:39,673][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:40,375][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:40,375][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.47it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.97it/s]
[2024-05-24 00:13:40,390][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:40,390][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:41,093][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:41,093][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.00it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.80it/s]
[2024-05-24 00:13:41,108][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:41,108][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:41,810][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:41,810][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.16it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.39it/s]
[2024-05-24 00:13:41,825][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:41,825][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:42,527][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:42,528][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.36it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.49it/s]
[2024-05-24 00:13:42,542][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:42,543][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:43,245][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:43,245][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.44it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.03it/s]
[2024-05-24 00:13:43,260][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:43,260][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:43,963][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:43,964][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.68it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.29it/s]
[2024-05-24 00:13:43,978][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:43,978][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:44,681][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:44,681][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.25it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.69it/s]
[2024-05-24 00:13:44,696][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:44,696][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:45,399][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:45,399][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.15it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.09it/s]
[2024-05-24 00:13:45,414][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:45,414][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:46,116][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:46,116][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.62it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.73it/s]
[2024-05-24 00:13:46,131][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:46,132][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:46,834][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:46,834][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.36it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.72it/s]
[2024-05-24 00:13:46,849][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:46,849][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:47,551][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:47,552][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 169.73it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.24it/s]
[2024-05-24 00:13:47,567][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:47,567][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:48,269][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:48,269][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 165.01it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.50it/s]
[2024-05-24 00:13:48,285][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:48,285][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:48,987][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:48,987][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.30it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.57it/s]
[2024-05-24 00:13:49,002][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:49,002][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:49,704][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:49,705][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.44it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.70it/s]
[2024-05-24 00:13:49,719][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:49,719][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:50,423][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:50,423][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 161.07it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.88it/s]
[2024-05-24 00:13:50,439][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:50,439][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:51,141][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:51,142][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.43it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.25it/s]
[2024-05-24 00:13:51,157][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:51,157][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:51,859][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:51,859][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.99it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.55it/s]
[2024-05-24 00:13:51,874][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:51,874][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:52,576][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:52,577][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.50it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.79it/s]
[2024-05-24 00:13:52,591][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:52,592][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:53,294][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:53,295][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.29it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 179.29it/s]
[2024-05-24 00:13:53,309][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:53,309][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:54,012][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:54,012][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.94it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.76it/s]
[2024-05-24 00:13:54,027][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:54,027][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:54,729][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:54,729][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.39it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.71it/s]
[2024-05-24 00:13:54,744][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:54,745][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:55,447][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:55,447][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.74it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.13it/s]
[2024-05-24 00:13:55,462][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:55,462][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:56,164][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:56,165][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.50it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.92it/s]
[2024-05-24 00:13:56,179][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:56,179][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:56,882][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:56,882][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.37it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.94it/s]
[2024-05-24 00:13:56,897][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:56,897][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:57,600][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:57,600][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.16it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.35it/s]
[2024-05-24 00:13:57,615][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:57,615][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:58,317][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:58,317][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.50it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.12it/s]
[2024-05-24 00:13:58,331][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:58,332][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:59,035][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:59,035][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 168.41it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.21it/s]
[2024-05-24 00:13:59,050][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:59,050][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:13:59,753][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:13:59,754][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.04it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.14it/s]
[2024-05-24 00:13:59,769][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:13:59,769][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:00,472][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:14:00,472][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.99it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.92it/s]
[2024-05-24 00:14:00,487][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:14:00,487][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:01,190][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:14:01,190][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.94it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.03it/s]
[2024-05-24 00:14:01,205][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:14:01,205][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:01,908][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:14:01,908][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 162.16it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.41it/s]
[2024-05-24 00:14:01,923][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:14:01,924][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:02,626][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:14:02,626][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.16it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.70it/s]
[2024-05-24 00:14:02,641][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:14:02,641][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:03,344][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:14:03,344][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.22it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 179.43it/s]
[2024-05-24 00:14:03,359][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:14:03,359][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:04,061][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:14:04,061][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.99it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.28it/s]
[2024-05-24 00:14:04,076][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:14:04,076][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:04,779][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:14:04,779][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.71it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.42it/s]
[2024-05-24 00:14:04,794][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:14:04,794][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:05,498][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:14:05,498][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.14it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.63it/s]
[2024-05-24 00:14:05,513][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:14:05,513][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:06,216][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:14:06,216][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.94it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.63it/s]
[2024-05-24 00:14:06,231][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:14:06,231][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:06,934][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:14:06,934][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.76it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.97it/s]
[2024-05-24 00:14:06,949][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:14:06,949][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:07,651][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:14:07,651][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.03it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.60it/s]
[2024-05-24 00:14:07,666][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:14:07,666][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:08,368][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:14:08,368][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.70it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.47it/s]
[2024-05-24 00:14:08,383][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:14:08,383][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:09,086][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:14:09,086][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.78it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.87it/s]
[2024-05-24 00:14:09,100][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:14:09,101][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:09,803][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:14:09,803][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.17it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.75it/s]
[2024-05-24 00:14:09,818][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:14:09,818][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:10,520][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:14:10,521][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 169.95it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.81it/s]
[2024-05-24 00:14:10,536][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:14:10,536][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:11,238][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:14:11,238][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.18it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.73it/s]
[2024-05-24 00:14:11,253][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:14:11,253][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:11,956][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:14:11,956][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.46it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.33it/s]
[2024-05-24 00:14:11,971][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:14:11,971][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:12,674][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:14:12,674][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.74it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.33it/s]
[2024-05-24 00:14:12,689][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:14:12,689][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:13,392][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:14:13,392][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 169.94it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.40it/s]
[2024-05-24 00:14:13,407][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:14:13,407][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:14,110][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:14:14,110][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.78it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.51it/s]
[2024-05-24 00:14:14,125][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:14:14,125][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:14,827][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:14:14,827][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.67it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.43it/s]
[2024-05-24 00:14:14,842][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:14:14,842][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:15,544][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:14:15,544][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.50it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.27it/s]
[2024-05-24 00:14:15,559][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:14:15,559][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:16,261][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:14:16,261][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.45it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.67it/s]
[2024-05-24 00:14:16,276][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:14:16,276][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:16,978][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:14:16,979][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.71it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.93it/s]
[2024-05-24 00:14:16,993][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:14:16,993][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:17,695][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:14:17,696][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.99it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.74it/s]
[2024-05-24 00:14:17,711][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:14:17,711][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:18,413][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:14:18,414][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 169.95it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.92it/s]
[2024-05-24 00:14:18,429][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:14:18,429][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:19,131][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:14:19,132][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.39it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.73it/s]
[2024-05-24 00:14:19,147][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:14:19,147][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:19,849][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:14:19,849][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.15it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.61it/s]
[2024-05-24 00:14:19,864][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:14:19,864][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:20,567][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:14:20,567][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 160.14it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.40it/s]
[2024-05-24 00:14:20,583][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:14:20,583][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:21,286][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:14:21,286][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.59it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.26it/s]
[2024-05-24 00:14:21,301][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:14:21,301][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:22,003][semstamp][INFO] - Candidate text: 5.
[2024-05-24 00:14:22,003][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.13it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.90it/s]
[2024-05-24 00:14:22,018][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:14:22,018][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-24 00:14:22,018][semstamp][INFO] - WARNING: desired semantic signature can't be sampled after max_trials 100
[2024-05-24 00:14:22,018][semstamp][INFO] - CONTEXT: Panicked investors who participated in the mammoth stock sell-off should get back into the market immediately because a lengthy hiatus often results in missing out on gains. Here are  few tips for novice investors to navigate the volatile markets:
1. **Diversification is key**: Spread your investments across asset classes, sectors, and geographies to minimize risk.
2. **Start with a solid foundation**: Allocate a portion of your portfolio to low-risk investments like bonds, CDs, or money market funds.
3. **Set clear goals and timelines**: Define your investment objectives and horizons to avoid emotional decision-making.
4. **Dollar-cost average**: Invest a fixed amount of money at regular intervals, regardless of market conditions, to reduce timing risks.

[2024-05-24 00:14:22,019][semstamp][INFO] - NOTE: use regular (non-filtered-by-sig) continuation: 5.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:26,632][semstamp][INFO] - Candidate text:  **Stay informed but avoid emotional responses**: Stay up-to-date with market news, but avoid making impulsive decisions based on short-term market fluctuations.

[2024-05-24 00:14:26,633][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 153.03it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 169.52it/s]
[2024-05-24 00:14:26,649][semstamp][INFO] - LSH Candidate: 6
[2024-05-24 00:14:26,649][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:28,694][semstamp][INFO] - Candidate text:  **Educate yourself**: Continuously learn about personal finance, investing, and the economy to make informed decisions.

[2024-05-24 00:14:28,694][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 154.25it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 166.74it/s]
[2024-05-24 00:14:28,711][semstamp][INFO] - LSH Candidate: 6
[2024-05-24 00:14:28,711][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:31,158][semstamp][INFO] - Candidate text:  **Stay informed but don't overreact**: Keep up with market news, but avoid making impulsive decisions based on short-term market fluctuations.

[2024-05-24 00:14:31,158][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 155.47it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 169.69it/s]
[2024-05-24 00:14:31,174][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:14:31,174][semstamp][INFO] - Candidate text falls within the semantic partition.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:32,766][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:14:32,767][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 166.11it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.24it/s]
[2024-05-24 00:14:32,782][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:14:32,782][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:33,522][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:14:33,523][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 169.17it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 179.05it/s]
[2024-05-24 00:14:33,538][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:14:33,538][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:34,278][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:14:34,279][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 165.93it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.24it/s]
[2024-05-24 00:14:34,294][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:14:34,294][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:35,034][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:14:35,035][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 164.48it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.85it/s]
[2024-05-24 00:14:35,050][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:14:35,050][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:35,790][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:14:35,790][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.65it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.68it/s]
[2024-05-24 00:14:35,805][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:14:35,805][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:36,545][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:14:36,545][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.66it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.96it/s]
[2024-05-24 00:14:36,560][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:14:36,560][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:37,301][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:14:37,301][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 140.44it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 155.99it/s]
[2024-05-24 00:14:37,318][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:14:37,318][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:38,059][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:14:38,059][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 163.44it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.24it/s]
[2024-05-24 00:14:38,075][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:14:38,075][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:38,815][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:14:38,815][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 152.41it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 160.10it/s]
[2024-05-24 00:14:38,832][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:14:38,832][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:39,572][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:14:39,572][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.11it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.79it/s]
[2024-05-24 00:14:39,587][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:14:39,588][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:40,327][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:14:40,328][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.05it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.67it/s]
[2024-05-24 00:14:40,343][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:14:40,343][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:41,083][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:14:41,083][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 153.17it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 164.22it/s]
[2024-05-24 00:14:41,099][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:14:41,099][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:41,839][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:14:41,839][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.60it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.17it/s]
[2024-05-24 00:14:41,854][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:14:41,854][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:42,594][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:14:42,594][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 165.62it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 165.89it/s]
[2024-05-24 00:14:42,610][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:14:42,610][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:43,352][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:14:43,353][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 156.23it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 155.01it/s]
[2024-05-24 00:14:43,370][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:14:43,370][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:44,112][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:14:44,112][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 160.92it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 159.62it/s]
[2024-05-24 00:14:44,129][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:14:44,129][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:44,871][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:14:44,871][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 161.67it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.34it/s]
[2024-05-24 00:14:44,887][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:14:44,888][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:45,630][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:14:45,630][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 160.29it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.22it/s]
[2024-05-24 00:14:45,646][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:14:45,647][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:46,387][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:14:46,387][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 152.73it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 158.17it/s]
[2024-05-24 00:14:46,404][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:14:46,404][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:47,146][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:14:47,146][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 157.15it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 160.21it/s]
[2024-05-24 00:14:47,163][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:14:47,163][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:47,904][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:14:47,905][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 164.42it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.22it/s]
[2024-05-24 00:14:47,920][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:14:47,920][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:48,661][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:14:48,661][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 169.63it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 161.57it/s]
[2024-05-24 00:14:48,677][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:14:48,677][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:49,417][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:14:49,418][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 168.29it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.59it/s]
[2024-05-24 00:14:49,433][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:14:49,433][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:50,173][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:14:50,173][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.84it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.77it/s]
[2024-05-24 00:14:50,188][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:14:50,188][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:50,928][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:14:50,929][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.36it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.42it/s]
[2024-05-24 00:14:50,943][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:14:50,944][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:51,684][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:14:51,685][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.54it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.70it/s]
[2024-05-24 00:14:51,699][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:14:51,699][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:52,440][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:14:52,440][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.11it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.99it/s]
[2024-05-24 00:14:52,455][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:14:52,455][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:53,197][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:14:53,197][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 161.89it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.79it/s]
[2024-05-24 00:14:53,213][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:14:53,213][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:53,955][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:14:53,955][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.17it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.62it/s]
[2024-05-24 00:14:53,970][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:14:53,970][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:54,710][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:14:54,710][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.61it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.60it/s]
[2024-05-24 00:14:54,725][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:14:54,725][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:55,465][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:14:55,466][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.22it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.74it/s]
[2024-05-24 00:14:55,480][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:14:55,480][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:56,221][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:14:56,221][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.50it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.20it/s]
[2024-05-24 00:14:56,236][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:14:56,236][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:56,976][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:14:56,977][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.01it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.82it/s]
[2024-05-24 00:14:56,991][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:14:56,992][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:57,731][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:14:57,731][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.31it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.37it/s]
[2024-05-24 00:14:57,746][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:14:57,746][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:58,487][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:14:58,487][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 164.21it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.88it/s]
[2024-05-24 00:14:58,502][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:14:58,503][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:59,243][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:14:59,243][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.85it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.04it/s]
[2024-05-24 00:14:59,258][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:14:59,258][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:14:59,998][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:14:59,999][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.28it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.54it/s]
[2024-05-24 00:15:00,014][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:00,014][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:00,755][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:00,755][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.55it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.71it/s]
[2024-05-24 00:15:00,770][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:00,770][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:01,510][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:01,511][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.44it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.12it/s]
[2024-05-24 00:15:01,526][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:01,526][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:02,267][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:02,267][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 157.44it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.44it/s]
[2024-05-24 00:15:02,283][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:02,283][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:03,024][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:03,024][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.32it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.87it/s]
[2024-05-24 00:15:03,039][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:03,039][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:03,780][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:03,781][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 157.47it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.04it/s]
[2024-05-24 00:15:03,797][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:03,797][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:04,539][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:04,539][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 166.76it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 166.53it/s]
[2024-05-24 00:15:04,554][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:04,555][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:05,296][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:05,297][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 163.88it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.40it/s]
[2024-05-24 00:15:05,312][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:05,312][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:06,055][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:06,055][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 160.54it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.11it/s]
[2024-05-24 00:15:06,071][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:06,071][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:06,812][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:06,812][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 164.51it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.14it/s]
[2024-05-24 00:15:06,827][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:06,827][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:07,567][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:07,567][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.96it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.88it/s]
[2024-05-24 00:15:07,582][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:07,582][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:08,322][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:08,323][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 167.19it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.25it/s]
[2024-05-24 00:15:08,338][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:08,338][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:09,079][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:09,079][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 163.22it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.88it/s]
[2024-05-24 00:15:09,095][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:09,095][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:09,836][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:09,837][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 160.75it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.91it/s]
[2024-05-24 00:15:09,852][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:09,853][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:10,594][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:10,594][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.97it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.45it/s]
[2024-05-24 00:15:10,609][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:10,609][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:11,350][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:11,350][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.67it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.36it/s]
[2024-05-24 00:15:11,365][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:11,365][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:12,105][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:12,105][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.43it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.30it/s]
[2024-05-24 00:15:12,120][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:12,120][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:12,860][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:12,860][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 169.10it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.85it/s]
[2024-05-24 00:15:12,875][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:12,876][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:13,616][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:13,616][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.63it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.47it/s]
[2024-05-24 00:15:13,631][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:13,631][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:14,372][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:14,373][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 156.52it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 169.92it/s]
[2024-05-24 00:15:14,389][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:14,389][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:15,131][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:15,131][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 154.51it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 169.01it/s]
[2024-05-24 00:15:15,148][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:15,148][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:15,888][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:15,889][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 164.87it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.22it/s]
[2024-05-24 00:15:15,904][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:15,904][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:16,644][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:16,644][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.03it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.84it/s]
[2024-05-24 00:15:16,659][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:16,659][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:17,399][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:17,399][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.22it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.14it/s]
[2024-05-24 00:15:17,414][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:17,414][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:18,154][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:18,154][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.69it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 178.08it/s]
[2024-05-24 00:15:18,169][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:18,169][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:18,910][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:18,910][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.25it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.80it/s]
[2024-05-24 00:15:18,925][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:18,925][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:19,664][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:19,664][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.88it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.17it/s]
[2024-05-24 00:15:19,679][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:19,679][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:20,419][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:20,419][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.41it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.28it/s]
[2024-05-24 00:15:20,434][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:20,434][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:21,175][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:21,175][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 168.06it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.82it/s]
[2024-05-24 00:15:21,190][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:21,190][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:21,932][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:21,932][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.47it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.87it/s]
[2024-05-24 00:15:21,947][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:21,947][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:22,688][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:22,688][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.56it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.52it/s]
[2024-05-24 00:15:22,703][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:22,703][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:23,443][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:23,443][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.14it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.84it/s]
[2024-05-24 00:15:23,458][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:23,458][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:24,197][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:24,197][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.39it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.21it/s]
[2024-05-24 00:15:24,212][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:24,212][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:24,953][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:24,953][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.46it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.18it/s]
[2024-05-24 00:15:24,968][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:24,968][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:25,709][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:25,710][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 162.64it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.71it/s]
[2024-05-24 00:15:25,725][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:25,725][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:26,465][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:26,466][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.50it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.41it/s]
[2024-05-24 00:15:26,480][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:26,480][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:27,221][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:27,221][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.63it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.94it/s]
[2024-05-24 00:15:27,236][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:27,236][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:27,978][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:27,978][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 161.06it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.74it/s]
[2024-05-24 00:15:27,994][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:27,994][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:28,735][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:28,735][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.38it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.20it/s]
[2024-05-24 00:15:28,750][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:28,751][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:29,492][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:29,492][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.52it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.85it/s]
[2024-05-24 00:15:29,507][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:29,507][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:30,248][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:30,248][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.25it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.60it/s]
[2024-05-24 00:15:30,263][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:30,263][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:31,004][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:31,004][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.53it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.89it/s]
[2024-05-24 00:15:31,019][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:31,019][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:31,760][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:31,760][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.29it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.53it/s]
[2024-05-24 00:15:31,775][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:31,775][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:32,517][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:32,517][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 167.59it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.25it/s]
[2024-05-24 00:15:32,532][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:32,532][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:33,273][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:33,273][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.10it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.91it/s]
[2024-05-24 00:15:33,288][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:33,288][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:34,028][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:34,028][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.57it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.45it/s]
[2024-05-24 00:15:34,043][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:34,043][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:34,783][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:34,784][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.35it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.18it/s]
[2024-05-24 00:15:34,798][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:34,799][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:35,538][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:35,539][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.13it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.12it/s]
[2024-05-24 00:15:35,553][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:35,553][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:36,293][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:36,294][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.29it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.58it/s]
[2024-05-24 00:15:36,308][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:36,309][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:37,050][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:37,050][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.34it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 165.04it/s]
[2024-05-24 00:15:37,065][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:37,065][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:37,807][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:37,807][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.05it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.83it/s]
[2024-05-24 00:15:37,822][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:37,822][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:38,564][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:38,564][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 166.70it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.74it/s]
[2024-05-24 00:15:38,579][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:38,579][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:39,320][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:39,320][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.11it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.06it/s]
[2024-05-24 00:15:39,335][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:39,335][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:40,075][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:40,076][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 169.82it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.69it/s]
[2024-05-24 00:15:40,091][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:40,091][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:40,833][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:40,833][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 160.63it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.29it/s]
[2024-05-24 00:15:40,849][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:40,849][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:41,591][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:41,591][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.17it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.51it/s]
[2024-05-24 00:15:41,606][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:41,606][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:42,346][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:42,346][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.63it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.57it/s]
[2024-05-24 00:15:42,361][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:42,361][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:43,101][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:43,102][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.55it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.39it/s]
[2024-05-24 00:15:43,116][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:43,117][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:43,858][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:43,858][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 160.28it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.14it/s]
[2024-05-24 00:15:43,874][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:43,874][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:44,615][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:44,615][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 162.37it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.62it/s]
[2024-05-24 00:15:44,631][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:44,631][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:45,373][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:45,373][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 160.81it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.71it/s]
[2024-05-24 00:15:45,389][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:45,389][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:46,131][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:46,131][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.03it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 176.53it/s]
[2024-05-24 00:15:46,146][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:46,146][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:46,887][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:46,888][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.98it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 177.64it/s]
[2024-05-24 00:15:46,902][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:46,902][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:47,644][semstamp][INFO] - Candidate text: 6.
[2024-05-24 00:15:47,645][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.51it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 175.46it/s]
[2024-05-24 00:15:47,659][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:15:47,660][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
[2024-05-24 00:15:47,660][semstamp][INFO] - WARNING: desired semantic signature can't be sampled after max_trials 100
[2024-05-24 00:15:47,660][semstamp][INFO] - CONTEXT: Panicked investors who participated in the mammoth stock sell-off should get back into the market immediately because a lengthy hiatus often results in missing out on gains. Here are  few tips for novice investors to navigate the volatile markets:
1. **Diversification is key**: Spread your investments across asset classes, sectors, and geographies to minimize risk.
2. **Start with a solid foundation**: Allocate a portion of your portfolio to low-risk investments like bonds, CDs, or money market funds.
3. **Set clear goals and timelines**: Define your investment objectives and horizons to avoid emotional decision-making.
4. **Dollar-cost average**: Invest a fixed amount of money at regular intervals, regardless of market conditions, to reduce timing risks.
5. **Stay informed but don't overreact**: Keep up with market news, but avoid making impulsive decisions based on short-term market fluctuations.

[2024-05-24 00:15:47,660][semstamp][INFO] - NOTE: use regular (non-filtered-by-sig) continuation: 6.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:51,487][semstamp][INFO] - Candidate text:  **Consider seeking professional guidance**: If you're new to investing or lack confidence in your abilities, consult a financial advisor or investment expert.


[2024-05-24 00:15:51,487][semstamp][INFO] - Accept Mask: tensor([6, 0], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 156.94it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 169.26it/s]
[2024-05-24 00:15:51,503][semstamp][INFO] - LSH Candidate: 1
[2024-05-24 00:15:51,503][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:53,725][semstamp][INFO] - Candidate text:  **Consult a financial advisor (if needed)**: If you're unsure about managing your investments, consider seeking professional guidance.


[2024-05-24 00:15:53,726][semstamp][INFO] - Accept Mask: tensor([6, 0], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 160.44it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.49it/s]
[2024-05-24 00:15:53,741][semstamp][INFO] - LSH Candidate: 5
[2024-05-24 00:15:53,741][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:56,031][semstamp][INFO] - Candidate text:  **Monitor and adjust**: Regularly review your portfolio and rebalance it as needed to ensure it remains aligned with your goals.


[2024-05-24 00:15:56,031][semstamp][INFO] - Accept Mask: tensor([6, 0], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 164.08it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:15:58,263][semstamp][INFO] - Candidate text:  **Rebalance periodically**: Regularly review your portfolio and rebalance it to ensure it remains aligned with your investment strategy.


[2024-05-24 00:15:58,263][semstamp][INFO] - Accept Mask: tensor([6, 0], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 158.17it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.56it/s]
[2024-05-24 00:15:58,279][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:15:58,279][semstamp][INFO] - Candidate text falls within the semantic partition.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:16:00,545][semstamp][INFO] - Candidate text: Remember, investing in the stock market involves risks, and there will be times when the market experiences significant downturns.
[2024-05-24 00:16:00,545][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 166.52it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 174.20it/s]
[2024-05-24 00:16:00,560][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:16:00,560][semstamp][INFO] - Candidate text falls within the semantic partition.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:16:02,769][semstamp][INFO] - Candidate text:  However, history has shown that stocks have consistently provided higher returns over the long term compared to other asset classes.
[2024-05-24 00:16:02,769][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 152.93it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 168.88it/s]
[2024-05-24 00:16:02,785][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:16:02,785][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:16:04,791][semstamp][INFO] - Candidate text:  However, by adopting a disciplined approach, you can increase your chances of achieving long-term success.


[2024-05-24 00:16:04,792][semstamp][INFO] - Accept Mask: tensor([5, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 162.49it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.22it/s]
[2024-05-24 00:16:04,807][semstamp][INFO] - LSH Candidate: 5
[2024-05-24 00:16:04,807][semstamp][INFO] - Candidate text falls within the semantic partition.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:16:06,009][semstamp][INFO] - Candidate text: ---

**What do you think?
[2024-05-24 00:16:06,009][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 154.81it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:16:07,150][semstamp][INFO] - Candidate text: ---

What do you think?
[2024-05-24 00:16:07,150][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 161.29it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.38it/s]
[2024-05-24 00:16:07,165][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:16:07,166][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:16:08,298][semstamp][INFO] - Candidate text: ---

What do you think?
[2024-05-24 00:16:08,298][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 166.90it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.86it/s]
[2024-05-24 00:16:08,313][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:16:08,313][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:16:10,053][semstamp][INFO] - Candidate text: ---

Do you have any questions about navigating the stock market?
[2024-05-24 00:16:10,053][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 163.33it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.12it/s]
[2024-05-24 00:16:10,069][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:16:10,069][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:16:11,473][semstamp][INFO] - Candidate text: ---

**What do you think about this article?
[2024-05-24 00:16:11,474][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 160.85it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.08it/s]
[2024-05-24 00:16:11,489][semstamp][INFO] - LSH Candidate: 3
[2024-05-24 00:16:11,489][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:16:13,097][semstamp][INFO] - Candidate text: ---

Investing in stocks can be intimidating, especially for beginners.
[2024-05-24 00:16:13,098][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 164.32it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 166.17it/s]
[2024-05-24 00:16:13,113][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:16:13,113][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:16:16,002][semstamp][INFO] - Candidate text: ---

Disclaimer: This article is intended for educational purposes only and should not be considered personalized investment advice.
[2024-05-24 00:16:16,002][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 153.32it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:16:17,620][semstamp][INFO] - Candidate text: **Now, go ahead and take control of your financial future!
[2024-05-24 00:16:17,620][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 157.37it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 170.00it/s]
[2024-05-24 00:16:17,636][semstamp][INFO] - LSH Candidate: 6
[2024-05-24 00:16:17,636][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:16:19,652][semstamp][INFO] - Candidate text: **Investing in stocks: A beginner's guide**

Are you new to stock market investing?
[2024-05-24 00:16:19,652][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 164.20it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 173.31it/s]
[2024-05-24 00:16:19,668][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:16:19,668][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:16:23,250][semstamp][INFO] - Candidate text: ---

**Additional resources:**

* **"The Little Book of Common Sense Investing" by John C. Bogle**: A seminal book that provides an excellent introduction to index fund investing and long-term wealth creation.

[2024-05-24 00:16:23,250][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 138.93it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 165.08it/s]
[2024-05-24 00:16:23,267][semstamp][INFO] - LSH Candidate: 6
[2024-05-24 00:16:23,267][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:16:24,876][semstamp][INFO] - Candidate text: **Disclaimer:** This article is not intended as personalized investment advice.
[2024-05-24 00:16:24,876][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 162.14it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.79it/s]
[2024-05-24 00:16:24,891][semstamp][INFO] - LSH Candidate: 0
[2024-05-24 00:16:24,891][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:16:27,049][semstamp][INFO] - Candidate text: Disclaimer: The information provided in this article is for general guidance only and does not constitute personalized investment advice.
[2024-05-24 00:16:27,049][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 157.27it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:16:28,803][semstamp][INFO] - Candidate text: ---

### Market Insights

#### US Stocks: A Bumpy Ride Ahead?


[2024-05-24 00:16:28,804][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 154.90it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 168.26it/s]
[2024-05-24 00:16:28,820][semstamp][INFO] - LSH Candidate: 2
[2024-05-24 00:16:28,820][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:16:31,721][semstamp][INFO] - Candidate text: ---

**Disclaimer:**

The views expressed in this article are solely those of the author and do not reflect the opinions or views of any financial institution or organization.
[2024-05-24 00:16:31,722][semstamp][INFO] - Accept Mask: tensor([1, 4], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 153.87it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 168.47it/s]
[2024-05-24 00:16:31,738][semstamp][INFO] - LSH Candidate: 1
[2024-05-24 00:16:31,738][semstamp][INFO] - Candidate text falls within the semantic partition.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:16:34,254][semstamp][INFO] - Candidate text:  The information provided is for general guidance only and does not constitute personalized investment advice.
[2024-05-24 00:16:34,254][semstamp][INFO] - Accept Mask: tensor([6, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 152.72it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 168.72it/s]
[2024-05-24 00:16:34,271][semstamp][INFO] - LSH Candidate: 7
[2024-05-24 00:16:34,271][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:16:36,378][semstamp][INFO] - Candidate text:  The content is for general information purposes only and should not be considered as personalized investment advice.
[2024-05-24 00:16:36,378][semstamp][INFO] - Accept Mask: tensor([6, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 161.21it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:16:38,427][semstamp][INFO] - Candidate text:  This article is intended for general information purposes only and does not constitute personalized investment advice.
[2024-05-24 00:16:38,427][semstamp][INFO] - Accept Mask: tensor([6, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 159.79it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 169.71it/s]
[2024-05-24 00:16:38,443][semstamp][INFO] - LSH Candidate: 7
[2024-05-24 00:16:38,443][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:16:40,347][semstamp][INFO] - Candidate text:  The information provided is general in nature and does not constitute personal investment advice.
[2024-05-24 00:16:40,348][semstamp][INFO] - Accept Mask: tensor([6, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 157.78it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:16:42,261][semstamp][INFO] - Candidate text:  The information provided is for educational purposes only and does not constitute investment advice.
[2024-05-24 00:16:42,261][semstamp][INFO] - Accept Mask: tensor([6, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 157.48it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 166.53it/s]
[2024-05-24 00:16:42,277][semstamp][INFO] - LSH Candidate: 7
[2024-05-24 00:16:42,277][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:16:44,249][semstamp][INFO] - Candidate text:  This content is for educational purposes only and should not be considered as investment advice.
[2024-05-24 00:16:44,249][semstamp][INFO] - Accept Mask: tensor([6, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 161.03it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 167.57it/s]
[2024-05-24 00:16:44,265][semstamp][INFO] - LSH Candidate: 7
[2024-05-24 00:16:44,265][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:16:46,308][semstamp][INFO] - Candidate text:  The information provided is for educational purposes only and is not intended as personalized investment advice.
[2024-05-24 00:16:46,308][semstamp][INFO] - Accept Mask: tensor([6, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 154.52it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:16:48,493][semstamp][INFO] - Candidate text:  This article is intended for general informational purposes only and should not be considered as personalized investment advice.
[2024-05-24 00:16:48,493][semstamp][INFO] - Accept Mask: tensor([6, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 158.36it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 165.42it/s]
[2024-05-24 00:16:48,509][semstamp][INFO] - LSH Candidate: 7
[2024-05-24 00:16:48,510][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:16:50,619][semstamp][INFO] - Candidate text:  The information provided is for educational purposes only and should not be considered as personalized investment advice.
[2024-05-24 00:16:50,619][semstamp][INFO] - Accept Mask: tensor([6, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 158.11it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 167.12it/s]
[2024-05-24 00:16:50,635][semstamp][INFO] - LSH Candidate: 7
[2024-05-24 00:16:50,635][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:16:52,813][semstamp][INFO] - Candidate text:  This article is intended for general information purposes only and should not be considered as personalized investment advice.
[2024-05-24 00:16:52,814][semstamp][INFO] - Accept Mask: tensor([6, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 155.91it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 169.05it/s]
[2024-05-24 00:16:52,830][semstamp][INFO] - LSH Candidate: 7
[2024-05-24 00:16:52,830][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-24 00:16:55,009][semstamp][INFO] - Candidate text:  This content is intended for general information purposes only and should not be construed as personalized investment advice.
[2024-05-24 00:16:55,009][semstamp][INFO] - Accept Mask: tensor([6, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 155.58it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 167.53it/s]
[2024-05-24 00:16:55,025][semstamp][INFO] - LSH Candidate: 6
[2024-05-24 00:16:55,025][semstamp][INFO] - Candidate text falls within the semantic partition.
[2024-05-24 00:16:55,026][semstamp][INFO] - Prompt: Panicked investors who participated in the mammoth stock sell-off should get back into the market immediately because a lengthy hiatus often results in missing out on gains.
[2024-05-24 00:16:55,026][semstamp][INFO] - Response: ("Panicked investors who participated in the mammoth stock sell-off should get back into the market immediately because a lengthy hiatus often results in missing out on gains. Here are  few tips for novice investors to navigate the volatile markets:\n1. **Diversification is key**: Spread your investments across asset classes, sectors, and geographies to minimize risk.\n2. **Start with a solid foundation**: Allocate a portion of your portfolio to low-risk investments like bonds, CDs, or money market funds.\n3. **Set clear goals and timelines**: Define your investment objectives and horizons to avoid emotional decision-making.\n4. **Dollar-cost average**: Invest a fixed amount of money at regular intervals, regardless of market conditions, to reduce timing risks.\n5. **Stay informed but don't overreact**: Keep up with market news, but avoid making impulsive decisions based on short-term market fluctuations.\n6. **Rebalance periodically**: Regularly review your portfolio and rebalance it to ensure it remains aligned with your investment strategy.\n\nRemember, investing in the stock market involves risks, and there will be times when the market experiences significant downturns. However, by adopting a disciplined approach, you can increase your chances of achieving long-term success.\n\n---\n\n**Disclaimer:**\n\nThe views expressed in this article are solely those of the author and do not reflect the opinions or views of any financial institution or organization. This content is intended for general information purposes only and should not be construed as personalized investment advice.", 454)
[2024-05-24 00:16:55,026][watermarker][INFO] - Received completion: Panicked investors who participated in the mammoth stock sell-off should get back into the market immediately because a lengthy hiatus often results in missing out on gains. Here are  few tips for novice investors to navigate the volatile markets:
1. **Diversification is key**: Spread your investments across asset classes, sectors, and geographies to minimize risk.
2. **Start with a solid foundation**: Allocate a portion of your portfolio to low-risk investments like bonds, CDs, or money market funds.
3. **Set clear goals and timelines**: Define your investment objectives and horizons to avoid emotional decision-making.
4. **Dollar-cost average**: Invest a fixed amount of money at regular intervals, regardless of market conditions, to reduce timing risks.
5. **Stay informed but don't overreact**: Keep up with market news, but avoid making impulsive decisions based on short-term market fluctuations.
6. **Rebalance periodically**: Regularly review your portfolio and rebalance it to ensure it remains aligned with your investment strategy.

Remember, investing in the stock market involves risks, and there will be times when the market experiences significant downturns. However, by adopting a disciplined approach, you can increase your chances of achieving long-term success.

---

**Disclaimer:**

The views expressed in this article are solely those of the author and do not reflect the opinions or views of any financial institution or organization. This content is intended for general information purposes only and should not be construed as personalized investment advice.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 162.54it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 167.18it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 166.71it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.26it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 166.19it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.61it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 167.07it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 171.93it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 166.37it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.19it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 166.51it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.93it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 167.28it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 166.88it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 166.73it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 166.52it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 167.71it/s]
n_watermark: 12, n_test_sent: 16
zscore: 4.618802153517007
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 165.47it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 168.69it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 168.15it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.70it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 167.74it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.01it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 166.72it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.39it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 148.83it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.24it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 167.66it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 172.98it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 168.03it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 168.27it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 169.14it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 167.50it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 167.64it/s]
n_watermark: 12, n_test_sent: 16
zscore: 4.618802153517007
[2024-05-24 00:16:55,284][__main__][INFO] - Watermarked Text: Panicked investors who participated in the mammoth stock sell-off should get back into the market immediately because a lengthy hiatus often results in missing out on gains. Here are  few tips for novice investors to navigate the volatile markets:
1. **Diversification is key**: Spread your investments across asset classes, sectors, and geographies to minimize risk.
2. **Start with a solid foundation**: Allocate a portion of your portfolio to low-risk investments like bonds, CDs, or money market funds.
3. **Set clear goals and timelines**: Define your investment objectives and horizons to avoid emotional decision-making.
4. **Dollar-cost average**: Invest a fixed amount of money at regular intervals, regardless of market conditions, to reduce timing risks.
5. **Stay informed but don't overreact**: Keep up with market news, but avoid making impulsive decisions based on short-term market fluctuations.
6. **Rebalance periodically**: Regularly review your portfolio and rebalance it to ensure it remains aligned with your investment strategy.

Remember, investing in the stock market involves risks, and there will be times when the market experiences significant downturns. However, by adopting a disciplined approach, you can increase your chances of achieving long-term success.

---

**Disclaimer:**

The views expressed in this article are solely those of the author and do not reflect the opinions or views of any financial institution or organization. This content is intended for general information purposes only and should not be construed as personalized investment advice.
[2024-05-24 00:16:55,284][__main__][INFO] - Is Watermark Detected?: True
[2024-05-24 00:16:55,284][__main__][INFO] - Score: 4.618802153517007
[2024-05-24 00:16:55,284][__main__][INFO] - Time taken: 400.9696674346924
Data appended to ./inputs/c4_5.csv
