/local1/borito1907/anaconda3/envs/watermark/lib/python3.12/site-packages/transformers/utils/hub.py:122: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
[nltk_data] Downloading package punkt to /home/borito1907/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[2024-05-21 16:34:21,739][__main__][INFO] - Starting to watermark...
[2024-05-21 16:34:21,739][__main__][INFO] - Prompt: Write a 250 word essay on the role of power and its impact on characters in the Lord of the Rings 
        series. How does the ring symbolize power, and what does Tolkien suggest about the nature of power?

        Answer:
[2024-05-21 16:34:21,739][__main__][INFO] - Getting the watermarker...
[2024-05-21 16:34:21,739][watermarker][INFO] - Using device: cuda
[2024-05-21 16:34:21,739][root][INFO] - Device: auto
[2024-05-21 16:34:21,739][model_builders.pipeline][INFO] - Initializing TheBloke/Mixtral-8x7B-Instruct-v0.1-GPTQ
/local1/borito1907/anaconda3/envs/watermark/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/local1/borito1907/anaconda3/envs/watermark/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2024-05-21 16:34:38,364][accelerate.big_modeling][WARNING] - You shouldn't move a model that is dispatched using accelerate hooks.
/local1/borito1907/anaconda3/envs/watermark/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2024-05-21 16:34:39,101][semstamp][INFO] - {'max_new_tokens': 1024, 'do_sample': True, 'temperature': 0.7, 'top_p': 0.95, 'top_k': 40, 'repetition_penalty': 1.1, 'bad_words_ids': [[28705, 13]], 'min_new_tokens': 195}
[2024-05-21 16:34:39,101][semstamp][INFO] - Initializing embedder model.
[2024-05-21 16:34:39,102][sentence_transformers.SentenceTransformer][INFO] - Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v1
[2024-05-21 16:34:39,992][sentence_transformers.SentenceTransformer][INFO] - Use pytorch device_name: cuda
[2024-05-21 16:34:40,050][semstamp][INFO] - Finished initializing embedder model.
initializing random projection LSH model
loading SBERT base model...
[2024-05-21 16:34:40,056][__main__][INFO] - Got the watermarker. Generating watermarked text...
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  2.37it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  2.37it/s]
Error executing job with overrides: []
Traceback (most recent call last):
  File "/local1/borito1907/impossibility-watermark/watermarker_tester.py", line 29, in test
    watermarked_text = watermarker.generate(prompt)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local1/borito1907/impossibility-watermark/watermarker.py", line 50, in generate
    completion = self.generate_watermarked_outputs(prompt)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local1/borito1907/impossibility-watermark/semstamp.py", line 73, in generate_watermarked_outputs
    return self._lsh_generate_watermarked_outputs(prompt)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local1/borito1907/impossibility-watermark/semstamp.py", line 83, in _lsh_generate_watermarked_outputs
    response = lsh_reject_completion(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/local1/borito1907/impossibility-watermark/SemStamp/sampling_lsh_utils.py", line 103, in lsh_reject_completion
    outputs = model.generate(**text_ids, **generator_kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: transformers.generation.utils.GenerationMixin.generate() argument after ** must be a mapping, not Tensor

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
