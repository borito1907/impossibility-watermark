/local1/borito1907/anaconda3/envs/watermark/lib/python3.10/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
[nltk_data] Downloading package punkt to /home/borito1907/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[2024-08-21 10:31:17,188][__main__][INFO] - Getting the watermarker...
[2024-08-21 10:31:17,189][watermarker][INFO] - Using device: cuda:0
[2024-08-21 10:31:17,189][model_builders.pipeline][INFO] - Initializing hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4
Loading checkpoint shards:   0%|          | 0/9 [00:00<?, ?it/s]Loading checkpoint shards:  11%|█         | 1/9 [00:01<00:09,  1.14s/it]Loading checkpoint shards:  22%|██▏       | 2/9 [00:02<00:07,  1.11s/it]Loading checkpoint shards:  33%|███▎      | 3/9 [00:03<00:06,  1.09s/it]Loading checkpoint shards:  44%|████▍     | 4/9 [00:04<00:05,  1.10s/it]Loading checkpoint shards:  56%|█████▌    | 5/9 [00:05<00:04,  1.10s/it]Loading checkpoint shards:  67%|██████▋   | 6/9 [00:06<00:03,  1.09s/it]Loading checkpoint shards:  78%|███████▊  | 7/9 [00:07<00:02,  1.13s/it]Loading checkpoint shards:  89%|████████▉ | 8/9 [00:08<00:01,  1.04s/it]Loading checkpoint shards: 100%|██████████| 9/9 [00:09<00:00,  1.14it/s]Loading checkpoint shards: 100%|██████████| 9/9 [00:09<00:00,  1.02s/it]
/local1/borito1907/anaconda3/envs/watermark/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 0.3. An updated version of the class exists in the from rom langchain-huggingface package and should be used instead. To use it run `pip install -U from rom langchain-huggingface` and import as `from from rom langchain_huggingface import llms import HuggingFacePipeline`.
  warn_deprecated(
[2024-08-21 10:31:31,808][sentence_transformers.SentenceTransformer][INFO] - Use pytorch device_name: cuda
[2024-08-21 10:31:31,808][sentence_transformers.SentenceTransformer][INFO] - Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2
[2024-08-21 10:31:33,005][watermarkers.adaptive][INFO] - {'max_new_tokens': 768, 'do_sample': True, 'temperature': 1.0, 'top_p': 0.95, 'top_k': 40, 'repetition_penalty': 1.1}
[2024-08-21 10:31:33,005][__main__][INFO] - {'prompt': None, 'prompt_file': './data/WQE/dev.csv', 'prompt_num': 1, 'is_completion': False, 'generation_stats_file_path': None, 'watermarked_text_file_name': None, 'partition': 2, 'generator_args': {'model_name_or_path': 'hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4', 'revision': 'main', 'model_cache_dir': '/data2/.shared_models/', 'device_map': 'auto', 'trust_remote_code': True, 'max_new_tokens': 768, 'min_new_tokens': 128, 'do_sample': True, 'temperature': 1.0, 'top_p': 0.95, 'top_k': 40, 'repetition_penalty': 1.1, 'watermark_score_threshold': 5.0, 'diversity_penalty': 0.0}, 'watermark_args': {'name': 'adaptive', 'measure_model_name': 'gpt2-large', 'embedding_model_name': 'sentence-transformers/all-mpnet-base-v2', 'mapping_list': None, 'alpha': 2.0, 'top_k': 50, 'top_p': 0.9, 'repetition_penalty': 1.1, 'no_repeat_ngram_size': 0, 'max_new_tokens': 786, 'min_new_tokens': 128, 'secret_string': 'The quick brown fox jumps over the lazy dog', 'measure_threshold': 50, 'delta_0': 1.0, 'delta': 1.5, 'device': 'auto'}, 'attack_args': {'prompt': None, 'prompt_file': './inputs/dynamic_prompts.csv', 'prompt_num': 6, 'watermarked_text': None, 'watermarked_text_path': None, 'watermarked_text_num': 1, 'num_steps': 2000, 'patience': 250, 'stop_at_removal': False, 'num_successful_steps': 100, 'results_dir': None, 'model_cache_dir': '/local1/borito1907/.cache/', 'save_name': None, 'use_watermark': False, 'backtrack_patience': 50, 'is_completion': False, 'json_path': None, 'json_index': 0, 'is_continuation': False, 'prev_csv_file': None, 'cuda': '1'}}
[2024-08-21 10:31:33,005][__main__][INFO] - Got the watermarker. Generating watermarked text...
Error executing job with overrides: ['++partition=2']
Traceback (most recent call last):
  File "/local1/borito1907/impossibility-watermark/adaptive_test_gen.py", line 48, in test
    prompt, id = get_prompt_and_id_dev(cfg.prompt_file, prompt_num)
  File "/local1/borito1907/impossibility-watermark/utils.py", line 102, in get_prompt_and_id_dev
    raise Exception(f"Index out of range.")
Exception: Index out of range.

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
