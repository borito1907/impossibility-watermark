/local1/borito1907/anaconda3/envs/watermark_2/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
[nltk_data] Downloading package punkt to /home/borito1907/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[2024-05-26 11:31:31,218][__main__][INFO] - Starting to watermark...
[2024-05-26 11:31:31,222][__main__][INFO] - Prompt: Describe the main responsibilities of a U.S. Senator.
[2024-05-26 11:31:31,222][__main__][INFO] - Getting the watermarker...
[2024-05-26 11:31:31,223][watermarker][INFO] - Using device: cuda
[2024-05-26 11:31:31,223][model_builders.pipeline][INFO] - Initializing MaziyarPanahi/Meta-Llama-3-70B-Instruct-GPTQ
/local1/borito1907/anaconda3/envs/watermark_2/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
INFO - You passed a model that is compatible with the Marlin int4*fp16 GPTQ kernel but use_marlin is False. We recommend using `use_marlin=True` to use the optimized Marlin kernels for inference. Example: `model = AutoGPTQForCausalLM.from_quantized(..., use_marlin=True)`.
INFO - The layer lm_head is not quantized.
[2024-05-26 11:31:34,494][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2024-05-26 11:31:42,015][auto_gptq.utils.accelerate_utils][WARNING] - Some weights of the model checkpoint at /local1/borito1907/.cache/models--MaziyarPanahi--Meta-Llama-3-70B-Instruct-GPTQ/snapshots/46c7afccd4f9345a3d43c1468fde1034cf0a0932/model.safetensors were not used when initializing LlamaForCausalLM: set(). This may or may not be an issue - make sure that the checkpoint does not have unnecessary parameters, or that the model definition correctly corresponds to the checkpoint.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
The model 'LlamaGPTQForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'JambaForCausalLM', 'LlamaForCausalLM', 'MambaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'OlmoForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].
/local1/borito1907/anaconda3/envs/watermark_2/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 0.3. An updated version of the class exists in the from rom langchain-huggingface package and should be used instead. To use it run `pip install -U from rom langchain-huggingface` and import as `from from rom langchain_huggingface import llms import HuggingFacePipeline`.
  warn_deprecated(
[2024-05-26 11:31:43,720][semstamp][INFO] - Setting up generating components...
[2024-05-26 11:31:43,723][semstamp][INFO] - {'max_new_tokens': 1024, 'do_sample': True, 'temperature': 1, 'top_p': 0.95, 'top_k': 40, 'repetition_penalty': 1.1, 'bad_words_ids': [[198]], 'min_new_tokens': 245}
[2024-05-26 11:31:43,723][semstamp][INFO] - Initializing embedder model.
[2024-05-26 11:31:43,723][sentence_transformers.SentenceTransformer][INFO] - Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v1
/local1/borito1907/anaconda3/envs/watermark_2/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2024-05-26 11:31:44,626][sentence_transformers.SentenceTransformer][INFO] - Use pytorch device_name: cuda
[2024-05-26 11:31:44,703][semstamp][INFO] - Finished initializing embedder model.
initializing random projection LSH model
loading SBERT base model...
[2024-05-26 11:31:44,704][__main__][INFO] - Got the watermarker. Generating watermarked text...
[2024-05-26 11:31:44,704][semstamp][INFO] - Passing the following prompt to the LSH reject completion function:
 Describe the main responsibilities of a U.S. Senator.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  2.80it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  2.80it/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-26 11:31:47,872][semstamp][INFO] - Candidate text: 

As a U.S. Senator,ing Assistant, a helpful personal assistant), I'd be happy to outline the main responsibilities of a U.S. Senator:

**1.
[2024-05-26 11:31:47,872][semstamp][INFO] - Accept Mask: tensor([7, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 137.10it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 154.95it/s]
[2024-05-26 11:31:47,892][semstamp][INFO] - LSH Candidate: 4
[2024-05-26 11:31:47,892][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-26 11:31:49,647][semstamp][INFO] - Candidate text: 

As a helpful personal assistant,, A U.S. Senator has several key responsibilities that include:

1.
[2024-05-26 11:31:49,647][semstamp][INFO] - Accept Mask: tensor([7, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 142.46it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 157.67it/s]
[2024-05-26 11:31:49,665][semstamp][INFO] - LSH Candidate: 4
[2024-05-26 11:31:49,665][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-26 11:31:51,820][semstamp][INFO] - Candidate text: 

As a helpful personal assistant, of yours, I can provide you with detailed information about the main responsibilities of a U.S. Senator.


[2024-05-26 11:31:51,820][semstamp][INFO] - Accept Mask: tensor([7, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 142.00it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 156.01it/s]
[2024-05-26 11:31:51,838][semstamp][INFO] - LSH Candidate: 4
[2024-05-26 11:31:51,838][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-26 11:31:53,994][semstamp][INFO] - Candidate text: 

As a helpful personal assistant, of yours, I'd be delighted to outline the main responsibilities of a U.S. Senator:

1.
[2024-05-26 11:31:53,995][semstamp][INFO] - Accept Mask: tensor([7, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 139.21it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 154.94it/s]
[2024-05-26 11:31:54,013][semstamp][INFO] - LSH Candidate: 4
[2024-05-26 11:31:54,013][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-26 11:31:56,984][semstamp][INFO] - Candidate text: 

As a helpful personal assistant,, on behalf of my user, and with utmost respect for the esteemed office, A U.S. Senator has several key responsibilities, the main ones being:

1.
[2024-05-26 11:31:56,984][semstamp][INFO] - Accept Mask: tensor([7, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 141.60it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 157.13it/s]
[2024-05-26 11:31:57,002][semstamp][INFO] - LSH Candidate: 4
[2024-05-26 11:31:57,002][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-26 11:31:59,158][semstamp][INFO] - Candidate text: 

As a trusted personal assistant, of yours, I'm happy to provide an overview of the main responsibilities of a U.S. Senator.


[2024-05-26 11:31:59,158][semstamp][INFO] - Accept Mask: tensor([7, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 143.11it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 155.02it/s]
[2024-05-26 11:31:59,176][semstamp][INFO] - LSH Candidate: 4
[2024-05-26 11:31:59,176][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-26 11:32:01,332][semstamp][INFO] - Candidate text: 

As a helpful personal assistant, a U.S. Senator has several key responsibilities, and here are some of the main ones:

1.
[2024-05-26 11:32:01,333][semstamp][INFO] - Accept Mask: tensor([7, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 145.90it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 156.64it/s]
[2024-05-26 11:32:01,350][semstamp][INFO] - LSH Candidate: 4
[2024-05-26 11:32:01,350][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-26 11:32:03,572][semstamp][INFO] - Candidate text: 

As a helpful personal assistant, of yours, I'd be delighted to outline the main responsibilities of a U.S. Senator:

**1.
[2024-05-26 11:32:03,573][semstamp][INFO] - Accept Mask: tensor([7, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 141.06it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 155.88it/s]
[2024-05-26 11:32:03,591][semstamp][INFO] - LSH Candidate: 4
[2024-05-26 11:32:03,591][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-26 11:32:05,946][semstamp][INFO] - Candidate text: 

As a helpful personal assistant, in this response, I will outline the key responsibilities of a United States Senator.

The primary role of a U.S.
[2024-05-26 11:32:05,947][semstamp][INFO] - Accept Mask: tensor([7, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 139.33it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 152.51it/s]
[2024-05-26 11:32:05,965][semstamp][INFO] - LSH Candidate: 4
[2024-05-26 11:32:05,965][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-26 11:32:07,650][semstamp][INFO] - Candidate text: 

As a helpful personal assistant, A U.S. Senator has several key responsibilities that include:

1.
[2024-05-26 11:32:07,651][semstamp][INFO] - Accept Mask: tensor([7, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 146.76it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 157.03it/s]
[2024-05-26 11:32:07,668][semstamp][INFO] - LSH Candidate: 4
[2024-05-26 11:32:07,668][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[2024-05-26 11:32:10,225][semstamp][INFO] - Candidate text: 

As a helpful personal assistant, A U.S. Senator has several key responsibilities, as outlined in Article I, (Legislative) of the United States Constitution.
[2024-05-26 11:32:10,225][semstamp][INFO] - Accept Mask: tensor([7, 2], device='cuda:0')
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 139.33it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 154.38it/s]
[2024-05-26 11:32:10,244][semstamp][INFO] - LSH Candidate: 4
[2024-05-26 11:32:10,244][semstamp][INFO] - Candidate text is doesn't fall into the correct place in the embedding space.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Traceback (most recent call last):
  File "/local1/borito1907/impossibility-watermark/watermarked_text_generator.py", line 44, in <module>
    test()
  File "/local1/borito1907/anaconda3/envs/watermark_2/lib/python3.10/site-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
  File "/local1/borito1907/anaconda3/envs/watermark_2/lib/python3.10/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/local1/borito1907/anaconda3/envs/watermark_2/lib/python3.10/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/local1/borito1907/anaconda3/envs/watermark_2/lib/python3.10/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
  File "/local1/borito1907/anaconda3/envs/watermark_2/lib/python3.10/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
  File "/local1/borito1907/anaconda3/envs/watermark_2/lib/python3.10/site-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
  File "/local1/borito1907/anaconda3/envs/watermark_2/lib/python3.10/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "/local1/borito1907/impossibility-watermark/watermarked_text_generator.py", line 27, in test
    watermarked_text = watermarker.generate(prompt)
  File "/local1/borito1907/impossibility-watermark/watermarker.py", line 51, in generate
    completion = self.generate_watermarked_outputs(prompt)
  File "/local1/borito1907/impossibility-watermark/semstamp.py", line 209, in generate_watermarked_outputs
    return self._lsh_generate_watermarked_outputs(prompt)
  File "/local1/borito1907/impossibility-watermark/semstamp.py", line 221, in _lsh_generate_watermarked_outputs
    response = self.lsh_reject_completion(prompt)
  File "/local1/borito1907/impossibility-watermark/semstamp.py", line 143, in lsh_reject_completion
    new_text, new_text_ids = self.generate_sentence(text, text_ids, stopping_criteria)
  File "/local1/borito1907/impossibility-watermark/semstamp.py", line 100, in generate_sentence
    outputs = self.model.generate(inputs=text_ids, generation_config=self.gen_config, **self.generator_kwargs)
  File "/local1/borito1907/AutoGPTQ/auto_gptq/modeling/_base.py", line 534, in generate
    return self.model.generate(**kwargs)
  File "/local1/borito1907/anaconda3/envs/watermark_2/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/local1/borito1907/anaconda3/envs/watermark_2/lib/python3.10/site-packages/transformers/generation/utils.py", line 1622, in generate
    result = self._sample(
  File "/local1/borito1907/anaconda3/envs/watermark_2/lib/python3.10/site-packages/transformers/generation/utils.py", line 2791, in _sample
    outputs = self(
  File "/local1/borito1907/anaconda3/envs/watermark_2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/local1/borito1907/anaconda3/envs/watermark_2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/local1/borito1907/anaconda3/envs/watermark_2/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 1211, in forward
    outputs = self.model(
  File "/local1/borito1907/anaconda3/envs/watermark_2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/local1/borito1907/anaconda3/envs/watermark_2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/local1/borito1907/anaconda3/envs/watermark_2/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 1018, in forward
    layer_outputs = decoder_layer(
  File "/local1/borito1907/anaconda3/envs/watermark_2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/local1/borito1907/anaconda3/envs/watermark_2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/local1/borito1907/anaconda3/envs/watermark_2/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 741, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
  File "/local1/borito1907/anaconda3/envs/watermark_2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/local1/borito1907/anaconda3/envs/watermark_2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/local1/borito1907/anaconda3/envs/watermark_2/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 645, in forward
    query_states, key_states = apply_rotary_pos_emb(query_states, key_states, cos, sin)
  File "/local1/borito1907/anaconda3/envs/watermark_2/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 206, in apply_rotary_pos_emb
    q_embed = (q * cos) + (rotate_half(q) * sin)
  File "/local1/borito1907/anaconda3/envs/watermark_2/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 181, in rotate_half
    return torch.cat((-x2, x1), dim=-1)
KeyboardInterrupt
