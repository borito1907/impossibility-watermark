{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# Function to normalize scores\n",
    "def normalize_score(score, mean, stdev):\n",
    "    if score == -1:\n",
    "        return score  # Don't normalize if score is -1\n",
    "    return (score - mean) / stdev\n",
    "\n",
    "def merge_watermark_scores(df1, df2):\n",
    "    # Ensure both DFs have the same structure and number of rows\n",
    "    if not df1.shape == df2.shape:\n",
    "        raise ValueError(\"DataFrames must have the same shape\")\n",
    "    \n",
    "    # Iterate through the rows and merge watermark_score based on the conditions\n",
    "    for index, (wm1, wm2) in enumerate(zip(df1['watermark_score'], df2['watermark_score'])):\n",
    "        if wm1 == -1 and wm2 == -1:\n",
    "            # Do nothing, both are -1\n",
    "            continue\n",
    "        elif wm1 != -1 and wm2 != -1 and wm1 != wm2:\n",
    "            # Print if both are not -1 and not equal\n",
    "            print(f\"Conflict at index {index}: df1: {wm1}, df2: {wm2}\")\n",
    "        elif wm1 == -1 and wm2 != -1:\n",
    "            # Replace df1's score with df2's if df1 is -1\n",
    "            df1.at[index, 'watermark_score'] = wm2\n",
    "        elif wm2 == -1 and wm1 != -1:\n",
    "            # Replace df2's score with df1's if df2 is -1\n",
    "            df2.at[index, 'watermark_score'] = wm1\n",
    "    \n",
    "    return df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /data2/borito1907/impossibility-watermark/attack_traces/DiffOracle_SemStampWatermarker_Document1StepMutator_n-steps=200_attack_results_annotatedmerged.csv\n",
      "Processing file: /data2/borito1907/impossibility-watermark/attack_traces/DiffOracle_SemStampWatermarker_DocumentMutator_n-steps=200_attack_results_annotatedmerged.csv\n",
      "Processing file: /data2/borito1907/impossibility-watermark/attack_traces/DiffOracle_SemStampWatermarker_Document2StepMutator_n-steps=200_attack_results_annotatedmerged.csv\n"
     ]
    }
   ],
   "source": [
    "mean_score = -0.7281950363003581\n",
    "stdev_score = 0.933524266518816\n",
    "\n",
    "dir_path = \"/data2/borito1907/impossibility-watermark/attack_traces\"\n",
    "\n",
    "# counter = 0\n",
    "\n",
    "# Loop over all CSV files in the directory\n",
    "for filename in os.listdir(dir_path):\n",
    "    if (\"Document\" in filename) and (\"SemStamp\" in filename) and \"n-steps=200\" in filename and filename.endswith(\"annotatedmerged.csv\"):\n",
    "        df_path = os.path.join(dir_path, filename)\n",
    "        print(f\"Processing file: {df_path}\")\n",
    "        new_df_path = os.path.join(dir_path, filename.replace('.csv', '_annotatedfinal.csv'))\n",
    "        df = pd.read_csv(df_path)\n",
    "                \n",
    "        # Apply normalization\n",
    "        df['normalized_watermark_score'] = df['watermark_score'].apply(lambda x: normalize_score(x, mean_score, stdev_score))\n",
    "\n",
    "        # df.to_csv(new_df_path, index=False, quoting=csv.QUOTE_ALL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /data2/borito1907/impossibility-watermark/attack_traces/DiffOracle_SemStampWatermarker_SentenceMutator_n-steps=200_attack_results_annotated.csv\n"
     ]
    }
   ],
   "source": [
    "mean_score = -0.7281950363003581\n",
    "stdev_score = 0.933524266518816\n",
    "\n",
    "dir_path = \"/data2/borito1907/impossibility-watermark/attack_traces\"\n",
    "\n",
    "# counter = 0\n",
    "\n",
    "# Loop over all CSV files in the directory\n",
    "for filename in os.listdir(dir_path):\n",
    "    if (\"good_embedder\" not in filename) and (\"Sentence\" in filename) and (\"SemStamp\" in filename) and \"n-steps=200\" in filename and filename.endswith(\"annotated.csv\"):\n",
    "        df_path = os.path.join(dir_path, filename)\n",
    "        print(f\"Processing file: {df_path}\")\n",
    "        new_df_path = os.path.join(dir_path, filename.replace('annotated.csv', 'annotated1.csv'))\n",
    "        df = pd.read_csv(df_path)\n",
    "                \n",
    "        # Apply normalization\n",
    "        df['normalized_watermark_score'] = df['watermark_score'].apply(lambda x: normalize_score(x, mean_score, stdev_score))\n",
    "\n",
    "        df.to_csv(new_df_path, index=False, quoting=csv.QUOTE_ALL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /data2/borito1907/DiffOracle_semstamp_WordMutator_n-steps=1000_attack_results_newest_annotated.csv\n"
     ]
    }
   ],
   "source": [
    "mean_score = -0.7281950363003581\n",
    "stdev_score = 0.933524266518816\n",
    "\n",
    "dir_path = \"/data2/borito1907\"\n",
    "filename = 'DiffOracle_semstamp_WordMutator_n-steps=1000_attack_results_newest_annotated.csv'\n",
    "df_path = os.path.join(dir_path, filename)\n",
    "print(f\"Processing file: {df_path}\")\n",
    "new_df_path = os.path.join(dir_path, filename.replace('annotated.csv', 'annotatedfinal.csv'))\n",
    "df = pd.read_csv(df_path)\n",
    "        \n",
    "# Apply normalization\n",
    "df['normalized_watermark_score'] = df['watermark_score'].apply(lambda x: normalize_score(x, mean_score, stdev_score))\n",
    "\n",
    "# df.to_csv(new_df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_score = -0.7281950363003581\n",
    "stdev_score = 0.933524266518816\n",
    "\n",
    "\n",
    "df_path = \"/data2/borito1907/impossibility-watermark/unwatermarked_scores/semstamp_detect_unwatermarked.csv\"\n",
    "\n",
    "new_df_path = \"/data2/borito1907/impossibility-watermark/unwatermarked_scores/semstamp_detect_unwatermarked_normalized.csv\"\n",
    "df = pd.read_csv(df_path)\n",
    "        \n",
    "# Apply normalization\n",
    "df['normalized_watermark_score'] = df['watermark_score'].apply(lambda x: normalize_score(x, mean_score, stdev_score))\n",
    "\n",
    "# df.to_csv(new_df_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /data2/borito1907/impossibility-watermark/attack_traces/DiffOracle_AdaptiveWatermarker_SentenceMutator_n-steps=200_attack_results_annotated.csv\n"
     ]
    }
   ],
   "source": [
    "mean_score = 51.60824692338929\n",
    "stdev_score = 5.957990385248221\n",
    "\n",
    "dir_path = \"/data2/borito1907/impossibility-watermark/attack_traces\"\n",
    "\n",
    "# counter = 0\n",
    "\n",
    "# Loop over all CSV files in the directory\n",
    "for filename in os.listdir(dir_path):\n",
    "    if (\"Adaptive\" in filename) and (\"Sentence\") in filename and filename.endswith(\"annotated.csv\"):\n",
    "        df_path = os.path.join(dir_path, filename)\n",
    "        print(f\"Processing file: {df_path}\")\n",
    "        new_df_path = os.path.join(dir_path, filename.replace('annotated.csv', 'annotated1.csv'))\n",
    "        df = pd.read_csv(df_path)\n",
    "                \n",
    "        # Apply normalization\n",
    "        df['normalized_watermark_score'] = df['watermark_score'].apply(lambda x: normalize_score(x, mean_score, stdev_score))\n",
    "\n",
    "        # df.to_csv(new_df_path, index=False, quoting=csv.QUOTE_ALL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /data2/borito1907/DiffOracle_adaptive_WordMutator_n-steps=1000_attack_results_newest_annotated.csv\n"
     ]
    }
   ],
   "source": [
    "mean_score = 51.60824692338929\n",
    "stdev_score = 5.957990385248221\n",
    "\n",
    "dir_path = \"/data2/borito1907\"\n",
    "filename = 'DiffOracle_adaptive_WordMutator_n-steps=1000_attack_results_newest_annotated.csv'\n",
    "df_path = os.path.join(dir_path, filename)\n",
    "print(f\"Processing file: {df_path}\")\n",
    "new_df_path = os.path.join(dir_path, filename.replace('annotated.csv', 'annotatedfinal.csv'))\n",
    "df = pd.read_csv(df_path)\n",
    "        \n",
    "# Apply normalization\n",
    "df['normalized_watermark_score'] = df['watermark_score'].apply(lambda x: normalize_score(x, mean_score, stdev_score))\n",
    "\n",
    "# df.to_csv(new_df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def breakup_attacks(df):\n",
    "    # Break the DF up into smaller DFs\n",
    "    dfs = []\n",
    "    current_df = None\n",
    "\n",
    "    # Iterate over the rows and split on step_num resets\n",
    "    for i, row in df.iterrows():\n",
    "        # Check if the step_num resets to -1, indicating a new sequence\n",
    "        if row['mutation_num'] == -1:\n",
    "            if current_df is not None and not current_df.empty:\n",
    "                dfs.append(current_df.reset_index(drop=True))  # Save the current increasing DF\n",
    "            current_df = pd.DataFrame([row])  # Start a new DataFrame with the reset row\n",
    "        else:\n",
    "            # Append the row to the current DataFrame\n",
    "            current_df = pd.concat([current_df, pd.DataFrame([row])])\n",
    "\n",
    "    # Add the last DataFrame if it exists and is non-empty\n",
    "    if current_df is not None and not current_df.empty:\n",
    "        dfs.append(current_df.reset_index(drop=True))\n",
    "    \n",
    "    return dfs\n",
    "\n",
    "df = pd.read_csv('/data2/borito1907/DiffOracle_adaptive_WordMutator_n-steps=1000_attack_results_newest_annotatedfinal.csv')\n",
    "dfs = breakup_attacks(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       8.045520\n",
       "100     5.417271\n",
       "200     4.860457\n",
       "300     4.091313\n",
       "400     3.575051\n",
       "500     2.860453\n",
       "600     3.237212\n",
       "700     2.651760\n",
       "800     2.869096\n",
       "900     2.928565\n",
       "1000    2.485681\n",
       "1001    2.548309\n",
       "Name: normalized_watermark_score, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = dfs[0][dfs[0]['normalized_watermark_score'] != -1.0]\n",
    "temp['normalized_watermark_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       8.000975\n",
       "100     5.872734\n",
       "200     4.992905\n",
       "300     4.024349\n",
       "400     3.954658\n",
       "500     3.120251\n",
       "600     3.047872\n",
       "700     2.731215\n",
       "800     2.695275\n",
       "900     2.901662\n",
       "1000    2.413255\n",
       "1001    2.546398\n",
       "Name: normalized_watermark_score, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = dfs[1][dfs[1]['normalized_watermark_score'] != -1.0]\n",
    "temp['normalized_watermark_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/data2/borito1907/DiffOracle_semstamp_WordMutator_n-steps=1000_attack_results_newest_annotatedfinal.csv')\n",
    "dfs = breakup_attacks(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New DocMutator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /data2/borito1907/impossibility-watermark/attack_traces/DiffOracle_AdaptiveWatermarker_DocumentMutator_n-steps=50_attack_results_v2_annotated.csv\n"
     ]
    }
   ],
   "source": [
    "# mean_score = 51.60824692338929\n",
    "# stdev_score = 5.957990385248221\n",
    "\n",
    "# dir_path = \"/data2/borito1907/impossibility-watermark/attack_traces\"\n",
    "\n",
    "# # counter = 0\n",
    "\n",
    "# # Loop over all CSV files in the directory\n",
    "# for filename in os.listdir(dir_path):\n",
    "#     if (\"Adaptive\" in filename) and (\"Document\") in filename and \"v2\" in filename and filename.endswith(\"annotated.csv\"):\n",
    "#         df_path = os.path.join(dir_path, filename)\n",
    "#         print(f\"Processing file: {df_path}\")\n",
    "#         new_df_path = os.path.join(dir_path, filename.replace('annotated.csv', 'annotated1.csv'))\n",
    "\n",
    "#         # Check if the new file already exists\n",
    "#         if os.path.exists(new_df_path):\n",
    "#             print(f\"File {new_df_path} already exists. Skipping...\")\n",
    "#             continue  # Skip this file and move to the next one\n",
    "#         df = pd.read_csv(df_path)\n",
    "                \n",
    "#         # Apply normalization\n",
    "#         df['normalized_watermark_score'] = df['watermark_score'].apply(lambda x: normalize_score(x, mean_score, stdev_score))\n",
    "\n",
    "        \n",
    "#         df.to_csv(new_df_path, index=False, quoting=csv.QUOTE_ALL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /data2/borito1907/impossibility-watermark/attack_traces/AdaptiveWatermaker_sandpaper_results_annotated.csv\n"
     ]
    }
   ],
   "source": [
    "mean_score = 51.60824692338929\n",
    "stdev_score = 5.957990385248221\n",
    "\n",
    "dir_path = \"/data2/borito1907/impossibility-watermark/attack_traces\"\n",
    "\n",
    "# counter = 0\n",
    "\n",
    "# Loop over all CSV files in the directory\n",
    "for filename in os.listdir(dir_path):\n",
    "    if (\"Adaptive\" in filename) and (\"sandpaper\") in filename and filename.endswith(\"annotated.csv\"):\n",
    "        df_path = os.path.join(dir_path, filename)\n",
    "        print(f\"Processing file: {df_path}\")\n",
    "        new_df_path = os.path.join(dir_path, filename.replace('annotated.csv', 'annotated1.csv'))\n",
    "\n",
    "        # Check if the new file already exists\n",
    "        if os.path.exists(new_df_path):\n",
    "            print(f\"File {new_df_path} already exists. Skipping...\")\n",
    "            continue  # Skip this file and move to the next one\n",
    "        df = pd.read_csv(df_path)\n",
    "                \n",
    "        # Apply normalization\n",
    "        df['normalized_watermark_score'] = df['watermark_score'].apply(lambda x: normalize_score(x, mean_score, stdev_score))\n",
    "\n",
    "        \n",
    "        df.to_csv(new_df_path, index=False, quoting=csv.QUOTE_ALL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gptq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
