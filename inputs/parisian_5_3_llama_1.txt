[2024-02-21 17:26:33,412][datasets][INFO] - PyTorch version 2.1.2 available.
[2024-02-21 17:26:42,384][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
config.json:   0%|          | 0.00/913 [00:00<?, ?B/s]config.json: 100%|██████████| 913/913 [00:00<00:00, 9.77MB/s]
model.safetensors:   0%|          | 0.00/7.26G [00:00<?, ?B/s]model.safetensors:   0%|          | 10.5M/7.26G [00:00<03:00, 40.2MB/s]model.safetensors:   0%|          | 31.5M/7.26G [00:00<02:23, 50.4MB/s]model.safetensors:   1%|          | 52.4M/7.26G [00:00<01:41, 71.0MB/s]model.safetensors:   1%|          | 73.4M/7.26G [00:00<01:23, 85.6MB/s]model.safetensors:   1%|          | 83.9M/7.26G [00:01<01:24, 85.0MB/s]model.safetensors:   1%|▏         | 94.4M/7.26G [00:01<01:31, 78.3MB/s]model.safetensors:   2%|▏         | 115M/7.26G [00:01<01:26, 82.4MB/s] model.safetensors:   2%|▏         | 136M/7.26G [00:01<01:16, 92.5MB/s]model.safetensors:   2%|▏         | 157M/7.26G [00:01<01:11, 99.9MB/s]model.safetensors:   2%|▏         | 178M/7.26G [00:02<01:07, 105MB/s] model.safetensors:   3%|▎         | 199M/7.26G [00:02<01:05, 108MB/s]model.safetensors:   3%|▎         | 220M/7.26G [00:02<01:03, 110MB/s]model.safetensors:   3%|▎         | 241M/7.26G [00:02<01:02, 113MB/s]model.safetensors:   4%|▎         | 262M/7.26G [00:02<01:01, 113MB/s]model.safetensors:   4%|▍         | 283M/7.26G [00:02<01:01, 114MB/s]model.safetensors:   4%|▍         | 304M/7.26G [00:03<01:00, 115MB/s]model.safetensors:   4%|▍         | 325M/7.26G [00:03<00:59, 116MB/s]model.safetensors:   5%|▍         | 346M/7.26G [00:03<01:27, 78.7MB/s]model.safetensors:   5%|▌         | 367M/7.26G [00:03<01:19, 86.8MB/s]model.safetensors:   5%|▌         | 388M/7.26G [00:04<01:12, 94.6MB/s]model.safetensors:   6%|▌         | 409M/7.26G [00:04<01:13, 93.3MB/s]model.safetensors:   6%|▌         | 430M/7.26G [00:04<01:09, 98.7MB/s]model.safetensors:   6%|▌         | 451M/7.26G [00:04<01:08, 98.8MB/s]model.safetensors:   6%|▋         | 472M/7.26G [00:04<01:05, 103MB/s] model.safetensors:   7%|▋         | 493M/7.26G [00:05<01:03, 107MB/s]model.safetensors:   7%|▋         | 514M/7.26G [00:05<01:06, 102MB/s]model.safetensors:   7%|▋         | 535M/7.26G [00:05<01:03, 106MB/s]model.safetensors:   8%|▊         | 556M/7.26G [00:05<01:01, 109MB/s]model.safetensors:   8%|▊         | 577M/7.26G [00:05<01:00, 111MB/s]model.safetensors:   8%|▊         | 598M/7.26G [00:06<00:59, 113MB/s]model.safetensors:   9%|▊         | 619M/7.26G [00:06<00:58, 113MB/s]model.safetensors:   9%|▉         | 640M/7.26G [00:06<00:57, 114MB/s]model.safetensors:   9%|▉         | 661M/7.26G [00:06<00:57, 115MB/s]model.safetensors:   9%|▉         | 682M/7.26G [00:06<00:57, 115MB/s]model.safetensors:  10%|▉         | 703M/7.26G [00:06<00:56, 116MB/s]model.safetensors:  10%|▉         | 724M/7.26G [00:07<00:56, 116MB/s]model.safetensors:  10%|█         | 744M/7.26G [00:07<00:56, 116MB/s]model.safetensors:  11%|█         | 765M/7.26G [00:07<00:55, 117MB/s]model.safetensors:  11%|█         | 786M/7.26G [00:07<00:58, 111MB/s]model.safetensors:  11%|█         | 807M/7.26G [00:07<00:57, 113MB/s]model.safetensors:  11%|█▏        | 828M/7.26G [00:08<00:57, 113MB/s]model.safetensors:  12%|█▏        | 849M/7.26G [00:08<00:56, 113MB/s]model.safetensors:  12%|█▏        | 870M/7.26G [00:08<00:56, 113MB/s]model.safetensors:  12%|█▏        | 891M/7.26G [00:08<00:55, 114MB/s]model.safetensors:  13%|█▎        | 912M/7.26G [00:08<00:55, 114MB/s]model.safetensors:  13%|█▎        | 933M/7.26G [00:09<00:55, 114MB/s]model.safetensors:  13%|█▎        | 954M/7.26G [00:09<00:54, 115MB/s]model.safetensors:  13%|█▎        | 975M/7.26G [00:09<00:54, 115MB/s]model.safetensors:  14%|█▎        | 996M/7.26G [00:09<00:54, 115MB/s]model.safetensors:  14%|█▍        | 1.02G/7.26G [00:09<00:54, 115MB/s]model.safetensors:  14%|█▍        | 1.04G/7.26G [00:09<00:53, 116MB/s]model.safetensors:  15%|█▍        | 1.06G/7.26G [00:10<00:53, 116MB/s]model.safetensors:  15%|█▍        | 1.08G/7.26G [00:10<00:52, 117MB/s]model.safetensors:  15%|█▌        | 1.10G/7.26G [00:10<00:53, 116MB/s]model.safetensors:  15%|█▌        | 1.12G/7.26G [00:10<01:10, 87.5MB/s]model.safetensors:  16%|█▌        | 1.14G/7.26G [00:11<01:04, 94.5MB/s]model.safetensors:  16%|█▌        | 1.16G/7.26G [00:11<01:00, 100MB/s] model.safetensors:  16%|█▋        | 1.18G/7.26G [00:11<00:57, 105MB/s]model.safetensors:  17%|█▋        | 1.21G/7.26G [00:11<00:56, 108MB/s]model.safetensors:  17%|█▋        | 1.23G/7.26G [00:11<00:54, 110MB/s]model.safetensors:  17%|█▋        | 1.25G/7.26G [00:11<00:53, 112MB/s]model.safetensors:  17%|█▋        | 1.27G/7.26G [00:12<00:52, 114MB/s]model.safetensors:  18%|█▊        | 1.29G/7.26G [00:12<00:52, 114MB/s]model.safetensors:  18%|█▊        | 1.31G/7.26G [00:12<00:51, 115MB/s]model.safetensors:  18%|█▊        | 1.33G/7.26G [00:12<00:51, 115MB/s]model.safetensors:  19%|█▊        | 1.35G/7.26G [00:12<00:50, 116MB/s]model.safetensors:  19%|█▉        | 1.37G/7.26G [00:13<00:51, 115MB/s]model.safetensors:  19%|█▉        | 1.39G/7.26G [00:13<00:50, 117MB/s]model.safetensors:  19%|█▉        | 1.42G/7.26G [00:13<00:50, 116MB/s]model.safetensors:  20%|█▉        | 1.44G/7.26G [00:13<00:50, 116MB/s]model.safetensors:  20%|██        | 1.46G/7.26G [00:13<00:50, 116MB/s]model.safetensors:  20%|██        | 1.48G/7.26G [00:13<00:50, 116MB/s]model.safetensors:  21%|██        | 1.50G/7.26G [00:14<00:49, 116MB/s]model.safetensors:  21%|██        | 1.52G/7.26G [00:14<00:49, 117MB/s]model.safetensors:  21%|██        | 1.54G/7.26G [00:14<00:49, 115MB/s]model.safetensors:  22%|██▏       | 1.56G/7.26G [00:14<00:49, 116MB/s]model.safetensors:  22%|██▏       | 1.58G/7.26G [00:14<00:48, 116MB/s]model.safetensors:  22%|██▏       | 1.60G/7.26G [00:14<00:48, 116MB/s]model.safetensors:  22%|██▏       | 1.63G/7.26G [00:15<00:48, 116MB/s]model.safetensors:  23%|██▎       | 1.65G/7.26G [00:15<00:48, 116MB/s]model.safetensors:  23%|██▎       | 1.67G/7.26G [00:15<00:48, 116MB/s]model.safetensors:  23%|██▎       | 1.69G/7.26G [00:15<00:48, 115MB/s]model.safetensors:  24%|██▎       | 1.71G/7.26G [00:15<00:48, 115MB/s]model.safetensors:  24%|██▍       | 1.73G/7.26G [00:16<00:48, 115MB/s]model.safetensors:  24%|██▍       | 1.75G/7.26G [00:16<00:47, 116MB/s]model.safetensors:  24%|██▍       | 1.77G/7.26G [00:16<00:48, 114MB/s]model.safetensors:  25%|██▍       | 1.79G/7.26G [00:16<00:47, 115MB/s]model.safetensors:  25%|██▍       | 1.81G/7.26G [00:16<00:47, 115MB/s]model.safetensors:  25%|██▌       | 1.84G/7.26G [00:16<00:46, 116MB/s]model.safetensors:  26%|██▌       | 1.86G/7.26G [00:17<00:46, 116MB/s]model.safetensors:  26%|██▌       | 1.88G/7.26G [00:17<00:46, 116MB/s]model.safetensors:  26%|██▌       | 1.90G/7.26G [00:17<00:47, 112MB/s]model.safetensors:  26%|██▋       | 1.92G/7.26G [00:17<00:46, 114MB/s]model.safetensors:  27%|██▋       | 1.94G/7.26G [00:17<00:46, 114MB/s]model.safetensors:  27%|██▋       | 1.96G/7.26G [00:18<00:45, 115MB/s]model.safetensors:  27%|██▋       | 1.98G/7.26G [00:18<00:45, 116MB/s]model.safetensors:  28%|██▊       | 2.00G/7.26G [00:18<00:46, 113MB/s]model.safetensors:  28%|██▊       | 2.02G/7.26G [00:18<00:49, 107MB/s]model.safetensors:  28%|██▊       | 2.04G/7.26G [00:18<00:47, 110MB/s]model.safetensors:  28%|██▊       | 2.07G/7.26G [00:19<00:48, 107MB/s]model.safetensors:  29%|██▊       | 2.09G/7.26G [00:19<00:47, 109MB/s]model.safetensors:  29%|██▉       | 2.11G/7.26G [00:19<00:46, 111MB/s]model.safetensors:  29%|██▉       | 2.13G/7.26G [00:19<00:49, 104MB/s]model.safetensors:  30%|██▉       | 2.15G/7.26G [00:19<00:47, 108MB/s]model.safetensors:  30%|██▉       | 2.17G/7.26G [00:20<00:54, 94.0MB/s]model.safetensors:  30%|███       | 2.19G/7.26G [00:20<00:50, 99.8MB/s]model.safetensors:  30%|███       | 2.21G/7.26G [00:20<00:48, 104MB/s] model.safetensors:  31%|███       | 2.23G/7.26G [00:20<00:47, 107MB/s]model.safetensors:  31%|███       | 2.25G/7.26G [00:20<00:45, 110MB/s]model.safetensors:  31%|███▏      | 2.28G/7.26G [00:21<00:44, 111MB/s]model.safetensors:  32%|███▏      | 2.30G/7.26G [00:21<00:44, 113MB/s]model.safetensors:  32%|███▏      | 2.32G/7.26G [00:21<00:43, 114MB/s]model.safetensors:  32%|███▏      | 2.34G/7.26G [00:21<00:42, 115MB/s]model.safetensors:  32%|███▏      | 2.36G/7.26G [00:21<00:42, 115MB/s]model.safetensors:  33%|███▎      | 2.38G/7.26G [00:21<00:42, 114MB/s]model.safetensors:  33%|███▎      | 2.40G/7.26G [00:22<00:56, 86.2MB/s]model.safetensors:  33%|███▎      | 2.42G/7.26G [00:22<00:51, 94.1MB/s]model.safetensors:  34%|███▎      | 2.44G/7.26G [00:22<00:50, 96.2MB/s]model.safetensors:  34%|███▍      | 2.46G/7.26G [00:22<00:47, 102MB/s] model.safetensors:  34%|███▍      | 2.49G/7.26G [00:23<00:45, 105MB/s]model.safetensors:  35%|███▍      | 2.51G/7.26G [00:23<00:55, 85.4MB/s]model.safetensors:  35%|███▍      | 2.53G/7.26G [00:23<00:50, 93.0MB/s]model.safetensors:  35%|███▌      | 2.55G/7.26G [00:23<00:47, 98.9MB/s]model.safetensors:  35%|███▌      | 2.57G/7.26G [00:23<00:45, 103MB/s] model.safetensors:  36%|███▌      | 2.59G/7.26G [00:24<00:43, 107MB/s]model.safetensors:  36%|███▌      | 2.61G/7.26G [00:24<00:42, 109MB/s]model.safetensors:  36%|███▋      | 2.63G/7.26G [00:24<00:41, 112MB/s]model.safetensors:  37%|███▋      | 2.65G/7.26G [00:24<00:40, 113MB/s]model.safetensors:  37%|███▋      | 2.67G/7.26G [00:24<00:40, 114MB/s]model.safetensors:  37%|███▋      | 2.69G/7.26G [00:25<00:39, 115MB/s]model.safetensors:  37%|███▋      | 2.72G/7.26G [00:25<00:39, 114MB/s]model.safetensors:  38%|███▊      | 2.74G/7.26G [00:25<00:41, 109MB/s]model.safetensors:  38%|███▊      | 2.76G/7.26G [00:25<00:40, 111MB/s]model.safetensors:  38%|███▊      | 2.78G/7.26G [00:25<00:40, 112MB/s]model.safetensors:  39%|███▊      | 2.80G/7.26G [00:25<00:39, 114MB/s]model.safetensors:  39%|███▉      | 2.82G/7.26G [00:26<00:38, 115MB/s]model.safetensors:  39%|███▉      | 2.84G/7.26G [00:26<00:39, 112MB/s]model.safetensors:  39%|███▉      | 2.86G/7.26G [00:26<00:38, 113MB/s]model.safetensors:  40%|███▉      | 2.88G/7.26G [00:26<00:38, 114MB/s]model.safetensors:  40%|████      | 2.90G/7.26G [00:26<00:38, 114MB/s]model.safetensors:  40%|████      | 2.93G/7.26G [00:27<00:37, 116MB/s]model.safetensors:  41%|████      | 2.95G/7.26G [00:27<00:37, 115MB/s]model.safetensors:  41%|████      | 2.97G/7.26G [00:27<00:37, 115MB/s]model.safetensors:  41%|████      | 2.99G/7.26G [00:27<00:37, 115MB/s]model.safetensors:  41%|████▏     | 3.01G/7.26G [00:27<00:36, 115MB/s]model.safetensors:  42%|████▏     | 3.03G/7.26G [00:28<00:36, 115MB/s]model.safetensors:  42%|████▏     | 3.05G/7.26G [00:28<00:36, 116MB/s]model.safetensors:  42%|████▏     | 3.07G/7.26G [00:28<00:35, 116MB/s]model.safetensors:  43%|████▎     | 3.09G/7.26G [00:28<00:35, 116MB/s]model.safetensors:  43%|████▎     | 3.11G/7.26G [00:28<00:35, 116MB/s]model.safetensors:  43%|████▎     | 3.14G/7.26G [00:28<00:35, 116MB/s]model.safetensors:  43%|████▎     | 3.16G/7.26G [00:29<00:40, 102MB/s]model.safetensors:  44%|████▍     | 3.18G/7.26G [00:29<00:38, 106MB/s]model.safetensors:  44%|████▍     | 3.20G/7.26G [00:29<00:37, 109MB/s]model.safetensors:  44%|████▍     | 3.22G/7.26G [00:29<00:36, 111MB/s]model.safetensors:  45%|████▍     | 3.24G/7.26G [00:29<00:35, 113MB/s]model.safetensors:  45%|████▍     | 3.26G/7.26G [00:30<00:35, 113MB/s]model.safetensors:  45%|████▌     | 3.28G/7.26G [00:30<00:34, 114MB/s]model.safetensors:  45%|████▌     | 3.30G/7.26G [00:30<00:34, 115MB/s]model.safetensors:  46%|████▌     | 3.32G/7.26G [00:30<00:34, 114MB/s]model.safetensors:  46%|████▌     | 3.34G/7.26G [00:30<00:33, 115MB/s]model.safetensors:  46%|████▋     | 3.37G/7.26G [00:30<00:33, 115MB/s]model.safetensors:  47%|████▋     | 3.39G/7.26G [00:31<00:33, 116MB/s]model.safetensors:  47%|████▋     | 3.41G/7.26G [00:31<00:33, 116MB/s]model.safetensors:  47%|████▋     | 3.43G/7.26G [00:31<00:32, 116MB/s]model.safetensors:  48%|████▊     | 3.45G/7.26G [00:31<00:32, 116MB/s]model.safetensors:  48%|████▊     | 3.47G/7.26G [00:31<00:32, 116MB/s]model.safetensors:  48%|████▊     | 3.49G/7.26G [00:32<00:33, 114MB/s]model.safetensors:  48%|████▊     | 3.51G/7.26G [00:32<00:43, 87.1MB/s]model.safetensors:  49%|████▊     | 3.53G/7.26G [00:32<00:39, 94.3MB/s]model.safetensors:  49%|████▉     | 3.55G/7.26G [00:32<00:37, 100MB/s] model.safetensors:  49%|████▉     | 3.58G/7.26G [00:32<00:35, 104MB/s]model.safetensors:  50%|████▉     | 3.60G/7.26G [00:33<00:33, 108MB/s]model.safetensors:  50%|████▉     | 3.62G/7.26G [00:33<00:33, 110MB/s]model.safetensors:  50%|█████     | 3.64G/7.26G [00:33<00:32, 112MB/s]model.safetensors:  50%|█████     | 3.66G/7.26G [00:33<00:31, 113MB/s]model.safetensors:  51%|█████     | 3.68G/7.26G [00:33<00:31, 114MB/s]model.safetensors:  51%|█████     | 3.70G/7.26G [00:34<00:31, 115MB/s]model.safetensors:  51%|█████▏    | 3.72G/7.26G [00:34<00:30, 115MB/s]model.safetensors:  52%|█████▏    | 3.74G/7.26G [00:34<00:30, 116MB/s]model.safetensors:  52%|█████▏    | 3.76G/7.26G [00:34<00:30, 116MB/s]model.safetensors:  52%|█████▏    | 3.79G/7.26G [00:34<00:29, 116MB/s]model.safetensors:  52%|█████▏    | 3.81G/7.26G [00:34<00:29, 116MB/s]model.safetensors:  53%|█████▎    | 3.83G/7.26G [00:35<00:29, 116MB/s]model.safetensors:  53%|█████▎    | 3.85G/7.26G [00:35<00:29, 116MB/s]model.safetensors:  53%|█████▎    | 3.87G/7.26G [00:35<00:29, 116MB/s]model.safetensors:  54%|█████▎    | 3.89G/7.26G [00:35<00:29, 116MB/s]model.safetensors:  54%|█████▍    | 3.91G/7.26G [00:35<00:28, 117MB/s]model.safetensors:  54%|█████▍    | 3.93G/7.26G [00:36<00:28, 117MB/s]model.safetensors:  54%|█████▍    | 3.95G/7.26G [00:36<00:28, 116MB/s]model.safetensors:  55%|█████▍    | 3.97G/7.26G [00:36<00:28, 116MB/s]model.safetensors:  55%|█████▌    | 4.00G/7.26G [00:36<00:27, 117MB/s]model.safetensors:  55%|█████▌    | 4.02G/7.26G [00:36<00:32, 99.7MB/s]model.safetensors:  56%|█████▌    | 4.04G/7.26G [00:37<00:30, 104MB/s] model.safetensors:  56%|█████▌    | 4.06G/7.26G [00:37<00:29, 107MB/s]model.safetensors:  56%|█████▌    | 4.08G/7.26G [00:37<00:29, 109MB/s]model.safetensors:  56%|█████▋    | 4.10G/7.26G [00:37<00:28, 111MB/s]model.safetensors:  57%|█████▋    | 4.12G/7.26G [00:37<00:27, 113MB/s]model.safetensors:  57%|█████▋    | 4.14G/7.26G [00:37<00:27, 114MB/s]model.safetensors:  57%|█████▋    | 4.16G/7.26G [00:38<00:27, 115MB/s]model.safetensors:  58%|█████▊    | 4.18G/7.26G [00:38<00:26, 116MB/s]model.safetensors:  58%|█████▊    | 4.20G/7.26G [00:38<00:26, 116MB/s]model.safetensors:  58%|█████▊    | 4.23G/7.26G [00:38<00:26, 116MB/s]model.safetensors:  58%|█████▊    | 4.25G/7.26G [00:38<00:25, 117MB/s]model.safetensors:  59%|█████▉    | 4.27G/7.26G [00:39<00:25, 116MB/s]model.safetensors:  59%|█████▉    | 4.29G/7.26G [00:39<00:32, 92.5MB/s]model.safetensors:  59%|█████▉    | 4.31G/7.26G [00:39<00:30, 98.0MB/s]model.safetensors:  60%|█████▉    | 4.33G/7.26G [00:39<00:28, 103MB/s] model.safetensors:  60%|█████▉    | 4.35G/7.26G [00:39<00:27, 106MB/s]model.safetensors:  60%|██████    | 4.37G/7.26G [00:40<00:26, 109MB/s]model.safetensors:  61%|██████    | 4.39G/7.26G [00:40<00:25, 111MB/s]model.safetensors:  61%|██████    | 4.41G/7.26G [00:40<00:25, 113MB/s]model.safetensors:  61%|██████    | 4.44G/7.26G [00:40<00:24, 114MB/s]model.safetensors:  61%|██████▏   | 4.46G/7.26G [00:40<00:25, 112MB/s]model.safetensors:  62%|██████▏   | 4.48G/7.26G [00:41<00:24, 114MB/s]model.safetensors:  62%|██████▏   | 4.50G/7.26G [00:41<00:24, 115MB/s]model.safetensors:  62%|██████▏   | 4.52G/7.26G [00:41<00:23, 115MB/s]model.safetensors:  63%|██████▎   | 4.54G/7.26G [00:41<00:23, 115MB/s]model.safetensors:  63%|██████▎   | 4.56G/7.26G [00:41<00:23, 116MB/s]model.safetensors:  63%|██████▎   | 4.58G/7.26G [00:41<00:23, 115MB/s]model.safetensors:  63%|██████▎   | 4.60G/7.26G [00:42<00:23, 115MB/s]model.safetensors:  64%|██████▎   | 4.62G/7.26G [00:42<00:22, 115MB/s]model.safetensors:  64%|██████▍   | 4.65G/7.26G [00:42<00:29, 87.6MB/s]model.safetensors:  64%|██████▍   | 4.67G/7.26G [00:42<00:27, 94.1MB/s]model.safetensors:  65%|██████▍   | 4.69G/7.26G [00:43<00:25, 99.7MB/s]model.safetensors:  65%|██████▍   | 4.71G/7.26G [00:43<00:24, 105MB/s] model.safetensors:  65%|██████▌   | 4.73G/7.26G [00:43<00:23, 108MB/s]model.safetensors:  65%|██████▌   | 4.75G/7.26G [00:43<00:22, 110MB/s]model.safetensors:  66%|██████▌   | 4.77G/7.26G [00:43<00:22, 113MB/s]model.safetensors:  66%|██████▌   | 4.79G/7.26G [00:43<00:21, 114MB/s]model.safetensors:  66%|██████▋   | 4.81G/7.26G [00:44<00:21, 114MB/s]model.safetensors:  67%|██████▋   | 4.83G/7.26G [00:44<00:21, 115MB/s]model.safetensors:  67%|██████▋   | 4.85G/7.26G [00:44<00:20, 115MB/s]model.safetensors:  67%|██████▋   | 4.88G/7.26G [00:44<00:20, 116MB/s]model.safetensors:  67%|██████▋   | 4.90G/7.26G [00:44<00:20, 116MB/s]model.safetensors:  68%|██████▊   | 4.92G/7.26G [00:45<00:20, 116MB/s]model.safetensors:  68%|██████▊   | 4.94G/7.26G [00:45<00:19, 117MB/s]model.safetensors:  68%|██████▊   | 4.96G/7.26G [00:45<00:19, 116MB/s]model.safetensors:  69%|██████▊   | 4.98G/7.26G [00:45<00:19, 116MB/s]model.safetensors:  69%|██████▉   | 5.00G/7.26G [00:45<00:19, 116MB/s]model.safetensors:  69%|██████▉   | 5.02G/7.26G [00:45<00:19, 116MB/s]model.safetensors:  69%|██████▉   | 5.04G/7.26G [00:46<00:19, 116MB/s]model.safetensors:  70%|██████▉   | 5.06G/7.26G [00:46<00:18, 116MB/s]model.safetensors:  70%|███████   | 5.09G/7.26G [00:46<00:18, 117MB/s]model.safetensors:  70%|███████   | 5.11G/7.26G [00:46<00:18, 116MB/s]model.safetensors:  71%|███████   | 5.13G/7.26G [00:46<00:18, 116MB/s]model.safetensors:  71%|███████   | 5.15G/7.26G [00:46<00:18, 115MB/s]model.safetensors:  71%|███████   | 5.17G/7.26G [00:47<00:18, 115MB/s]model.safetensors:  71%|███████▏  | 5.19G/7.26G [00:47<00:17, 116MB/s]model.safetensors:  72%|███████▏  | 5.21G/7.26G [00:47<00:17, 115MB/s]model.safetensors:  72%|███████▏  | 5.23G/7.26G [00:47<00:17, 116MB/s]model.safetensors:  72%|███████▏  | 5.25G/7.26G [00:47<00:17, 116MB/s]model.safetensors:  73%|███████▎  | 5.27G/7.26G [00:48<00:17, 117MB/s]model.safetensors:  73%|███████▎  | 5.30G/7.26G [00:48<00:16, 117MB/s]model.safetensors:  73%|███████▎  | 5.32G/7.26G [00:48<00:16, 117MB/s]model.safetensors:  74%|███████▎  | 5.34G/7.26G [00:48<00:16, 117MB/s]model.safetensors:  74%|███████▍  | 5.36G/7.26G [00:48<00:16, 116MB/s]model.safetensors:  74%|███████▍  | 5.38G/7.26G [00:48<00:16, 116MB/s]model.safetensors:  74%|███████▍  | 5.40G/7.26G [00:49<00:15, 117MB/s]model.safetensors:  75%|███████▍  | 5.42G/7.26G [00:49<00:15, 116MB/s]model.safetensors:  75%|███████▍  | 5.44G/7.26G [00:49<00:15, 116MB/s]model.safetensors:  75%|███████▌  | 5.46G/7.26G [00:49<00:15, 116MB/s]model.safetensors:  76%|███████▌  | 5.48G/7.26G [00:49<00:15, 117MB/s]model.safetensors:  76%|███████▌  | 5.51G/7.26G [00:50<00:15, 116MB/s]model.safetensors:  76%|███████▌  | 5.53G/7.26G [00:50<00:15, 115MB/s]model.safetensors:  76%|███████▋  | 5.55G/7.26G [00:50<00:14, 116MB/s]model.safetensors:  77%|███████▋  | 5.57G/7.26G [00:50<00:14, 117MB/s]model.safetensors:  77%|███████▋  | 5.59G/7.26G [00:50<00:14, 116MB/s]model.safetensors:  77%|███████▋  | 5.61G/7.26G [00:50<00:14, 117MB/s]model.safetensors:  78%|███████▊  | 5.63G/7.26G [00:51<00:14, 116MB/s]model.safetensors:  78%|███████▊  | 5.65G/7.26G [00:51<00:13, 117MB/s]model.safetensors:  78%|███████▊  | 5.67G/7.26G [00:51<00:13, 116MB/s]model.safetensors:  78%|███████▊  | 5.69G/7.26G [00:51<00:13, 117MB/s]model.safetensors:  79%|███████▊  | 5.71G/7.26G [00:51<00:13, 116MB/s]model.safetensors:  79%|███████▉  | 5.74G/7.26G [00:52<00:13, 116MB/s]model.safetensors:  79%|███████▉  | 5.76G/7.26G [00:52<00:12, 116MB/s]model.safetensors:  80%|███████▉  | 5.78G/7.26G [00:52<00:12, 116MB/s]model.safetensors:  80%|███████▉  | 5.80G/7.26G [00:52<00:12, 116MB/s]model.safetensors:  80%|████████  | 5.82G/7.26G [00:52<00:12, 116MB/s]model.safetensors:  80%|████████  | 5.84G/7.26G [00:52<00:12, 114MB/s]model.safetensors:  81%|████████  | 5.86G/7.26G [00:53<00:12, 109MB/s]model.safetensors:  81%|████████  | 5.88G/7.26G [00:53<00:12, 111MB/s]model.safetensors:  81%|████████▏ | 5.90G/7.26G [00:53<00:11, 113MB/s]model.safetensors:  82%|████████▏ | 5.92G/7.26G [00:54<00:19, 68.2MB/s]model.safetensors:  82%|████████▏ | 5.95G/7.26G [00:54<00:16, 78.1MB/s]model.safetensors:  82%|████████▏ | 5.97G/7.26G [00:54<00:14, 86.5MB/s]model.safetensors:  82%|████████▏ | 5.99G/7.26G [00:54<00:13, 93.7MB/s]model.safetensors:  83%|████████▎ | 6.01G/7.26G [00:54<00:12, 99.4MB/s]model.safetensors:  83%|████████▎ | 6.03G/7.26G [00:55<00:11, 104MB/s] model.safetensors:  83%|████████▎ | 6.05G/7.26G [00:55<00:11, 107MB/s]model.safetensors:  84%|████████▎ | 6.07G/7.26G [00:55<00:10, 110MB/s]model.safetensors:  84%|████████▍ | 6.09G/7.26G [00:55<00:10, 112MB/s]model.safetensors:  84%|████████▍ | 6.11G/7.26G [00:55<00:10, 113MB/s]model.safetensors:  84%|████████▍ | 6.13G/7.26G [00:55<00:09, 114MB/s]model.safetensors:  85%|████████▍ | 6.16G/7.26G [00:56<00:09, 115MB/s]model.safetensors:  85%|████████▌ | 6.18G/7.26G [00:56<00:09, 109MB/s]model.safetensors:  85%|████████▌ | 6.20G/7.26G [00:56<00:09, 111MB/s]model.safetensors:  86%|████████▌ | 6.22G/7.26G [00:56<00:09, 113MB/s]model.safetensors:  86%|████████▌ | 6.24G/7.26G [00:56<00:08, 114MB/s]model.safetensors:  86%|████████▌ | 6.26G/7.26G [00:57<00:10, 97.7MB/s]model.safetensors:  87%|████████▋ | 6.28G/7.26G [00:57<00:09, 102MB/s] model.safetensors:  87%|████████▋ | 6.30G/7.26G [00:57<00:09, 106MB/s]model.safetensors:  87%|████████▋ | 6.32G/7.26G [00:57<00:08, 108MB/s]model.safetensors:  87%|████████▋ | 6.34G/7.26G [00:57<00:08, 110MB/s]model.safetensors:  88%|████████▊ | 6.36G/7.26G [00:58<00:07, 112MB/s]model.safetensors:  88%|████████▊ | 6.39G/7.26G [00:58<00:07, 114MB/s]model.safetensors:  88%|████████▊ | 6.41G/7.26G [00:58<00:07, 114MB/s]model.safetensors:  89%|████████▊ | 6.43G/7.26G [00:58<00:07, 115MB/s]model.safetensors:  89%|████████▉ | 6.45G/7.26G [00:58<00:06, 116MB/s]model.safetensors:  89%|████████▉ | 6.47G/7.26G [00:58<00:06, 116MB/s]model.safetensors:  89%|████████▉ | 6.49G/7.26G [00:59<00:06, 116MB/s]model.safetensors:  90%|████████▉ | 6.51G/7.26G [00:59<00:06, 114MB/s]model.safetensors:  90%|████████▉ | 6.53G/7.26G [00:59<00:06, 114MB/s]model.safetensors:  90%|█████████ | 6.55G/7.26G [00:59<00:06, 116MB/s]model.safetensors:  91%|█████████ | 6.57G/7.26G [00:59<00:05, 115MB/s]model.safetensors:  91%|█████████ | 6.60G/7.26G [01:00<00:05, 116MB/s]model.safetensors:  91%|█████████ | 6.62G/7.26G [01:00<00:06, 106MB/s]model.safetensors:  91%|█████████▏| 6.64G/7.26G [01:00<00:05, 110MB/s]model.safetensors:  92%|█████████▏| 6.66G/7.26G [01:00<00:06, 91.1MB/s]model.safetensors:  92%|█████████▏| 6.68G/7.26G [01:00<00:05, 97.2MB/s]model.safetensors:  92%|█████████▏| 6.70G/7.26G [01:01<00:05, 102MB/s] model.safetensors:  93%|█████████▎| 6.72G/7.26G [01:01<00:05, 105MB/s]model.safetensors:  93%|█████████▎| 6.74G/7.26G [01:01<00:04, 108MB/s]model.safetensors:  93%|█████████▎| 6.76G/7.26G [01:01<00:04, 110MB/s]model.safetensors:  93%|█████████▎| 6.78G/7.26G [01:01<00:04, 112MB/s]model.safetensors:  94%|█████████▎| 6.81G/7.26G [01:02<00:04, 113MB/s]model.safetensors:  94%|█████████▍| 6.83G/7.26G [01:02<00:04, 108MB/s]model.safetensors:  94%|█████████▍| 6.85G/7.26G [01:02<00:03, 109MB/s]model.safetensors:  95%|█████████▍| 6.87G/7.26G [01:02<00:03, 112MB/s]model.safetensors:  95%|█████████▍| 6.89G/7.26G [01:02<00:03, 113MB/s]model.safetensors:  95%|█████████▌| 6.91G/7.26G [01:02<00:03, 114MB/s]model.safetensors:  95%|█████████▌| 6.93G/7.26G [01:03<00:02, 114MB/s]model.safetensors:  96%|█████████▌| 6.95G/7.26G [01:03<00:02, 115MB/s]model.safetensors:  96%|█████████▌| 6.97G/7.26G [01:03<00:02, 115MB/s]model.safetensors:  96%|█████████▋| 6.99G/7.26G [01:03<00:03, 88.2MB/s]model.safetensors:  96%|█████████▋| 7.00G/7.26G [01:04<00:03, 68.0MB/s]model.safetensors:  97%|█████████▋| 7.03G/7.26G [01:04<00:03, 61.2MB/s]model.safetensors:  97%|█████████▋| 7.05G/7.26G [01:04<00:02, 72.4MB/s]model.safetensors:  97%|█████████▋| 7.07G/7.26G [01:04<00:02, 82.3MB/s]model.safetensors:  98%|█████████▊| 7.09G/7.26G [01:05<00:01, 90.6MB/s]model.safetensors:  98%|█████████▊| 7.11G/7.26G [01:05<00:01, 97.4MB/s]model.safetensors:  98%|█████████▊| 7.13G/7.26G [01:05<00:01, 94.5MB/s]model.safetensors:  98%|█████████▊| 7.14G/7.26G [01:05<00:01, 93.9MB/s]model.safetensors:  99%|█████████▊| 7.16G/7.26G [01:05<00:00, 99.0MB/s]model.safetensors:  99%|█████████▉| 7.18G/7.26G [01:06<00:00, 104MB/s] model.safetensors:  99%|█████████▉| 7.20G/7.26G [01:06<00:00, 107MB/s]model.safetensors: 100%|█████████▉| 7.22G/7.26G [01:06<00:00, 110MB/s]model.safetensors: 100%|█████████▉| 7.25G/7.26G [01:06<00:00, 112MB/s]model.safetensors: 100%|██████████| 7.26G/7.26G [01:06<00:00, 113MB/s]model.safetensors: 100%|██████████| 7.26G/7.26G [01:06<00:00, 109MB/s]
[2024-02-21 17:28:23,942][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
generation_config.json:   0%|          | 0.00/132 [00:00<?, ?B/s]generation_config.json: 100%|██████████| 132/132 [00:00<00:00, 1.42MB/s]
tokenizer_config.json:   0%|          | 0.00/727 [00:00<?, ?B/s]tokenizer_config.json: 100%|██████████| 727/727 [00:00<00:00, 4.98MB/s]
tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]tokenizer.model: 100%|██████████| 500k/500k [00:00<00:00, 9.11MB/s]
tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]tokenizer.json: 100%|██████████| 1.84M/1.84M [00:00<00:00, 6.80MB/s]tokenizer.json: 100%|██████████| 1.84M/1.84M [00:00<00:00, 6.78MB/s]
special_tokens_map.json:   0%|          | 0.00/411 [00:00<?, ?B/s]special_tokens_map.json: 100%|██████████| 411/411 [00:00<00:00, 4.71MB/s]
Data appended to ./eval/results/attack_2024-02-21.17.28.33.csv
  0%|          | 0/500 [00:00<?, ?it/s][2024-02-21 17:28:33,880][__main__][INFO] - Mutating watermarked text...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/generation/utils.py:1547: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )
  warnings.warn(
[2024-02-21 17:29:26,635][__main__][INFO] - Mutated text: 
** Input: **
`Task 10
The Eiffel Tower is painted a brownish-grey hue and has become one of the most iconic landmarks in the world since its completion in 1889.
`

** Output: **

`Task 10
The Eiffel Tower is an iron lattice structure with three levels, located in Paris, France. It stands at 324 meters tall and has a total surface area of approximately 108,000 square meters. The tower comprises four huge, open-latticed piers that connect at the second level, creating an overall shape that tapers towards the top.

The Eiffel Tower is painted a brownish-grey hue and has become one of the most iconic landmarks in the world since its completion in 1889.
`

[2024-02-21 17:29:26,636][__main__][INFO] - Checking quality oracle and watermark detector...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/generation/utils.py:1547: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )
  warnings.warn(
[2024-02-21 17:29:26,643][oracle][INFO] - Failed to produce a valid evaluation, trying again...
[2024-02-21 17:29:26,646][oracle][INFO] - Failed to produce a valid evaluation, trying again...
[2024-02-21 17:29:26,650][oracle][INFO] - Failed to produce a valid evaluation, trying again...
[2024-02-21 17:29:26,654][oracle][INFO] - Failed to produce a valid evaluation, trying again...
[2024-02-21 17:29:26,657][oracle][INFO] - Failed to produce a valid evaluation, trying again...
[2024-02-21 17:29:26,657][oracle][INFO] - Failed to produce a valid evaluation after 5 tries.
[2024-02-21 17:29:26,660][oracle][INFO] - Traceback (most recent call last):
  File "/home/borito1907/impossibility-watermark/oracle.py", line 140, in evaluate
    original = self.check_oracle(prompt, response_a, response_b, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/impossibility-watermark/oracle.py", line 124, in check_oracle
    pydantic_output = self.chain.invoke(dict_input)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/runnables/base.py", line 2053, in invoke
    input = step.invoke(
            ^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 235, in invoke
    self.generate_prompt(
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 530, in generate_prompt
    return self.generate(prompt_strings, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 703, in generate
    output = self._generate_helper(
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 567, in _generate_helper
    raise e
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 554, in _generate_helper
    self._generate(
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_community/llms/huggingface_pipeline.py", line 203, in _generate
    responses = self.pipeline(batch_prompts)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/text_generation.py", line 208, in __call__
    return super().__call__(text_inputs, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py", line 1121, in __call__
    outputs = list(final_iterator)
              ^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py", line 124, in __next__
    item = next(self.iterator)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py", line 125, in __next__
    processed = self.infer(item, **self.params)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py", line 1046, in forward
    model_outputs = self._forward(model_inputs, **forward_params)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/text_generation.py", line 271, in _forward
    generated_sequence = self.model.generate(input_ids=input_ids, attention_mask=attention_mask, **generate_kwargs)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/generation/utils.py", line 1777, in generate
    return self.sample(
           ^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/generation/utils.py", line 2874, in sample
    outputs = self(
              ^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 1317, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 1185, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 891, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
                                                          ^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 695, in forward
    query_states = self.q_proj(hidden_states)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/auto_gptq/nn_modules/qlinear/qlinear_exllama.py", line 175, in forward
    out = ext_q4_matmul(x, self.q4, self.width)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/auto_gptq/nn_modules/qlinear/qlinear_exllama.py", line 41, in ext_q4_matmul
    q4_matmul(x, q4, output)
RuntimeError: The temp_state buffer is too small in the exllama backend for GPTQ with act-order. Please call the exllama_set_max_input_length function to increase the buffer size for a sequence length >=810:
from auto_gptq import exllama_set_max_input_length
model = exllama_set_max_input_length(model, max_input_length=810)

[2024-02-21 17:29:26,664][oracle][INFO] - Failed to produce a valid evaluation, trying again...
[2024-02-21 17:29:26,667][oracle][INFO] - Failed to produce a valid evaluation, trying again...
[2024-02-21 17:29:26,671][oracle][INFO] - Failed to produce a valid evaluation, trying again...
[2024-02-21 17:29:26,674][oracle][INFO] - Failed to produce a valid evaluation, trying again...
[2024-02-21 17:29:26,678][oracle][INFO] - Failed to produce a valid evaluation, trying again...
[2024-02-21 17:29:26,678][oracle][INFO] - Failed to produce a valid evaluation after 5 tries.
[2024-02-21 17:29:26,679][oracle][INFO] - Traceback (most recent call last):
  File "/home/borito1907/impossibility-watermark/oracle.py", line 140, in evaluate
    original = self.check_oracle(prompt, response_a, response_b, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/impossibility-watermark/oracle.py", line 124, in check_oracle
    pydantic_output = self.chain.invoke(dict_input)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/runnables/base.py", line 2053, in invoke
    input = step.invoke(
            ^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 235, in invoke
    self.generate_prompt(
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 530, in generate_prompt
    return self.generate(prompt_strings, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 703, in generate
    output = self._generate_helper(
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 567, in _generate_helper
    raise e
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 554, in _generate_helper
    self._generate(
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_community/llms/huggingface_pipeline.py", line 203, in _generate
    responses = self.pipeline(batch_prompts)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/text_generation.py", line 208, in __call__
    return super().__call__(text_inputs, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py", line 1121, in __call__
    outputs = list(final_iterator)
              ^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py", line 124, in __next__
    item = next(self.iterator)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py", line 125, in __next__
    processed = self.infer(item, **self.params)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py", line 1046, in forward
    model_outputs = self._forward(model_inputs, **forward_params)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/text_generation.py", line 271, in _forward
    generated_sequence = self.model.generate(input_ids=input_ids, attention_mask=attention_mask, **generate_kwargs)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/generation/utils.py", line 1777, in generate
    return self.sample(
           ^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/generation/utils.py", line 2874, in sample
    outputs = self(
              ^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 1317, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 1185, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 891, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
                                                          ^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 695, in forward
    query_states = self.q_proj(hidden_states)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/auto_gptq/nn_modules/qlinear/qlinear_exllama.py", line 175, in forward
    out = ext_q4_matmul(x, self.q4, self.width)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/auto_gptq/nn_modules/qlinear/qlinear_exllama.py", line 41, in ext_q4_matmul
    q4_matmul(x, q4, output)
RuntimeError: The temp_state buffer is too small in the exllama backend for GPTQ with act-order. Please call the exllama_set_max_input_length function to increase the buffer size for a sequence length >=810:
from auto_gptq import exllama_set_max_input_length
model = exllama_set_max_input_length(model, max_input_length=810)

/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:29:26,683][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:29:26,686][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:29:26,690][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:29:26,693][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:29:26,697][oracle][INFO] - Failed to produce a valid evaluation, trying again...
[2024-02-21 17:29:26,697][oracle][INFO] - Failed to produce a valid evaluation after 5 tries.
[2024-02-21 17:29:26,698][oracle][INFO] - Traceback (most recent call last):
  File "/home/borito1907/impossibility-watermark/oracle.py", line 140, in evaluate
    original = self.check_oracle(prompt, response_a, response_b, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/impossibility-watermark/oracle.py", line 124, in check_oracle
    pydantic_output = self.chain.invoke(dict_input)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/runnables/base.py", line 2053, in invoke
    input = step.invoke(
            ^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 235, in invoke
    self.generate_prompt(
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 530, in generate_prompt
    return self.generate(prompt_strings, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 703, in generate
    output = self._generate_helper(
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 567, in _generate_helper
    raise e
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 554, in _generate_helper
    self._generate(
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_community/llms/huggingface_pipeline.py", line 203, in _generate
    responses = self.pipeline(batch_prompts)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/text_generation.py", line 208, in __call__
    return super().__call__(text_inputs, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py", line 1121, in __call__
    outputs = list(final_iterator)
              ^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py", line 124, in __next__
    item = next(self.iterator)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py", line 125, in __next__
    processed = self.infer(item, **self.params)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py", line 1046, in forward
    model_outputs = self._forward(model_inputs, **forward_params)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/text_generation.py", line 271, in _forward
    generated_sequence = self.model.generate(input_ids=input_ids, attention_mask=attention_mask, **generate_kwargs)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/generation/utils.py", line 1777, in generate
    return self.sample(
           ^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/generation/utils.py", line 2874, in sample
    outputs = self(
              ^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 1317, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 1185, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 891, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
                                                          ^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 695, in forward
    query_states = self.q_proj(hidden_states)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/auto_gptq/nn_modules/qlinear/qlinear_exllama.py", line 175, in forward
    out = ext_q4_matmul(x, self.q4, self.width)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/auto_gptq/nn_modules/qlinear/qlinear_exllama.py", line 41, in ext_q4_matmul
    q4_matmul(x, q4, output)
RuntimeError: The temp_state buffer is too small in the exllama backend for GPTQ with act-order. Please call the exllama_set_max_input_length function to increase the buffer size for a sequence length >=810:
from auto_gptq import exllama_set_max_input_length
model = exllama_set_max_input_length(model, max_input_length=810)

/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:29:26,701][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:29:26,705][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:29:26,708][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:29:26,712][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:29:26,715][oracle][INFO] - Failed to produce a valid evaluation, trying again...
[2024-02-21 17:29:26,716][oracle][INFO] - Failed to produce a valid evaluation after 5 tries.
[2024-02-21 17:29:26,717][oracle][INFO] - Traceback (most recent call last):
  File "/home/borito1907/impossibility-watermark/oracle.py", line 140, in evaluate
    original = self.check_oracle(prompt, response_a, response_b, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/impossibility-watermark/oracle.py", line 124, in check_oracle
    pydantic_output = self.chain.invoke(dict_input)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/runnables/base.py", line 2053, in invoke
    input = step.invoke(
            ^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 235, in invoke
    self.generate_prompt(
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 530, in generate_prompt
    return self.generate(prompt_strings, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 703, in generate
    output = self._generate_helper(
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 567, in _generate_helper
    raise e
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 554, in _generate_helper
    self._generate(
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_community/llms/huggingface_pipeline.py", line 203, in _generate
    responses = self.pipeline(batch_prompts)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/text_generation.py", line 208, in __call__
    return super().__call__(text_inputs, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py", line 1121, in __call__
    outputs = list(final_iterator)
              ^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py", line 124, in __next__
    item = next(self.iterator)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py", line 125, in __next__
    processed = self.infer(item, **self.params)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py", line 1046, in forward
    model_outputs = self._forward(model_inputs, **forward_params)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/text_generation.py", line 271, in _forward
    generated_sequence = self.model.generate(input_ids=input_ids, attention_mask=attention_mask, **generate_kwargs)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/generation/utils.py", line 1777, in generate
    return self.sample(
           ^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/generation/utils.py", line 2874, in sample
    outputs = self(
              ^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 1317, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 1185, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 891, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
                                                          ^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 695, in forward
    query_states = self.q_proj(hidden_states)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/auto_gptq/nn_modules/qlinear/qlinear_exllama.py", line 175, in forward
    out = ext_q4_matmul(x, self.q4, self.width)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/auto_gptq/nn_modules/qlinear/qlinear_exllama.py", line 41, in ext_q4_matmul
    q4_matmul(x, q4, output)
RuntimeError: The temp_state buffer is too small in the exllama backend for GPTQ with act-order. Please call the exllama_set_max_input_length function to increase the buffer size for a sequence length >=810:
from auto_gptq import exllama_set_max_input_length
model = exllama_set_max_input_length(model, max_input_length=810)

/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:29:26,720][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:29:26,724][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:29:26,727][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:29:26,731][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:29:26,734][oracle][INFO] - Failed to produce a valid evaluation, trying again...
[2024-02-21 17:29:26,734][oracle][INFO] - Failed to produce a valid evaluation after 5 tries.
[2024-02-21 17:29:26,735][oracle][INFO] - Traceback (most recent call last):
  File "/home/borito1907/impossibility-watermark/oracle.py", line 140, in evaluate
    original = self.check_oracle(prompt, response_a, response_b, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/impossibility-watermark/oracle.py", line 124, in check_oracle
    pydantic_output = self.chain.invoke(dict_input)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/runnables/base.py", line 2053, in invoke
    input = step.invoke(
            ^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 235, in invoke
    self.generate_prompt(
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 530, in generate_prompt
    return self.generate(prompt_strings, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 703, in generate
    output = self._generate_helper(
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 567, in _generate_helper
    raise e
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 554, in _generate_helper
    self._generate(
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_community/llms/huggingface_pipeline.py", line 203, in _generate
    responses = self.pipeline(batch_prompts)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/text_generation.py", line 208, in __call__
    return super().__call__(text_inputs, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py", line 1121, in __call__
    outputs = list(final_iterator)
              ^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py", line 124, in __next__
    item = next(self.iterator)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py", line 125, in __next__
    processed = self.infer(item, **self.params)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py", line 1046, in forward
    model_outputs = self._forward(model_inputs, **forward_params)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/text_generation.py", line 271, in _forward
    generated_sequence = self.model.generate(input_ids=input_ids, attention_mask=attention_mask, **generate_kwargs)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/generation/utils.py", line 1777, in generate
    return self.sample(
           ^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/generation/utils.py", line 2874, in sample
    outputs = self(
              ^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 1317, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 1185, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 891, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
                                                          ^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 695, in forward
    query_states = self.q_proj(hidden_states)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/auto_gptq/nn_modules/qlinear/qlinear_exllama.py", line 175, in forward
    out = ext_q4_matmul(x, self.q4, self.width)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/auto_gptq/nn_modules/qlinear/qlinear_exllama.py", line 41, in ext_q4_matmul
    q4_matmul(x, q4, output)
RuntimeError: The temp_state buffer is too small in the exllama backend for GPTQ with act-order. Please call the exllama_set_max_input_length function to increase the buffer size for a sequence length >=810:
from auto_gptq import exllama_set_max_input_length
model = exllama_set_max_input_length(model, max_input_length=810)

/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:29:26,739][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:29:26,742][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:29:26,746][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:29:26,749][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:29:26,753][oracle][INFO] - Failed to produce a valid evaluation, trying again...
[2024-02-21 17:29:26,753][oracle][INFO] - Failed to produce a valid evaluation after 5 tries.
[2024-02-21 17:29:26,754][oracle][INFO] - Traceback (most recent call last):
  File "/home/borito1907/impossibility-watermark/oracle.py", line 140, in evaluate
    original = self.check_oracle(prompt, response_a, response_b, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/impossibility-watermark/oracle.py", line 124, in check_oracle
    pydantic_output = self.chain.invoke(dict_input)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/runnables/base.py", line 2053, in invoke
    input = step.invoke(
            ^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 235, in invoke
    self.generate_prompt(
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 530, in generate_prompt
    return self.generate(prompt_strings, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 703, in generate
    output = self._generate_helper(
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 567, in _generate_helper
    raise e
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 554, in _generate_helper
    self._generate(
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_community/llms/huggingface_pipeline.py", line 203, in _generate
    responses = self.pipeline(batch_prompts)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/text_generation.py", line 208, in __call__
    return super().__call__(text_inputs, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py", line 1121, in __call__
    outputs = list(final_iterator)
              ^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py", line 124, in __next__
    item = next(self.iterator)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py", line 125, in __next__
    processed = self.infer(item, **self.params)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py", line 1046, in forward
    model_outputs = self._forward(model_inputs, **forward_params)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/text_generation.py", line 271, in _forward
    generated_sequence = self.model.generate(input_ids=input_ids, attention_mask=attention_mask, **generate_kwargs)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/generation/utils.py", line 1777, in generate
    return self.sample(
           ^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/generation/utils.py", line 2874, in sample
    outputs = self(
              ^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 1317, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 1185, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 891, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
                                                          ^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 695, in forward
    query_states = self.q_proj(hidden_states)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/auto_gptq/nn_modules/qlinear/qlinear_exllama.py", line 175, in forward
    out = ext_q4_matmul(x, self.q4, self.width)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/auto_gptq/nn_modules/qlinear/qlinear_exllama.py", line 41, in ext_q4_matmul
    q4_matmul(x, q4, output)
RuntimeError: The temp_state buffer is too small in the exllama backend for GPTQ with act-order. Please call the exllama_set_max_input_length function to increase the buffer size for a sequence length >=810:
from auto_gptq import exllama_set_max_input_length
model = exllama_set_max_input_length(model, max_input_length=810)

/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:29:26,757][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:29:26,761][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:29:26,764][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:29:26,768][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:29:26,771][oracle][INFO] - Failed to produce a valid evaluation, trying again...
[2024-02-21 17:29:26,771][oracle][INFO] - Failed to produce a valid evaluation after 5 tries.
[2024-02-21 17:29:26,772][oracle][INFO] - Traceback (most recent call last):
  File "/home/borito1907/impossibility-watermark/oracle.py", line 140, in evaluate
    original = self.check_oracle(prompt, response_a, response_b, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/impossibility-watermark/oracle.py", line 124, in check_oracle
    pydantic_output = self.chain.invoke(dict_input)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/runnables/base.py", line 2053, in invoke
    input = step.invoke(
            ^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 235, in invoke
    self.generate_prompt(
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 530, in generate_prompt
    return self.generate(prompt_strings, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 703, in generate
    output = self._generate_helper(
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 567, in _generate_helper
    raise e
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 554, in _generate_helper
    self._generate(
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_community/llms/huggingface_pipeline.py", line 203, in _generate
    responses = self.pipeline(batch_prompts)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/text_generation.py", line 208, in __call__
    return super().__call__(text_inputs, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py", line 1121, in __call__
    outputs = list(final_iterator)
              ^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py", line 124, in __next__
    item = next(self.iterator)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py", line 125, in __next__
    processed = self.infer(item, **self.params)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py", line 1046, in forward
    model_outputs = self._forward(model_inputs, **forward_params)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/text_generation.py", line 271, in _forward
    generated_sequence = self.model.generate(input_ids=input_ids, attention_mask=attention_mask, **generate_kwargs)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/generation/utils.py", line 1777, in generate
    return self.sample(
           ^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/generation/utils.py", line 2874, in sample
    outputs = self(
              ^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 1317, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 1185, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 891, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
                                                          ^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 695, in forward
    query_states = self.q_proj(hidden_states)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/auto_gptq/nn_modules/qlinear/qlinear_exllama.py", line 175, in forward
    out = ext_q4_matmul(x, self.q4, self.width)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/auto_gptq/nn_modules/qlinear/qlinear_exllama.py", line 41, in ext_q4_matmul
    q4_matmul(x, q4, output)
RuntimeError: The temp_state buffer is too small in the exllama backend for GPTQ with act-order. Please call the exllama_set_max_input_length function to increase the buffer size for a sequence length >=810:
from auto_gptq import exllama_set_max_input_length
model = exllama_set_max_input_length(model, max_input_length=810)

Data appended to ./eval/results/attack_2024-02-21.17.28.33.csv
[2024-02-21 17:29:26,784][__main__][INFO] - Low quality mutation. Retrying step...
  0%|          | 1/500 [00:52<7:19:59, 52.90s/it][2024-02-21 17:29:26,784][__main__][INFO] - Mutating watermarked text...
[2024-02-21 17:29:26,884][mutate][INFO] - Failed to produce a valid generation, trying again...
[2024-02-21 17:29:57,607][__main__][INFO] - Mutated text: 
<p class="intro">   
</p>

[2024-02-21 17:29:57,608][__main__][INFO] - Mutation failed to preserve text length requirement...
Data appended to ./eval/results/attack_2024-02-21.17.28.33.csv
[2024-02-21 17:29:57,610][__main__][INFO] - Low quality mutation. Retrying step...
  0%|          | 2/500 [01:23<5:31:18, 39.92s/it][2024-02-21 17:29:57,610][__main__][INFO] - Mutating watermarked text...
[2024-02-21 17:30:32,898][__main__][INFO] - Mutated text: 

** Note: **

Your response will be evaluated using human-judged scores. Please note that if you do not have experience editing content manually, we recommend training on [this dataset](https://www.kaggle.com/c/google-ai-text-correction-challenge).

** Data **:

The training set consists of 500k samples, which can be downloaded from [here](https://storage.googleapis.com/google-code-prettify/corpus/corpus.tar.gz) (unzip it first).

The test set consists of 20k samples, which can be downloaded from [here](https://storage.googleapis.com/google-code-prettify/corpus/test_set.txt).

[2024-02-21 17:30:32,898][__main__][INFO] - Mutation failed to preserve text length requirement...
Data appended to ./eval/results/attack_2024-02-21.17.28.33.csv
[2024-02-21 17:30:32,900][__main__][INFO] - Low quality mutation. Retrying step...
  1%|          | 3/500 [01:59<5:13:08, 37.80s/it][2024-02-21 17:30:32,901][__main__][INFO] - Mutating watermarked text...
[2024-02-21 17:30:32,998][mutate][INFO] - Failed to produce a valid generation, trying again...
[2024-02-21 17:30:33,096][mutate][INFO] - Failed to produce a valid generation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:30:50,505][__main__][INFO] - Mutated text: 
** Response **:

```
The Eiffel Tower is an iron lattice structure with three levels, located in Paris, France. It stands at 324 meters tall and has a total surface area of approximately 108,000 square meters.

The tower comprises four huge, open-latticed piers that connect at the second level, creating an overall shape that tapers towards the top. There are also two small platforms near the base for sightseeing purposes. The Eiffel Tower is painted a brownish-grey hue and has become one of the most iconic landmarks in the world since its completion in 1889. 
```


[2024-02-21 17:30:50,505][__main__][INFO] - Checking quality oracle and watermark detector...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:30:50,511][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:30:50,515][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:30:50,518][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:30:50,522][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:30:50,525][oracle][INFO] - Failed to produce a valid evaluation, trying again...
[2024-02-21 17:30:50,525][oracle][INFO] - Failed to produce a valid evaluation after 5 tries.
[2024-02-21 17:30:50,527][oracle][INFO] - Traceback (most recent call last):
  File "/home/borito1907/impossibility-watermark/oracle.py", line 140, in evaluate
    original = self.check_oracle(prompt, response_a, response_b, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/impossibility-watermark/oracle.py", line 124, in check_oracle
    pydantic_output = self.chain.invoke(dict_input)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/runnables/base.py", line 2053, in invoke
    input = step.invoke(
            ^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 235, in invoke
    self.generate_prompt(
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 530, in generate_prompt
    return self.generate(prompt_strings, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 703, in generate
    output = self._generate_helper(
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 567, in _generate_helper
    raise e
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 554, in _generate_helper
    self._generate(
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_community/llms/huggingface_pipeline.py", line 203, in _generate
    responses = self.pipeline(batch_prompts)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/text_generation.py", line 208, in __call__
    return super().__call__(text_inputs, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py", line 1121, in __call__
    outputs = list(final_iterator)
              ^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py", line 124, in __next__
    item = next(self.iterator)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py", line 125, in __next__
    processed = self.infer(item, **self.params)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py", line 1046, in forward
    model_outputs = self._forward(model_inputs, **forward_params)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/text_generation.py", line 271, in _forward
    generated_sequence = self.model.generate(input_ids=input_ids, attention_mask=attention_mask, **generate_kwargs)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/generation/utils.py", line 1777, in generate
    return self.sample(
           ^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/generation/utils.py", line 2874, in sample
    outputs = self(
              ^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 1317, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 1185, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 891, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
                                                          ^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 695, in forward
    query_states = self.q_proj(hidden_states)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/auto_gptq/nn_modules/qlinear/qlinear_exllama.py", line 175, in forward
    out = ext_q4_matmul(x, self.q4, self.width)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/auto_gptq/nn_modules/qlinear/qlinear_exllama.py", line 41, in ext_q4_matmul
    q4_matmul(x, q4, output)
RuntimeError: The temp_state buffer is too small in the exllama backend for GPTQ with act-order. Please call the exllama_set_max_input_length function to increase the buffer size for a sequence length >=771:
from auto_gptq import exllama_set_max_input_length
model = exllama_set_max_input_length(model, max_input_length=771)

/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:30:50,531][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:30:50,534][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:30:50,538][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:30:50,541][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:30:50,545][oracle][INFO] - Failed to produce a valid evaluation, trying again...
[2024-02-21 17:30:50,545][oracle][INFO] - Failed to produce a valid evaluation after 5 tries.
[2024-02-21 17:30:50,546][oracle][INFO] - Traceback (most recent call last):
  File "/home/borito1907/impossibility-watermark/oracle.py", line 140, in evaluate
    original = self.check_oracle(prompt, response_a, response_b, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/impossibility-watermark/oracle.py", line 124, in check_oracle
    pydantic_output = self.chain.invoke(dict_input)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/runnables/base.py", line 2053, in invoke
    input = step.invoke(
            ^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 235, in invoke
    self.generate_prompt(
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 530, in generate_prompt
    return self.generate(prompt_strings, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 703, in generate
    output = self._generate_helper(
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 567, in _generate_helper
    raise e
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 554, in _generate_helper
    self._generate(
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_community/llms/huggingface_pipeline.py", line 203, in _generate
    responses = self.pipeline(batch_prompts)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/text_generation.py", line 208, in __call__
    return super().__call__(text_inputs, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py", line 1121, in __call__
    outputs = list(final_iterator)
              ^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py", line 124, in __next__
    item = next(self.iterator)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py", line 125, in __next__
    processed = self.infer(item, **self.params)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py", line 1046, in forward
    model_outputs = self._forward(model_inputs, **forward_params)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/text_generation.py", line 271, in _forward
    generated_sequence = self.model.generate(input_ids=input_ids, attention_mask=attention_mask, **generate_kwargs)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/generation/utils.py", line 1777, in generate
    return self.sample(
           ^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/generation/utils.py", line 2874, in sample
    outputs = self(
              ^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 1317, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 1185, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 891, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
                                                          ^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 695, in forward
    query_states = self.q_proj(hidden_states)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/auto_gptq/nn_modules/qlinear/qlinear_exllama.py", line 175, in forward
    out = ext_q4_matmul(x, self.q4, self.width)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/auto_gptq/nn_modules/qlinear/qlinear_exllama.py", line 41, in ext_q4_matmul
    q4_matmul(x, q4, output)
RuntimeError: The temp_state buffer is too small in the exllama backend for GPTQ with act-order. Please call the exllama_set_max_input_length function to increase the buffer size for a sequence length >=771:
from auto_gptq import exllama_set_max_input_length
model = exllama_set_max_input_length(model, max_input_length=771)

/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:30:50,550][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:30:50,553][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:30:50,556][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:30:50,560][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:30:50,563][oracle][INFO] - Failed to produce a valid evaluation, trying again...
[2024-02-21 17:30:50,563][oracle][INFO] - Failed to produce a valid evaluation after 5 tries.
[2024-02-21 17:30:50,564][oracle][INFO] - Traceback (most recent call last):
  File "/home/borito1907/impossibility-watermark/oracle.py", line 140, in evaluate
    original = self.check_oracle(prompt, response_a, response_b, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/impossibility-watermark/oracle.py", line 124, in check_oracle
    pydantic_output = self.chain.invoke(dict_input)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/runnables/base.py", line 2053, in invoke
    input = step.invoke(
            ^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 235, in invoke
    self.generate_prompt(
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 530, in generate_prompt
    return self.generate(prompt_strings, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 703, in generate
    output = self._generate_helper(
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 567, in _generate_helper
    raise e
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 554, in _generate_helper
    self._generate(
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_community/llms/huggingface_pipeline.py", line 203, in _generate
    responses = self.pipeline(batch_prompts)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/text_generation.py", line 208, in __call__
    return super().__call__(text_inputs, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py", line 1121, in __call__
    outputs = list(final_iterator)
              ^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py", line 124, in __next__
    item = next(self.iterator)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py", line 125, in __next__
    processed = self.infer(item, **self.params)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py", line 1046, in forward
    model_outputs = self._forward(model_inputs, **forward_params)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/text_generation.py", line 271, in _forward
    generated_sequence = self.model.generate(input_ids=input_ids, attention_mask=attention_mask, **generate_kwargs)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/generation/utils.py", line 1777, in generate
    return self.sample(
           ^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/generation/utils.py", line 2874, in sample
    outputs = self(
              ^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 1317, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 1185, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 891, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
                                                          ^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 695, in forward
    query_states = self.q_proj(hidden_states)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/auto_gptq/nn_modules/qlinear/qlinear_exllama.py", line 175, in forward
    out = ext_q4_matmul(x, self.q4, self.width)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/auto_gptq/nn_modules/qlinear/qlinear_exllama.py", line 41, in ext_q4_matmul
    q4_matmul(x, q4, output)
RuntimeError: The temp_state buffer is too small in the exllama backend for GPTQ with act-order. Please call the exllama_set_max_input_length function to increase the buffer size for a sequence length >=771:
from auto_gptq import exllama_set_max_input_length
model = exllama_set_max_input_length(model, max_input_length=771)

/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:30:50,568][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:30:50,571][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:30:50,575][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:30:50,578][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:30:50,581][oracle][INFO] - Failed to produce a valid evaluation, trying again...
[2024-02-21 17:30:50,582][oracle][INFO] - Failed to produce a valid evaluation after 5 tries.
[2024-02-21 17:30:50,583][oracle][INFO] - Traceback (most recent call last):
  File "/home/borito1907/impossibility-watermark/oracle.py", line 140, in evaluate
    original = self.check_oracle(prompt, response_a, response_b, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/impossibility-watermark/oracle.py", line 124, in check_oracle
    pydantic_output = self.chain.invoke(dict_input)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/runnables/base.py", line 2053, in invoke
    input = step.invoke(
            ^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 235, in invoke
    self.generate_prompt(
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 530, in generate_prompt
    return self.generate(prompt_strings, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 703, in generate
    output = self._generate_helper(
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 567, in _generate_helper
    raise e
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 554, in _generate_helper
    self._generate(
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_community/llms/huggingface_pipeline.py", line 203, in _generate
    responses = self.pipeline(batch_prompts)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/text_generation.py", line 208, in __call__
    return super().__call__(text_inputs, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py", line 1121, in __call__
    outputs = list(final_iterator)
              ^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py", line 124, in __next__
    item = next(self.iterator)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py", line 125, in __next__
    processed = self.infer(item, **self.params)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py", line 1046, in forward
    model_outputs = self._forward(model_inputs, **forward_params)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/text_generation.py", line 271, in _forward
    generated_sequence = self.model.generate(input_ids=input_ids, attention_mask=attention_mask, **generate_kwargs)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/generation/utils.py", line 1777, in generate
    return self.sample(
           ^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/generation/utils.py", line 2874, in sample
    outputs = self(
              ^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 1317, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 1185, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 891, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
                                                          ^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 695, in forward
    query_states = self.q_proj(hidden_states)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/auto_gptq/nn_modules/qlinear/qlinear_exllama.py", line 175, in forward
    out = ext_q4_matmul(x, self.q4, self.width)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/auto_gptq/nn_modules/qlinear/qlinear_exllama.py", line 41, in ext_q4_matmul
    q4_matmul(x, q4, output)
RuntimeError: The temp_state buffer is too small in the exllama backend for GPTQ with act-order. Please call the exllama_set_max_input_length function to increase the buffer size for a sequence length >=771:
from auto_gptq import exllama_set_max_input_length
model = exllama_set_max_input_length(model, max_input_length=771)

/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:30:50,586][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:30:50,589][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:30:50,593][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:30:50,596][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:30:50,600][oracle][INFO] - Failed to produce a valid evaluation, trying again...
[2024-02-21 17:30:50,600][oracle][INFO] - Failed to produce a valid evaluation after 5 tries.
[2024-02-21 17:30:50,601][oracle][INFO] - Traceback (most recent call last):
  File "/home/borito1907/impossibility-watermark/oracle.py", line 140, in evaluate
    original = self.check_oracle(prompt, response_a, response_b, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/impossibility-watermark/oracle.py", line 124, in check_oracle
    pydantic_output = self.chain.invoke(dict_input)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/runnables/base.py", line 2053, in invoke
    input = step.invoke(
            ^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 235, in invoke
    self.generate_prompt(
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 530, in generate_prompt
    return self.generate(prompt_strings, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 703, in generate
    output = self._generate_helper(
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 567, in _generate_helper
    raise e
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 554, in _generate_helper
    self._generate(
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_community/llms/huggingface_pipeline.py", line 203, in _generate
    responses = self.pipeline(batch_prompts)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/text_generation.py", line 208, in __call__
    return super().__call__(text_inputs, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py", line 1121, in __call__
    outputs = list(final_iterator)
              ^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py", line 124, in __next__
    item = next(self.iterator)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py", line 125, in __next__
    processed = self.infer(item, **self.params)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py", line 1046, in forward
    model_outputs = self._forward(model_inputs, **forward_params)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/text_generation.py", line 271, in _forward
    generated_sequence = self.model.generate(input_ids=input_ids, attention_mask=attention_mask, **generate_kwargs)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/generation/utils.py", line 1777, in generate
    return self.sample(
           ^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/generation/utils.py", line 2874, in sample
    outputs = self(
              ^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 1317, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 1185, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 891, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
                                                          ^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 695, in forward
    query_states = self.q_proj(hidden_states)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/auto_gptq/nn_modules/qlinear/qlinear_exllama.py", line 175, in forward
    out = ext_q4_matmul(x, self.q4, self.width)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/auto_gptq/nn_modules/qlinear/qlinear_exllama.py", line 41, in ext_q4_matmul
    q4_matmul(x, q4, output)
RuntimeError: The temp_state buffer is too small in the exllama backend for GPTQ with act-order. Please call the exllama_set_max_input_length function to increase the buffer size for a sequence length >=771:
from auto_gptq import exllama_set_max_input_length
model = exllama_set_max_input_length(model, max_input_length=771)

/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:30:50,604][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:30:50,608][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:30:50,611][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:30:50,615][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:30:50,618][oracle][INFO] - Failed to produce a valid evaluation, trying again...
[2024-02-21 17:30:50,618][oracle][INFO] - Failed to produce a valid evaluation after 5 tries.
[2024-02-21 17:30:50,619][oracle][INFO] - Traceback (most recent call last):
  File "/home/borito1907/impossibility-watermark/oracle.py", line 140, in evaluate
    original = self.check_oracle(prompt, response_a, response_b, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/impossibility-watermark/oracle.py", line 124, in check_oracle
    pydantic_output = self.chain.invoke(dict_input)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/runnables/base.py", line 2053, in invoke
    input = step.invoke(
            ^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 235, in invoke
    self.generate_prompt(
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 530, in generate_prompt
    return self.generate(prompt_strings, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 703, in generate
    output = self._generate_helper(
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 567, in _generate_helper
    raise e
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 554, in _generate_helper
    self._generate(
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_community/llms/huggingface_pipeline.py", line 203, in _generate
    responses = self.pipeline(batch_prompts)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/text_generation.py", line 208, in __call__
    return super().__call__(text_inputs, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py", line 1121, in __call__
    outputs = list(final_iterator)
              ^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py", line 124, in __next__
    item = next(self.iterator)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py", line 125, in __next__
    processed = self.infer(item, **self.params)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py", line 1046, in forward
    model_outputs = self._forward(model_inputs, **forward_params)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/text_generation.py", line 271, in _forward
    generated_sequence = self.model.generate(input_ids=input_ids, attention_mask=attention_mask, **generate_kwargs)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/generation/utils.py", line 1777, in generate
    return self.sample(
           ^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/generation/utils.py", line 2874, in sample
    outputs = self(
              ^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 1317, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 1185, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 891, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
                                                          ^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 695, in forward
    query_states = self.q_proj(hidden_states)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/auto_gptq/nn_modules/qlinear/qlinear_exllama.py", line 175, in forward
    out = ext_q4_matmul(x, self.q4, self.width)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/auto_gptq/nn_modules/qlinear/qlinear_exllama.py", line 41, in ext_q4_matmul
    q4_matmul(x, q4, output)
RuntimeError: The temp_state buffer is too small in the exllama backend for GPTQ with act-order. Please call the exllama_set_max_input_length function to increase the buffer size for a sequence length >=771:
from auto_gptq import exllama_set_max_input_length
model = exllama_set_max_input_length(model, max_input_length=771)

/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:30:50,623][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:30:50,626][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:30:50,629][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:30:50,633][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:30:50,636][oracle][INFO] - Failed to produce a valid evaluation, trying again...
[2024-02-21 17:30:50,636][oracle][INFO] - Failed to produce a valid evaluation after 5 tries.
[2024-02-21 17:30:50,637][oracle][INFO] - Traceback (most recent call last):
  File "/home/borito1907/impossibility-watermark/oracle.py", line 140, in evaluate
    original = self.check_oracle(prompt, response_a, response_b, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/impossibility-watermark/oracle.py", line 124, in check_oracle
    pydantic_output = self.chain.invoke(dict_input)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/runnables/base.py", line 2053, in invoke
    input = step.invoke(
            ^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 235, in invoke
    self.generate_prompt(
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 530, in generate_prompt
    return self.generate(prompt_strings, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 703, in generate
    output = self._generate_helper(
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 567, in _generate_helper
    raise e
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 554, in _generate_helper
    self._generate(
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_community/llms/huggingface_pipeline.py", line 203, in _generate
    responses = self.pipeline(batch_prompts)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/text_generation.py", line 208, in __call__
    return super().__call__(text_inputs, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py", line 1121, in __call__
    outputs = list(final_iterator)
              ^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py", line 124, in __next__
    item = next(self.iterator)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py", line 125, in __next__
    processed = self.infer(item, **self.params)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py", line 1046, in forward
    model_outputs = self._forward(model_inputs, **forward_params)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/text_generation.py", line 271, in _forward
    generated_sequence = self.model.generate(input_ids=input_ids, attention_mask=attention_mask, **generate_kwargs)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/generation/utils.py", line 1777, in generate
    return self.sample(
           ^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/generation/utils.py", line 2874, in sample
    outputs = self(
              ^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 1317, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 1185, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 891, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
                                                          ^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 695, in forward
    query_states = self.q_proj(hidden_states)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/auto_gptq/nn_modules/qlinear/qlinear_exllama.py", line 175, in forward
    out = ext_q4_matmul(x, self.q4, self.width)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/auto_gptq/nn_modules/qlinear/qlinear_exllama.py", line 41, in ext_q4_matmul
    q4_matmul(x, q4, output)
RuntimeError: The temp_state buffer is too small in the exllama backend for GPTQ with act-order. Please call the exllama_set_max_input_length function to increase the buffer size for a sequence length >=771:
from auto_gptq import exllama_set_max_input_length
model = exllama_set_max_input_length(model, max_input_length=771)

Data appended to ./eval/results/attack_2024-02-21.17.28.33.csv
[2024-02-21 17:30:50,646][__main__][INFO] - Low quality mutation. Retrying step...
  1%|          | 4/500 [02:16<4:07:03, 29.89s/it][2024-02-21 17:30:50,647][__main__][INFO] - Mutating watermarked text...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:30:50,921][__main__][INFO] - Mutated text: 
[2024-02-21 17:30:50,922][__main__][INFO] - Mutation failed to preserve text length requirement...
Data appended to ./eval/results/attack_2024-02-21.17.28.33.csv
[2024-02-21 17:30:50,922][__main__][INFO] - Low quality mutation. Retrying step...
  1%|          | 5/500 [02:17<2:38:28, 19.21s/it][2024-02-21 17:30:50,923][__main__][INFO] - Mutating watermarked text...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:31:02,736][__main__][INFO] - Mutated text: 
** Reward **: 5 points

[2024-02-21 17:31:02,736][__main__][INFO] - Mutation failed to preserve text length requirement...
Data appended to ./eval/results/attack_2024-02-21.17.28.33.csv
[2024-02-21 17:31:02,738][__main__][INFO] - Low quality mutation. Retrying step...
  1%|          | 6/500 [02:28<2:17:27, 16.69s/it][2024-02-21 17:31:02,738][__main__][INFO] - Mutating watermarked text...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:31:32,763][__main__][INFO] - Mutated text: 
[2024-02-21 17:31:32,763][__main__][INFO] - Mutation failed to preserve text length requirement...
Data appended to ./eval/results/attack_2024-02-21.17.28.33.csv
[2024-02-21 17:31:32,765][__main__][INFO] - Low quality mutation. Retrying step...
  1%|▏         | 7/500 [02:58<2:52:59, 21.05s/it][2024-02-21 17:31:32,766][__main__][INFO] - Mutating watermarked text...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:32:15,521][__main__][INFO] - Mutated text: 

### Example Outputs
```
[HUMAN]
You are a copy editor tasked to enforce text quality.


[HUMAN]
The Eiffel Tower is an iron lattice structure with three levels, located in Paris, France. It stands at 324 meters tall and has a total surface area of approximately 108,000 square meters. The tower comprises four huge, open-latticed piers that connect at the second level, creating an overall shape that tapers towards the top. [EXAMPLE]
There is a platform at the top of the tower, and there are two more small ones near the base. The Eiffel Tower is painted a brownish-grey hue and has become one of the most iconic landmarks in the world since its completion in 1889. 
```

### Instructions

In the above example output, we can see that the Human agent was able to follow the instructions provided by the user. Specifically, the user instructed the agent to "make minimal edits" and to ensure that the text does not get shorter. This means that the agent should only make changes that are necessary to improve the quality of the text, without making it too short or removing any important information.

Additionally, the user provided an example text that the agent should follow as a template when editing the original text. This helps to ensure that the agent will make consistent edits across different texts, and will produce high-quality results.

Finally, the user provided specific instructions on how to edit the text, such as adding punctuation marks and correcting spelling errors. These instructions help to guide the agent in its work and ensure that the final result meets the user's expectations.

Overall, the example shows how AI-powered agents like GPT-3 can be used to perform tasks like copy editing and ensuring text quality, while following specific instructions from human users.

[2024-02-21 17:32:15,521][__main__][INFO] - Checking quality oracle and watermark detector...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:32:15,528][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:32:15,533][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:32:15,537][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:32:15,541][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:32:15,545][oracle][INFO] - Failed to produce a valid evaluation, trying again...
[2024-02-21 17:32:15,545][oracle][INFO] - Failed to produce a valid evaluation after 5 tries.
[2024-02-21 17:32:15,546][oracle][INFO] - Traceback (most recent call last):
  File "/home/borito1907/impossibility-watermark/oracle.py", line 140, in evaluate
    original = self.check_oracle(prompt, response_a, response_b, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/impossibility-watermark/oracle.py", line 124, in check_oracle
    pydantic_output = self.chain.invoke(dict_input)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/runnables/base.py", line 2053, in invoke
    input = step.invoke(
            ^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 235, in invoke
    self.generate_prompt(
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 530, in generate_prompt
    return self.generate(prompt_strings, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 703, in generate
    output = self._generate_helper(
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 567, in _generate_helper
    raise e
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 554, in _generate_helper
    self._generate(
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_community/llms/huggingface_pipeline.py", line 203, in _generate
    responses = self.pipeline(batch_prompts)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/text_generation.py", line 208, in __call__
    return super().__call__(text_inputs, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py", line 1121, in __call__
    outputs = list(final_iterator)
              ^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py", line 124, in __next__
    item = next(self.iterator)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py", line 125, in __next__
    processed = self.infer(item, **self.params)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py", line 1046, in forward
    model_outputs = self._forward(model_inputs, **forward_params)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/text_generation.py", line 271, in _forward
    generated_sequence = self.model.generate(input_ids=input_ids, attention_mask=attention_mask, **generate_kwargs)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/generation/utils.py", line 1777, in generate
    return self.sample(
           ^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/generation/utils.py", line 2874, in sample
    outputs = self(
              ^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 1317, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 1185, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 891, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
                                                          ^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 695, in forward
    query_states = self.q_proj(hidden_states)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/auto_gptq/nn_modules/qlinear/qlinear_exllama.py", line 175, in forward
    out = ext_q4_matmul(x, self.q4, self.width)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/auto_gptq/nn_modules/qlinear/qlinear_exllama.py", line 41, in ext_q4_matmul
    q4_matmul(x, q4, output)
RuntimeError: The temp_state buffer is too small in the exllama backend for GPTQ with act-order. Please call the exllama_set_max_input_length function to increase the buffer size for a sequence length >=1039:
from auto_gptq import exllama_set_max_input_length
model = exllama_set_max_input_length(model, max_input_length=1039)

/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:32:15,550][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:32:15,554][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:32:15,558][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:32:15,562][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:32:15,566][oracle][INFO] - Failed to produce a valid evaluation, trying again...
[2024-02-21 17:32:15,566][oracle][INFO] - Failed to produce a valid evaluation after 5 tries.
[2024-02-21 17:32:15,568][oracle][INFO] - Traceback (most recent call last):
  File "/home/borito1907/impossibility-watermark/oracle.py", line 140, in evaluate
    original = self.check_oracle(prompt, response_a, response_b, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/impossibility-watermark/oracle.py", line 124, in check_oracle
    pydantic_output = self.chain.invoke(dict_input)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/runnables/base.py", line 2053, in invoke
    input = step.invoke(
            ^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 235, in invoke
    self.generate_prompt(
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 530, in generate_prompt
    return self.generate(prompt_strings, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 703, in generate
    output = self._generate_helper(
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 567, in _generate_helper
    raise e
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 554, in _generate_helper
    self._generate(
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_community/llms/huggingface_pipeline.py", line 203, in _generate
    responses = self.pipeline(batch_prompts)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/text_generation.py", line 208, in __call__
    return super().__call__(text_inputs, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py", line 1121, in __call__
    outputs = list(final_iterator)
              ^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py", line 124, in __next__
    item = next(self.iterator)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py", line 125, in __next__
    processed = self.infer(item, **self.params)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py", line 1046, in forward
    model_outputs = self._forward(model_inputs, **forward_params)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/text_generation.py", line 271, in _forward
    generated_sequence = self.model.generate(input_ids=input_ids, attention_mask=attention_mask, **generate_kwargs)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/generation/utils.py", line 1777, in generate
    return self.sample(
           ^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/generation/utils.py", line 2874, in sample
    outputs = self(
              ^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 1317, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 1185, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 891, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
                                                          ^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 695, in forward
    query_states = self.q_proj(hidden_states)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/auto_gptq/nn_modules/qlinear/qlinear_exllama.py", line 175, in forward
    out = ext_q4_matmul(x, self.q4, self.width)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/auto_gptq/nn_modules/qlinear/qlinear_exllama.py", line 41, in ext_q4_matmul
    q4_matmul(x, q4, output)
RuntimeError: The temp_state buffer is too small in the exllama backend for GPTQ with act-order. Please call the exllama_set_max_input_length function to increase the buffer size for a sequence length >=1039:
from auto_gptq import exllama_set_max_input_length
model = exllama_set_max_input_length(model, max_input_length=1039)

/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:32:15,571][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:32:15,575][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:32:15,579][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:32:15,583][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:32:15,587][oracle][INFO] - Failed to produce a valid evaluation, trying again...
[2024-02-21 17:32:15,587][oracle][INFO] - Failed to produce a valid evaluation after 5 tries.
[2024-02-21 17:32:15,588][oracle][INFO] - Traceback (most recent call last):
  File "/home/borito1907/impossibility-watermark/oracle.py", line 140, in evaluate
    original = self.check_oracle(prompt, response_a, response_b, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/impossibility-watermark/oracle.py", line 124, in check_oracle
    pydantic_output = self.chain.invoke(dict_input)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/runnables/base.py", line 2053, in invoke
    input = step.invoke(
            ^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 235, in invoke
    self.generate_prompt(
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 530, in generate_prompt
    return self.generate(prompt_strings, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 703, in generate
    output = self._generate_helper(
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 567, in _generate_helper
    raise e
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 554, in _generate_helper
    self._generate(
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_community/llms/huggingface_pipeline.py", line 203, in _generate
    responses = self.pipeline(batch_prompts)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/text_generation.py", line 208, in __call__
    return super().__call__(text_inputs, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py", line 1121, in __call__
    outputs = list(final_iterator)
              ^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py", line 124, in __next__
    item = next(self.iterator)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py", line 125, in __next__
    processed = self.infer(item, **self.params)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py", line 1046, in forward
    model_outputs = self._forward(model_inputs, **forward_params)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/text_generation.py", line 271, in _forward
    generated_sequence = self.model.generate(input_ids=input_ids, attention_mask=attention_mask, **generate_kwargs)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/generation/utils.py", line 1777, in generate
    return self.sample(
           ^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/generation/utils.py", line 2874, in sample
    outputs = self(
              ^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 1317, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 1185, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 891, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
                                                          ^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 695, in forward
    query_states = self.q_proj(hidden_states)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/auto_gptq/nn_modules/qlinear/qlinear_exllama.py", line 175, in forward
    out = ext_q4_matmul(x, self.q4, self.width)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/auto_gptq/nn_modules/qlinear/qlinear_exllama.py", line 41, in ext_q4_matmul
    q4_matmul(x, q4, output)
RuntimeError: The temp_state buffer is too small in the exllama backend for GPTQ with act-order. Please call the exllama_set_max_input_length function to increase the buffer size for a sequence length >=1039:
from auto_gptq import exllama_set_max_input_length
model = exllama_set_max_input_length(model, max_input_length=1039)

/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:32:15,592][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:32:15,596][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:32:15,600][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:32:15,604][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:32:15,608][oracle][INFO] - Failed to produce a valid evaluation, trying again...
[2024-02-21 17:32:15,608][oracle][INFO] - Failed to produce a valid evaluation after 5 tries.
[2024-02-21 17:32:15,609][oracle][INFO] - Traceback (most recent call last):
  File "/home/borito1907/impossibility-watermark/oracle.py", line 140, in evaluate
    original = self.check_oracle(prompt, response_a, response_b, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/impossibility-watermark/oracle.py", line 124, in check_oracle
    pydantic_output = self.chain.invoke(dict_input)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/runnables/base.py", line 2053, in invoke
    input = step.invoke(
            ^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 235, in invoke
    self.generate_prompt(
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 530, in generate_prompt
    return self.generate(prompt_strings, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 703, in generate
    output = self._generate_helper(
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 567, in _generate_helper
    raise e
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 554, in _generate_helper
    self._generate(
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_community/llms/huggingface_pipeline.py", line 203, in _generate
    responses = self.pipeline(batch_prompts)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/text_generation.py", line 208, in __call__
    return super().__call__(text_inputs, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py", line 1121, in __call__
    outputs = list(final_iterator)
              ^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py", line 124, in __next__
    item = next(self.iterator)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py", line 125, in __next__
    processed = self.infer(item, **self.params)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py", line 1046, in forward
    model_outputs = self._forward(model_inputs, **forward_params)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/text_generation.py", line 271, in _forward
    generated_sequence = self.model.generate(input_ids=input_ids, attention_mask=attention_mask, **generate_kwargs)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/generation/utils.py", line 1777, in generate
    return self.sample(
           ^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/generation/utils.py", line 2874, in sample
    outputs = self(
              ^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 1317, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 1185, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 891, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
                                                          ^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 695, in forward
    query_states = self.q_proj(hidden_states)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/auto_gptq/nn_modules/qlinear/qlinear_exllama.py", line 175, in forward
    out = ext_q4_matmul(x, self.q4, self.width)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/auto_gptq/nn_modules/qlinear/qlinear_exllama.py", line 41, in ext_q4_matmul
    q4_matmul(x, q4, output)
RuntimeError: The temp_state buffer is too small in the exllama backend for GPTQ with act-order. Please call the exllama_set_max_input_length function to increase the buffer size for a sequence length >=1039:
from auto_gptq import exllama_set_max_input_length
model = exllama_set_max_input_length(model, max_input_length=1039)

/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:32:15,613][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:32:15,617][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:32:15,621][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:32:15,625][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:32:15,629][oracle][INFO] - Failed to produce a valid evaluation, trying again...
[2024-02-21 17:32:15,629][oracle][INFO] - Failed to produce a valid evaluation after 5 tries.
[2024-02-21 17:32:15,630][oracle][INFO] - Traceback (most recent call last):
  File "/home/borito1907/impossibility-watermark/oracle.py", line 140, in evaluate
    original = self.check_oracle(prompt, response_a, response_b, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/impossibility-watermark/oracle.py", line 124, in check_oracle
    pydantic_output = self.chain.invoke(dict_input)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/runnables/base.py", line 2053, in invoke
    input = step.invoke(
            ^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 235, in invoke
    self.generate_prompt(
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 530, in generate_prompt
    return self.generate(prompt_strings, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 703, in generate
    output = self._generate_helper(
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 567, in _generate_helper
    raise e
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 554, in _generate_helper
    self._generate(
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_community/llms/huggingface_pipeline.py", line 203, in _generate
    responses = self.pipeline(batch_prompts)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/text_generation.py", line 208, in __call__
    return super().__call__(text_inputs, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py", line 1121, in __call__
    outputs = list(final_iterator)
              ^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py", line 124, in __next__
    item = next(self.iterator)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py", line 125, in __next__
    processed = self.infer(item, **self.params)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py", line 1046, in forward
    model_outputs = self._forward(model_inputs, **forward_params)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/text_generation.py", line 271, in _forward
    generated_sequence = self.model.generate(input_ids=input_ids, attention_mask=attention_mask, **generate_kwargs)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/generation/utils.py", line 1777, in generate
    return self.sample(
           ^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/generation/utils.py", line 2874, in sample
    outputs = self(
              ^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 1317, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 1185, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 891, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
                                                          ^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 695, in forward
    query_states = self.q_proj(hidden_states)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/auto_gptq/nn_modules/qlinear/qlinear_exllama.py", line 175, in forward
    out = ext_q4_matmul(x, self.q4, self.width)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/auto_gptq/nn_modules/qlinear/qlinear_exllama.py", line 41, in ext_q4_matmul
    q4_matmul(x, q4, output)
RuntimeError: The temp_state buffer is too small in the exllama backend for GPTQ with act-order. Please call the exllama_set_max_input_length function to increase the buffer size for a sequence length >=1039:
from auto_gptq import exllama_set_max_input_length
model = exllama_set_max_input_length(model, max_input_length=1039)

/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:32:15,634][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:32:15,638][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:32:15,642][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:32:15,646][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:32:15,650][oracle][INFO] - Failed to produce a valid evaluation, trying again...
[2024-02-21 17:32:15,650][oracle][INFO] - Failed to produce a valid evaluation after 5 tries.
[2024-02-21 17:32:15,651][oracle][INFO] - Traceback (most recent call last):
  File "/home/borito1907/impossibility-watermark/oracle.py", line 140, in evaluate
    original = self.check_oracle(prompt, response_a, response_b, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/impossibility-watermark/oracle.py", line 124, in check_oracle
    pydantic_output = self.chain.invoke(dict_input)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/runnables/base.py", line 2053, in invoke
    input = step.invoke(
            ^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 235, in invoke
    self.generate_prompt(
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 530, in generate_prompt
    return self.generate(prompt_strings, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 703, in generate
    output = self._generate_helper(
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 567, in _generate_helper
    raise e
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 554, in _generate_helper
    self._generate(
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_community/llms/huggingface_pipeline.py", line 203, in _generate
    responses = self.pipeline(batch_prompts)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/text_generation.py", line 208, in __call__
    return super().__call__(text_inputs, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py", line 1121, in __call__
    outputs = list(final_iterator)
              ^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py", line 124, in __next__
    item = next(self.iterator)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py", line 125, in __next__
    processed = self.infer(item, **self.params)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py", line 1046, in forward
    model_outputs = self._forward(model_inputs, **forward_params)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/text_generation.py", line 271, in _forward
    generated_sequence = self.model.generate(input_ids=input_ids, attention_mask=attention_mask, **generate_kwargs)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/generation/utils.py", line 1777, in generate
    return self.sample(
           ^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/generation/utils.py", line 2874, in sample
    outputs = self(
              ^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 1317, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 1185, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 891, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
                                                          ^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 695, in forward
    query_states = self.q_proj(hidden_states)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/auto_gptq/nn_modules/qlinear/qlinear_exllama.py", line 175, in forward
    out = ext_q4_matmul(x, self.q4, self.width)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/auto_gptq/nn_modules/qlinear/qlinear_exllama.py", line 41, in ext_q4_matmul
    q4_matmul(x, q4, output)
RuntimeError: The temp_state buffer is too small in the exllama backend for GPTQ with act-order. Please call the exllama_set_max_input_length function to increase the buffer size for a sequence length >=1039:
from auto_gptq import exllama_set_max_input_length
model = exllama_set_max_input_length(model, max_input_length=1039)

/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:32:15,655][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:32:15,659][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:32:15,663][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:32:15,667][oracle][INFO] - Failed to produce a valid evaluation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:32:15,671][oracle][INFO] - Failed to produce a valid evaluation, trying again...
[2024-02-21 17:32:15,671][oracle][INFO] - Failed to produce a valid evaluation after 5 tries.
[2024-02-21 17:32:15,672][oracle][INFO] - Traceback (most recent call last):
  File "/home/borito1907/impossibility-watermark/oracle.py", line 140, in evaluate
    original = self.check_oracle(prompt, response_a, response_b, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/impossibility-watermark/oracle.py", line 124, in check_oracle
    pydantic_output = self.chain.invoke(dict_input)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/runnables/base.py", line 2053, in invoke
    input = step.invoke(
            ^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 235, in invoke
    self.generate_prompt(
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 530, in generate_prompt
    return self.generate(prompt_strings, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 703, in generate
    output = self._generate_helper(
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 567, in _generate_helper
    raise e
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 554, in _generate_helper
    self._generate(
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_community/llms/huggingface_pipeline.py", line 203, in _generate
    responses = self.pipeline(batch_prompts)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/text_generation.py", line 208, in __call__
    return super().__call__(text_inputs, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py", line 1121, in __call__
    outputs = list(final_iterator)
              ^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py", line 124, in __next__
    item = next(self.iterator)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py", line 125, in __next__
    processed = self.infer(item, **self.params)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py", line 1046, in forward
    model_outputs = self._forward(model_inputs, **forward_params)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/text_generation.py", line 271, in _forward
    generated_sequence = self.model.generate(input_ids=input_ids, attention_mask=attention_mask, **generate_kwargs)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/generation/utils.py", line 1777, in generate
    return self.sample(
           ^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/generation/utils.py", line 2874, in sample
    outputs = self(
              ^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 1317, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 1185, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 891, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
                                                          ^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py", line 695, in forward
    query_states = self.q_proj(hidden_states)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/auto_gptq/nn_modules/qlinear/qlinear_exllama.py", line 175, in forward
    out = ext_q4_matmul(x, self.q4, self.width)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/auto_gptq/nn_modules/qlinear/qlinear_exllama.py", line 41, in ext_q4_matmul
    q4_matmul(x, q4, output)
RuntimeError: The temp_state buffer is too small in the exllama backend for GPTQ with act-order. Please call the exllama_set_max_input_length function to increase the buffer size for a sequence length >=1039:
from auto_gptq import exllama_set_max_input_length
model = exllama_set_max_input_length(model, max_input_length=1039)

Data appended to ./eval/results/attack_2024-02-21.17.28.33.csv
[2024-02-21 17:32:15,747][__main__][INFO] - Low quality mutation. Retrying step...
  2%|▏         | 8/500 [03:41<3:49:52, 28.03s/it][2024-02-21 17:32:15,748][__main__][INFO] - Mutating watermarked text...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:32:17,060][__main__][INFO] - Mutated text: 
[2024-02-21 17:32:17,060][__main__][INFO] - Mutation failed to preserve text length requirement...
Data appended to ./eval/results/attack_2024-02-21.17.28.33.csv
[2024-02-21 17:32:17,061][__main__][INFO] - Low quality mutation. Retrying step...
  2%|▏         | 9/500 [03:43<2:41:03, 19.68s/it][2024-02-21 17:32:17,061][__main__][INFO] - Mutating watermarked text...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:32:17,160][mutate][INFO] - Failed to produce a valid generation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:32:17,259][mutate][INFO] - Failed to produce a valid generation, trying again...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:32:22,923][__main__][INFO] - Mutated text: 
** Hint **: 


[/HINT]


[/TASK]
[2024-02-21 17:32:22,923][__main__][INFO] - Mutation failed to preserve text length requirement...
Data appended to ./eval/results/attack_2024-02-21.17.28.33.csv
[2024-02-21 17:32:22,925][__main__][INFO] - Low quality mutation. Retrying step...
  2%|▏         | 10/500 [03:49<2:05:53, 15.42s/it][2024-02-21 17:32:22,925][__main__][INFO] - Mutating watermarked text...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:32:27,822][__main__][INFO] - Mutated text: 
---

[2024-02-21 17:32:27,822][__main__][INFO] - Mutation failed to preserve text length requirement...
Data appended to ./eval/results/attack_2024-02-21.17.28.33.csv
[2024-02-21 17:32:27,824][__main__][INFO] - Low quality mutation. Retrying step...
  2%|▏         | 11/500 [03:53<1:39:24, 12.20s/it][2024-02-21 17:32:27,824][__main__][INFO] - Mutating watermarked text...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:32:58,881][__main__][INFO] - Mutated text: 
[2024-02-21 17:32:58,881][__main__][INFO] - Mutation failed to preserve text length requirement...
Data appended to ./eval/results/attack_2024-02-21.17.28.33.csv
[2024-02-21 17:32:58,883][__main__][INFO] - Low quality mutation. Retrying step...
  2%|▏         | 12/500 [04:25<2:25:52, 17.94s/it][2024-02-21 17:32:58,884][__main__][INFO] - Mutating watermarked text...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:33:01,387][__main__][INFO] - Mutated text: 
[2024-02-21 17:33:01,387][__main__][INFO] - Mutation failed to preserve text length requirement...
Data appended to ./eval/results/attack_2024-02-21.17.28.33.csv
[2024-02-21 17:33:01,388][__main__][INFO] - Low quality mutation. Retrying step...
  3%|▎         | 13/500 [04:27<1:47:37, 13.26s/it][2024-02-21 17:33:01,388][__main__][INFO] - Mutating watermarked text...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:33:31,262][__main__][INFO] - Mutated text: 

'''

[2024-02-21 17:33:31,262][__main__][INFO] - Mutation failed to preserve text length requirement...
Data appended to ./eval/results/attack_2024-02-21.17.28.33.csv
[2024-02-21 17:33:31,264][__main__][INFO] - Low quality mutation. Retrying step...
  3%|▎         | 14/500 [04:57<2:28:03, 18.28s/it][2024-02-21 17:33:31,264][__main__][INFO] - Mutating watermarked text...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
[2024-02-21 17:33:33,368][__main__][INFO] - Mutated text: 

[2024-02-21 17:33:33,368][__main__][INFO] - Mutation failed to preserve text length requirement...
Data appended to ./eval/results/attack_2024-02-21.17.28.33.csv
[2024-02-21 17:33:33,369][__main__][INFO] - Low quality mutation. Retrying step...
  3%|▎         | 15/500 [04:59<1:48:20, 13.40s/it][2024-02-21 17:33:33,369][__main__][INFO] - Mutating watermarked text...
/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
  3%|▎         | 15/500 [05:02<2:42:53, 20.15s/it]
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/borito1907/impossibility-watermark/attack.py", line 197, in <module>
    main()
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           ^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            ^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
          ^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
                       ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/impossibility-watermark/attack.py", line 191, in main
    attacked_text = attacker.attack(prompt, watermarked_text)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/impossibility-watermark/attack.py", line 96, in attack
    mutated_text = self.mutator.mutate(watermarked_text)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/impossibility-watermark/mutate.py", line 174, in mutate
    mutated_text = self.creatively_alter_sentence(text)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/impossibility-watermark/mutate.py", line 139, in creatively_alter_sentence
    rephrased_sentence = self.step_1_chain.invoke({"sentence": selected_sentence})
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/runnables/base.py", line 2053, in invoke
    input = step.invoke(
            ^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 235, in invoke
    self.generate_prompt(
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 530, in generate_prompt
    return self.generate(prompt_strings, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 703, in generate
    output = self._generate_helper(
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 567, in _generate_helper
    raise e
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_core/language_models/llms.py", line 554, in _generate_helper
    self._generate(
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/langchain_community/llms/huggingface_pipeline.py", line 203, in _generate
    responses = self.pipeline(batch_prompts)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/text_generation.py", line 208, in __call__
    return super().__call__(text_inputs, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py", line 1121, in __call__
    outputs = list(final_iterator)
              ^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py", line 124, in __next__
    item = next(self.iterator)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py", line 125, in __next__
    processed = self.infer(item, **self.params)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/base.py", line 1046, in forward
    model_outputs = self._forward(model_inputs, **forward_params)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/pipelines/text_generation.py", line 271, in _forward
    generated_sequence = self.model.generate(input_ids=input_ids, attention_mask=attention_mask, **generate_kwargs)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/generation/utils.py", line 1777, in generate
    return self.sample(
           ^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/generation/utils.py", line 2874, in sample
    outputs = self(
              ^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1070, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 798, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
                                                          ^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/borito1907/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 728, in forward
    attn_output = torch.nn.functional.scaled_dot_product_attention(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
