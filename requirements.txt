torch
auto-gptq
datasets
hydra-core
jsonlines
nltk
numpy
optimum
pandas
protobuf
python-dotenv
scipy
sentencepiece
tiktoken
cython
langchain
openai
langchain-openai
langchain_community
transformers==4.42.0
accelerate
# textdiversity
# lexical_diversity
openai
nearpy
more-itertools
nearpy
guidance
langdetect

# extractors
language_tool_python
evaluate
flash-attn

# llama.cpp
--extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu124 # or cuXXX (124 = 12.4) depending on what you see for CUDA Version after running nvidia-smi
llama-cpp-python==0.2.82

# training
# torchtune
# setfit

# oracles
# prometheus-eval

# rewardbench.internlm
einops

# attack
python-socketio
