/local1/borito1907/anaconda3/envs/watermark/lib/python3.12/site-packages/langchain/_api/module_import.py:87: LangChainDeprecationWarning: Importing GuardrailsOutputParser from langchain.output_parsers is deprecated. Please replace the import with the following:
from langchain_community.output_parsers.rail_parser import GuardrailsOutputParser
  warnings.warn(
[2024-05-02 23:28:21,198][root][INFO] - Configuration: attack_args:
  prompt: null
  prompt_file: ./inputs/dynamic_prompts.csv
  prompt_num: 6
  watermarked_text: null
  watermarked_text_path: null
  watermarked_text_num: 1
  num_steps: 100
  patience: 100
  stop_at_removal: false
  num_successful_steps: 25
  results_dir: null
  model_cache_dir: ./.cache
  save_name: null
  use_watermark: true
  backtrack_patience: 25
  is_completion: false
  json_path: null
  json_index: 0
  is_continuation: false
  prev_csv_file: null
  cuda: '1'
generator_args:
  model_name_or_path: MaziyarPanahi/Meta-Llama-3-70B-Instruct-GPTQ
  revision: main
  model_cache_dir: ${attack_args.model_cache_dir}
  device_map: auto
  trust_remote_code: true
  max_new_tokens: 1024
  do_sample: true
  temperature: 0.7
  top_p: 0.95
  top_k: 40
  repetition_penalty: 1.1
  watermark_score_threshold: 5.0
  cuda: ${attack_args.cuda}
oracle_args:
  num_retries: 5
  use_system_profile: true
  system_profile: You are an impartial judge tasked to evaluate the quality of two
    prompt responses.
  model_name_or_path: MaziyarPanahi/Meta-Llama-3-70B-Instruct-GPTQ
  revision: main
  model_cache_dir: ${attack_args.model_cache_dir}
  device_map: auto
  trust_remote_code: true
  max_new_tokens: 1024
  do_sample: true
  temperature: 0.7
  top_p: 0.95
  top_k: 40
  repetition_penalty: 1.1
  cuda: ${attack_args.cuda}
  is_completion: ${attack_args.is_completion}
  watermark_score_threshold: 5.0
mutator_args:
  use_old_mutator: false
  use_system_profile: true
  system_profile: You are a copy editor tasked to enforce text quality.
  num_retries: 5
  model_name_or_path: TheBloke/Mixtral-8x7B-Instruct-v0.1-GPTQ
  revision: main
  model_cache_dir: ${attack_args.model_cache_dir}
  device_map: ${generator_args.device_map}
  trust_remote_code: ${generator_args.trust_remote_code}
  max_new_tokens: ${generator_args.max_new_tokens}
  do_sample: ${generator_args.do_sample}
  temperature: ${generator_args.temperature}
  top_p: ${generator_args.top_p}
  top_k: ${generator_args.top_k}
  repetition_penalty: ${generator_args.repetition_penalty}
  cuda: ${attack_args.cuda}
  use_pydantic_parser: false
watermark_args:
  name: umd
  gamma: 0.25
  delta: 2.0
  seeding_scheme: selfhash
  ignore_repeated_ngrams: true
  normalizers: []
  z_threshold: 0.5
  device: cuda
distinguisher:
  entropy: 1
  output_1: 1
  attack_id_1: 5
  output_2: 3
  attack_id_2: 1
  log_suffix: ''
  num_trials: 10
  num_repetitions: 5
  mutation_num: -1
  matcher: local

[2024-05-02 23:28:21,353][distinguish][INFO] - Initializing a new Distinguisher pipeline from cfg...
[2024-05-02 23:28:21,354][model_builders.pipeline][INFO] - Initializing MaziyarPanahi/Meta-Llama-3-70B-Instruct-GPTQ
/local1/borito1907/anaconda3/envs/watermark/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Error executing job with overrides: ['+distinguisher=local_distinguisher']
Traceback (most recent call last):
  File "/local1/borito1907/anaconda3/envs/watermark/lib/python3.12/importlib/metadata/__init__.py", line 397, in from_name
    return next(cls.discover(name=name))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
StopIteration

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/local1/borito1907/impossibility-watermark/optimized_distinguisher.py", line 95, in main
    distinguisher_object = Distinguisher(cfg.generator_args)
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local1/borito1907/impossibility-watermark/distinguish.py", line 56, in __init__
    self.pipeline = PipeLineBuilder(self.cfg)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local1/borito1907/impossibility-watermark/model_builders/pipeline.py", line 36, in __init__
    self.model = AutoModelForCausalLM.from_pretrained(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local1/borito1907/anaconda3/envs/watermark/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py", line 566, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local1/borito1907/anaconda3/envs/watermark/lib/python3.12/site-packages/transformers/modeling_utils.py", line 3055, in from_pretrained
    gptq_supports_cpu = version.parse(importlib.metadata.version("auto-gptq")) > version.parse("0.4.2")
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local1/borito1907/anaconda3/envs/watermark/lib/python3.12/importlib/metadata/__init__.py", line 888, in version
    return distribution(distribution_name).version
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local1/borito1907/anaconda3/envs/watermark/lib/python3.12/importlib/metadata/__init__.py", line 861, in distribution
    return Distribution.from_name(distribution_name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local1/borito1907/anaconda3/envs/watermark/lib/python3.12/importlib/metadata/__init__.py", line 399, in from_name
    raise PackageNotFoundError(name)
importlib.metadata.PackageNotFoundError: No package metadata was found for auto-gptq

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
