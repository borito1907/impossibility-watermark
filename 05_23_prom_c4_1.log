/local1/borito1907/anaconda3/envs/watermark_2/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
CUDA extension not installed.
CUDA extension not installed.
In file included from /local1/borito1907/anaconda3/envs/watermark_2/lib/python3.10/site-packages/numpy/core/include/numpy/ndarraytypes.h:1960,
                 from /local1/borito1907/anaconda3/envs/watermark_2/lib/python3.10/site-packages/numpy/core/include/numpy/ndarrayobject.h:12,
                 from /local1/borito1907/anaconda3/envs/watermark_2/lib/python3.10/site-packages/numpy/core/include/numpy/arrayobject.h:5,
                 from /home/borito1907/.pyxbld/temp.linux-x86_64-cpython-310/local1/borito1907/impossibility-watermark/levenshtein.c:1240:
/local1/borito1907/anaconda3/envs/watermark_2/lib/python3.10/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2: warning: #warning "Using deprecated NumPy API, disable it with " "#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION" [-Wcpp]
   17 | #warning "Using deprecated NumPy API, disable it with " \
      |  ^~~~~~~
[nltk_data] Downloading package punkt to /home/borito1907/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
CUDA_VISIBLE_DEVICES: 3,4,5,6,7
WORLD_SIZE: 5
[2024-05-24 00:19:41,175][model_builders.pipeline][INFO] - Initializing MaziyarPanahi/Meta-Llama-3-70B-Instruct-GPTQ
/local1/borito1907/anaconda3/envs/watermark_2/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
WARNING - Exllamav2 kernel is not installed, reset disable_exllamav2 to True. This may because you installed auto_gptq using a pre-build wheel on Windows, in which exllama_kernels are not compiled. To use exllama_kernels to further speedup inference, you can re-install auto_gptq from source.
[2024-05-24 00:19:41,322][auto_gptq.modeling._base][WARNING] - Exllamav2 kernel is not installed, reset disable_exllamav2 to True. This may because you installed auto_gptq using a pre-build wheel on Windows, in which exllama_kernels are not compiled. To use exllama_kernels to further speedup inference, you can re-install auto_gptq from source.
WARNING - CUDA kernels for auto_gptq are not installed, this will result in very slow inference speed. This may because:
1. You disabled CUDA extensions compilation by setting BUILD_CUDA_EXT=0 when install auto_gptq from source.
2. You are using pytorch without CUDA support.
3. CUDA and nvcc are not installed in your device.
[2024-05-24 00:19:41,322][auto_gptq.modeling._base][WARNING] - CUDA kernels for auto_gptq are not installed, this will result in very slow inference speed. This may because:
1. You disabled CUDA extensions compilation by setting BUILD_CUDA_EXT=0 when install auto_gptq from source.
2. You are using pytorch without CUDA support.
3. CUDA and nvcc are not installed in your device.
INFO - The layer lm_head is not quantized.
[2024-05-24 00:19:41,985][auto_gptq.modeling._base][INFO] - The layer lm_head is not quantized.
[2024-05-24 00:19:46,901][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Traceback (most recent call last):
  File "/local1/borito1907/impossibility-watermark/attack.py", line 250, in <module>
    main()
  File "/local1/borito1907/anaconda3/envs/watermark_2/lib/python3.10/site-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
  File "/local1/borito1907/anaconda3/envs/watermark_2/lib/python3.10/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/local1/borito1907/anaconda3/envs/watermark_2/lib/python3.10/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/local1/borito1907/anaconda3/envs/watermark_2/lib/python3.10/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
  File "/local1/borito1907/anaconda3/envs/watermark_2/lib/python3.10/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
  File "/local1/borito1907/anaconda3/envs/watermark_2/lib/python3.10/site-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
  File "/local1/borito1907/anaconda3/envs/watermark_2/lib/python3.10/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "/local1/borito1907/impossibility-watermark/attack.py", line 243, in main
    attacker = Attack(cfg)
  File "/local1/borito1907/impossibility-watermark/attack.py", line 49, in __init__
    self.generator_pipe_builder = get_or_create_pipeline_builder(cfg.generator_args.model_name_or_path, cfg.generator_args)
  File "/local1/borito1907/impossibility-watermark/attack.py", line 43, in get_or_create_pipeline_builder
    self.pipeline_builders[model_name_or_path] = PipeLineBuilder(args)
  File "/local1/borito1907/impossibility-watermark/model_builders/pipeline.py", line 58, in __init__
    self._init_model(self.cfg)
  File "/local1/borito1907/impossibility-watermark/model_builders/pipeline.py", line 83, in _init_model
    self.model = AutoGPTQForCausalLM.from_quantized(
  File "/local1/borito1907/anaconda3/envs/watermark_2/lib/python3.10/site-packages/auto_gptq/modeling/auto.py", line 135, in from_quantized
    return quant_func(
  File "/local1/borito1907/anaconda3/envs/watermark_2/lib/python3.10/site-packages/auto_gptq/modeling/_base.py", line 1246, in from_quantized
    accelerate.utils.modeling.load_checkpoint_in_model(
  File "/local1/borito1907/anaconda3/envs/watermark_2/lib/python3.10/site-packages/accelerate/utils/modeling.py", line 1673, in load_checkpoint_in_model
    loaded_checkpoint = load_state_dict(checkpoint_file, device_map=device_map)
  File "/local1/borito1907/anaconda3/envs/watermark_2/lib/python3.10/site-packages/accelerate/utils/modeling.py", line 1435, in load_state_dict
    return safe_load_file(checkpoint_file, device=list(device_map.values())[0])
  File "/local1/borito1907/anaconda3/envs/watermark_2/lib/python3.10/site-packages/safetensors/torch.py", line 313, in load_file
    result[k] = f.get_tensor(k)
KeyboardInterrupt
