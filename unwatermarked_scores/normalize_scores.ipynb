{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Function to normalize scores\n",
    "def normalize_score(score, mean, stdev):\n",
    "    if score == -1:\n",
    "        return score  # Don't normalize if score is -1\n",
    "    return (score - mean) / stdev\n",
    "\n",
    "def merge_watermark_scores(df1, df2):\n",
    "    # Ensure both DFs have the same structure and number of rows\n",
    "    if not df1.shape == df2.shape:\n",
    "        raise ValueError(\"DataFrames must have the same shape\")\n",
    "    \n",
    "    # Iterate through the rows and merge watermark_score based on the conditions\n",
    "    for index, (wm1, wm2) in enumerate(zip(df1['watermark_score'], df2['watermark_score'])):\n",
    "        if wm1 == -1 and wm2 == -1:\n",
    "            # Do nothing, both are -1\n",
    "            continue\n",
    "        elif wm1 != -1 and wm2 != -1 and wm1 != wm2:\n",
    "            # Print if both are not -1 and not equal\n",
    "            print(f\"Conflict at index {index}: df1: {wm1}, df2: {wm2}\")\n",
    "        elif wm1 == -1 and wm2 != -1:\n",
    "            # Replace df1's score with df2's if df1 is -1\n",
    "            df1.at[index, 'watermark_score'] = wm2\n",
    "        elif wm2 == -1 and wm1 != -1:\n",
    "            # Replace df2's score with df1's if df2 is -1\n",
    "            df2.at[index, 'watermark_score'] = wm1\n",
    "    \n",
    "    return df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /data2/borito1907/impossibility-watermark/attack_traces/DiffOracle_SemStampWatermarker_Document1StepMutator_n-steps=200_attack_results_annotatedmerged.csv\n",
      "Processing file: /data2/borito1907/impossibility-watermark/attack_traces/DiffOracle_SemStampWatermarker_DocumentMutator_n-steps=200_attack_results_annotatedmerged.csv\n",
      "Processing file: /data2/borito1907/impossibility-watermark/attack_traces/DiffOracle_SemStampWatermarker_Document2StepMutator_n-steps=200_attack_results_annotatedmerged.csv\n"
     ]
    }
   ],
   "source": [
    "mean_score = -0.7281950363003581\n",
    "stdev_score = 0.933524266518816\n",
    "\n",
    "dir_path = \"/data2/borito1907/impossibility-watermark/attack_traces\"\n",
    "\n",
    "# counter = 0\n",
    "\n",
    "# Loop over all CSV files in the directory\n",
    "for filename in os.listdir(dir_path):\n",
    "    if (\"Document\" in filename) and (\"SemStamp\" in filename) and \"n-steps=200\" in filename and filename.endswith(\"annotatedmerged.csv\"):\n",
    "        df_path = os.path.join(dir_path, filename)\n",
    "        print(f\"Processing file: {df_path}\")\n",
    "        new_df_path = os.path.join(dir_path, filename.replace('.csv', '_annotatedfinal.csv'))\n",
    "        df = pd.read_csv(df_path)\n",
    "                \n",
    "        # Apply normalization\n",
    "        df['normalized_watermark_score'] = df['watermark_score'].apply(lambda x: normalize_score(x, mean_score, stdev_score))\n",
    "\n",
    "        # df.to_csv(new_df_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /data2/borito1907/impossibility-watermark/attack_traces/DiffOracle_semstamp_SpanMutator_n-steps=200_attack_results_annotated.csv\n"
     ]
    }
   ],
   "source": [
    "mean_score = -0.7281950363003581\n",
    "stdev_score = 0.933524266518816\n",
    "\n",
    "dir_path = \"/data2/borito1907/impossibility-watermark/attack_traces\"\n",
    "\n",
    "# counter = 0\n",
    "\n",
    "# Loop over all CSV files in the directory\n",
    "for filename in os.listdir(dir_path):\n",
    "    if (\"good_embedder\" not in filename) and (\"Document\" not in filename) and (\"semstamp\" in filename) and \"n-steps=200\" in filename and filename.endswith(\"annotated.csv\"):\n",
    "        df_path = os.path.join(dir_path, filename)\n",
    "        print(f\"Processing file: {df_path}\")\n",
    "        new_df_path = os.path.join(dir_path, filename.replace('annotated.csv', 'annotatedfinal.csv'))\n",
    "        df = pd.read_csv(df_path)\n",
    "                \n",
    "        # Apply normalization\n",
    "        df['normalized_watermark_score'] = df['watermark_score'].apply(lambda x: normalize_score(x, mean_score, stdev_score))\n",
    "\n",
    "        # df.to_csv(new_df_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /data2/borito1907/DiffOracle_semstamp_WordMutator_n-steps=1000_attack_results_newest_annotated.csv\n"
     ]
    }
   ],
   "source": [
    "mean_score = -0.7281950363003581\n",
    "stdev_score = 0.933524266518816\n",
    "\n",
    "dir_path = \"/data2/borito1907\"\n",
    "filename = 'DiffOracle_semstamp_WordMutator_n-steps=1000_attack_results_newest_annotated.csv'\n",
    "df_path = os.path.join(dir_path, filename)\n",
    "print(f\"Processing file: {df_path}\")\n",
    "new_df_path = os.path.join(dir_path, filename.replace('annotated.csv', 'annotatedfinal.csv'))\n",
    "df = pd.read_csv(df_path)\n",
    "        \n",
    "# Apply normalization\n",
    "df['normalized_watermark_score'] = df['watermark_score'].apply(lambda x: normalize_score(x, mean_score, stdev_score))\n",
    "\n",
    "# df.to_csv(new_df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_score = -0.7281950363003581\n",
    "stdev_score = 0.933524266518816\n",
    "\n",
    "\n",
    "df_path = \"/data2/borito1907/impossibility-watermark/unwatermarked_scores/semstamp_detect_unwatermarked.csv\"\n",
    "\n",
    "new_df_path = \"/data2/borito1907/impossibility-watermark/unwatermarked_scores/semstamp_detect_unwatermarked_normalized.csv\"\n",
    "df = pd.read_csv(df_path)\n",
    "        \n",
    "# Apply normalization\n",
    "df['normalized_watermark_score'] = df['watermark_score'].apply(lambda x: normalize_score(x, mean_score, stdev_score))\n",
    "\n",
    "# df.to_csv(new_df_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /data2/borito1907/impossibility-watermark/attack_traces/DiffOracle_adaptive_SpanMutator_n-steps=200_attack_results_annotated.csv\n"
     ]
    }
   ],
   "source": [
    "mean_score = 51.60824692338929\n",
    "stdev_score = 5.957990385248221\n",
    "\n",
    "dir_path = \"/data2/borito1907/impossibility-watermark/attack_traces\"\n",
    "\n",
    "# counter = 0\n",
    "\n",
    "# Loop over all CSV files in the directory\n",
    "for filename in os.listdir(dir_path):\n",
    "    if (\"good_embedder\" not in filename) and (\"adaptive\" in filename) and \"n-steps=200\" in filename and filename.endswith(\"annotated.csv\"):\n",
    "        df_path = os.path.join(dir_path, filename)\n",
    "        print(f\"Processing file: {df_path}\")\n",
    "        new_df_path = os.path.join(dir_path, filename.replace('annotated.csv', 'annotatedfinal.csv'))\n",
    "        df = pd.read_csv(df_path)\n",
    "                \n",
    "        # Apply normalization\n",
    "        df['normalized_watermark_score'] = df['watermark_score'].apply(lambda x: normalize_score(x, mean_score, stdev_score))\n",
    "\n",
    "        # df.to_csv(new_df_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /data2/borito1907/DiffOracle_adaptive_WordMutator_n-steps=1000_attack_results_newest_annotated.csv\n"
     ]
    }
   ],
   "source": [
    "mean_score = 51.60824692338929\n",
    "stdev_score = 5.957990385248221\n",
    "\n",
    "dir_path = \"/data2/borito1907\"\n",
    "filename = 'DiffOracle_adaptive_WordMutator_n-steps=1000_attack_results_newest_annotated.csv'\n",
    "df_path = os.path.join(dir_path, filename)\n",
    "print(f\"Processing file: {df_path}\")\n",
    "new_df_path = os.path.join(dir_path, filename.replace('annotated.csv', 'annotatedfinal.csv'))\n",
    "df = pd.read_csv(df_path)\n",
    "        \n",
    "# Apply normalization\n",
    "df['normalized_watermark_score'] = df['watermark_score'].apply(lambda x: normalize_score(x, mean_score, stdev_score))\n",
    "\n",
    "# df.to_csv(new_df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def breakup_attacks(df):\n",
    "    # Break the DF up into smaller DFs\n",
    "    dfs = []\n",
    "    current_df = None\n",
    "\n",
    "    # Iterate over the rows and split on step_num resets\n",
    "    for i, row in df.iterrows():\n",
    "        # Check if the step_num resets to -1, indicating a new sequence\n",
    "        if row['mutation_num'] == -1:\n",
    "            if current_df is not None and not current_df.empty:\n",
    "                dfs.append(current_df.reset_index(drop=True))  # Save the current increasing DF\n",
    "            current_df = pd.DataFrame([row])  # Start a new DataFrame with the reset row\n",
    "        else:\n",
    "            # Append the row to the current DataFrame\n",
    "            current_df = pd.concat([current_df, pd.DataFrame([row])])\n",
    "\n",
    "    # Add the last DataFrame if it exists and is non-empty\n",
    "    if current_df is not None and not current_df.empty:\n",
    "        dfs.append(current_df.reset_index(drop=True))\n",
    "    \n",
    "    return dfs\n",
    "\n",
    "df = pd.read_csv('/data2/borito1907/DiffOracle_adaptive_WordMutator_n-steps=1000_attack_results_newest_annotatedfinal.csv')\n",
    "dfs = breakup_attacks(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       8.045520\n",
       "100     5.417271\n",
       "200     4.860457\n",
       "300     4.091313\n",
       "400     3.575051\n",
       "500     2.860453\n",
       "600     3.237212\n",
       "700     2.651760\n",
       "800     2.869096\n",
       "900     2.928565\n",
       "1000    2.485681\n",
       "1001    2.548309\n",
       "Name: normalized_watermark_score, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = dfs[0][dfs[0]['normalized_watermark_score'] != -1.0]\n",
    "temp['normalized_watermark_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       8.000975\n",
       "100     5.872734\n",
       "200     4.992905\n",
       "300     4.024349\n",
       "400     3.954658\n",
       "500     3.120251\n",
       "600     3.047872\n",
       "700     2.731215\n",
       "800     2.695275\n",
       "900     2.901662\n",
       "1000    2.413255\n",
       "1001    2.546398\n",
       "Name: normalized_watermark_score, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = dfs[1][dfs[1]['normalized_watermark_score'] != -1.0]\n",
    "temp['normalized_watermark_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/data2/borito1907/DiffOracle_semstamp_WordMutator_n-steps=1000_attack_results_newest_annotatedfinal.csv')\n",
    "dfs = breakup_attacks(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       8.524432\n",
       "20      7.164881\n",
       "40      6.319429\n",
       "60      4.230034\n",
       "80      3.630037\n",
       "100     4.570151\n",
       "120     2.820873\n",
       "140     1.654688\n",
       "160     1.654688\n",
       "180     1.654688\n",
       "200     0.488503\n",
       "220     1.654688\n",
       "240     1.071596\n",
       "260     1.654688\n",
       "280     2.237781\n",
       "300     3.403966\n",
       "320     2.820873\n",
       "340     2.820873\n",
       "360     2.057016\n",
       "380     2.624556\n",
       "400     3.192097\n",
       "420     3.192097\n",
       "440     3.192097\n",
       "460     2.624556\n",
       "480     0.921935\n",
       "500     0.921935\n",
       "520     2.057016\n",
       "540     2.057016\n",
       "560     2.057016\n",
       "580     2.057016\n",
       "600     1.489475\n",
       "620     0.354394\n",
       "640     0.921935\n",
       "660     1.489475\n",
       "680     1.489475\n",
       "700     1.489475\n",
       "720     1.489475\n",
       "740     2.057016\n",
       "760     1.489475\n",
       "780     1.489475\n",
       "800     2.057016\n",
       "820     2.057016\n",
       "840     1.489475\n",
       "860     3.192097\n",
       "880     2.624556\n",
       "900     3.192097\n",
       "920     3.192097\n",
       "940     2.057016\n",
       "960     3.192097\n",
       "980     2.624556\n",
       "1000    1.489475\n",
       "1001    0.921935\n",
       "Name: normalized_watermark_score, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = dfs[0][dfs[0]['normalized_watermark_score'] != -1.0]\n",
    "temp['normalized_watermark_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       8.202833\n",
       "20      6.043478\n",
       "40      6.043478\n",
       "60      4.963800\n",
       "80      2.804445\n",
       "100     1.724767\n",
       "120     2.264606\n",
       "140     1.724767\n",
       "160     1.724767\n",
       "180     1.724767\n",
       "200     1.724767\n",
       "220     1.184929\n",
       "240     0.645090\n",
       "260     0.645090\n",
       "280     0.645090\n",
       "300     0.645090\n",
       "320     0.645090\n",
       "340     0.645090\n",
       "360     0.645090\n",
       "380     0.645090\n",
       "400     2.264606\n",
       "420     1.184929\n",
       "440     1.184929\n",
       "460     1.724767\n",
       "480     1.724767\n",
       "500     1.184929\n",
       "520     1.184929\n",
       "540     1.184929\n",
       "560     1.724767\n",
       "580     1.724767\n",
       "600     2.264606\n",
       "620     2.264606\n",
       "640     1.724767\n",
       "660     2.264606\n",
       "680     3.344284\n",
       "700     3.344284\n",
       "720     3.344284\n",
       "740     3.344284\n",
       "760     3.344284\n",
       "780     3.344284\n",
       "800     2.264606\n",
       "820     2.804445\n",
       "840     1.184929\n",
       "860     1.184929\n",
       "880     1.184929\n",
       "900     0.105251\n",
       "920     1.184929\n",
       "940     0.645090\n",
       "960    -0.434588\n",
       "980    -0.974427\n",
       "1000   -0.434588\n",
       "1001   -0.434588\n",
       "Name: normalized_watermark_score, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = dfs[1][dfs[1]['normalized_watermark_score'] != -1.0]\n",
    "temp['normalized_watermark_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gptq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
