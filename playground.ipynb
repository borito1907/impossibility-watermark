{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['step_num', 'current_text', 'mutated_text', 'current_text_len',\n",
       "       'mutated_text_len', 'length_issue', 'quality_analysis',\n",
       "       'quality_preserved', 'watermark_detected', 'watermark_score',\n",
       "       'backtrack', 'timestamp'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('./semstamp_attacks/filtered_data.csv')\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'original_analysis': 'Response A is better than Response B. Both responses are identical, but Response A has proper paragraph breaks, which makes it easier to read and understand. Response B lacks paragraph breaks, making it a block of text that is difficult to follow. Additionally, Response A has proper spacing between sentences, which is not present in Response B. This makes Response A more coherent and easier to comprehend. Both responses have proper grammar, coherence, relevance, and accuracy, but the formatting of Response A makes it a better response overall.', 'original_answer': 'A', 'followup_analysis': 'Response A is better than Response B. Both responses have similar content and structure, but Response A has better coherence and grammar. Response B has unnecessary line breaks that disrupt the flow of the text, making it harder to read. Additionally, Response A has more varied sentence structures, which makes it more engaging to read. Both responses address the prompt well and provide accurate information about the Lord of the Rings series.', 'followup_answer': 'A', 'quality_preserved': False}\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_filtered_df = df[df[\"length_issue\"] == False]\n",
    "\n",
    "len_filtered_df[\"quality_analysis\"][1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(len_filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from collections import Counter\n",
    "\n",
    "def parse_and_aggregate_quality_analysis(data):\n",
    "    # Filter rows where 'length_issue' is False\n",
    "    filtered_data = data[data['length_issue'] == False]\n",
    "\n",
    "    # Convert the quality_analysis column from string to dictionary\n",
    "    quality_analysis_dicts = filtered_data['quality_analysis'].apply(ast.literal_eval)\n",
    "\n",
    "    # Initialize counters for original and follow-up analyses\n",
    "    original_analysis_counter = Counter()\n",
    "    followup_analysis_counter = Counter()\n",
    "\n",
    "    for analysis in quality_analysis_dicts:\n",
    "        # Extract original and followup analyses\n",
    "        original_answer = analysis.get('original_answer', '')\n",
    "        followup_answer = analysis.get('followup_answer', '')\n",
    "\n",
    "        # Update the counters\n",
    "        original_analysis_counter[original_answer] += 1\n",
    "        if followup_answer:\n",
    "            followup_analysis_counter[followup_answer] += 1\n",
    "\n",
    "    # Convert counters to DataFrames for better readability\n",
    "    original_analysis_agg = pd.DataFrame(original_analysis_counter.items(), columns=['Analysis', 'Count'])\n",
    "    followup_analysis_agg = pd.DataFrame(followup_analysis_counter.items(), columns=['Analysis', 'Count'])\n",
    "\n",
    "    return original_analysis_agg, followup_analysis_agg\n",
    "\n",
    "# Example usage with the provided data\n",
    "original_analysis_agg, followup_analysis_agg = parse_and_aggregate_quality_analysis(len_filtered_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Analysis</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Analysis  Count\n",
       "0        A     56"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_analysis_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Analysis</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Analysis  Count\n",
       "0        A     56"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "followup_analysis_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "watermark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
