{
	"cells": [
		{
			"cell_type": "code",
			"execution_count": 1,
			"metadata": {},
			"outputs": [],
			"source": [
				"import pandas as pd\n",
				"from matplotlib import pyplot as plt\n",
				"import ipywidgets as widgets\n",
				"import numpy as np"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 6,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"2385\n"
					]
				}
			],
			"source": [
				"df = pd.read_csv('results/IMP_oracle_eval_reward.csv')\n",
				"print(len(df))"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"if True:\n",
				"\tdf = df[(df['oracle_class'] == 'OffsetBiasOracle')]\n",
				"\tdf.to_csv('results/IMP_oracle_eval_reward.csv')"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 11,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"ArmoRMOracle 795\n",
						"InternLMOracle 795\n",
						"OffsetBiasOracle 795\n"
					]
				},
				{
					"data": {
						"text/html": [
							"<div>\n",
							"<style scoped>\n",
							"    .dataframe tbody tr th:only-of-type {\n",
							"        vertical-align: middle;\n",
							"    }\n",
							"\n",
							"    .dataframe tbody tr th {\n",
							"        vertical-align: top;\n",
							"    }\n",
							"\n",
							"    .dataframe thead th {\n",
							"        text-align: right;\n",
							"    }\n",
							"</style>\n",
							"<table border=\"1\" class=\"dataframe\">\n",
							"  <thead>\n",
							"    <tr style=\"text-align: right;\">\n",
							"      <th></th>\n",
							"      <th>accuracy</th>\n",
							"      <th>time</th>\n",
							"      <th>value</th>\n",
							"    </tr>\n",
							"  </thead>\n",
							"  <tbody>\n",
							"    <tr>\n",
							"      <th>ArmoRMOracle</th>\n",
							"      <td>NaN</td>\n",
							"      <td>NaN</td>\n",
							"      <td>NaN</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>InternLMOracle</th>\n",
							"      <td>NaN</td>\n",
							"      <td>NaN</td>\n",
							"      <td>NaN</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>OffsetBiasOracle</th>\n",
							"      <td>0.693082</td>\n",
							"      <td>0.313866</td>\n",
							"      <td>2.208212</td>\n",
							"    </tr>\n",
							"  </tbody>\n",
							"</table>\n",
							"</div>"
						],
						"text/plain": [
							"                  accuracy      time     value\n",
							"ArmoRMOracle           NaN       NaN       NaN\n",
							"InternLMOracle         NaN       NaN       NaN\n",
							"OffsetBiasOracle  0.693082  0.313866  2.208212"
						]
					},
					"execution_count": 11,
					"metadata": {},
					"output_type": "execute_result"
				}
			],
			"source": [
				"summary = []\n",
				"oracles = ['BinaryOracle', 'MutationOracle', 'Mutation1Oracle', 'SoloOracle', 'RelativeOracle', 'DiffOracle', 'ExampleOracle', 'JointOracle', 'RankOracle']\n",
				"judges = {'Meta-Llama-3.1-8B-Instruct-q8_0': '8B', 'Meta-Llama-3.1-70B-Instruct-q8_0': '70B'}\n",
				"indices = []\n",
				"# for oracle in oracles:\n",
				"# \tfor judge in judges:\n",
				"# \t\tfor do_explain in [True, False]:\n",
				"# \t\t\tdf_oracle = df[(df['oracle_class'] == oracle) & (df['explain'] == do_explain) & (df['judge_name'] == judge)]\n",
				"# \t\t\tavg = df_oracle['pred_correct'].mean()\n",
				"# \t\t\ttime = df_oracle['time_taken'].mean()\n",
				"# \t\t\tsummary.append([avg, time, avg/time])\n",
				"# \t\t\tprint(oracle, judges[judge], do_explain, len(df_oracle))\n",
				"# \t\t\tt_f = \"T\" if do_explain else \"F\"\n",
				"# \t\t\tindices.append(f\"{oracle}_{judges[judge]}_{t_f}\")\n",
				"\n",
				"oracles2 = ['ArmoRMOracle', 'InternLMOracle', 'OffsetBiasOracle']\n",
				"for oracle in oracles2:\n",
				"\tdf_oracle = df[(df['oracle_class'] == oracle)]\n",
				"\tavg = df_oracle['pred_correct'].mean()\n",
				"\ttime = df_oracle['time_taken'].mean()\n",
				"\tsummary.append([avg, time, avg/time])\n",
				"\tprint(oracle, len(df_oracle))\n",
				"\tindices.append(f\"{oracle}\")\n",
				"\n",
				"\n",
				"oracle_scoring = pd.DataFrame(data=summary,index=indices, columns=['accuracy', 'time', 'value'])\n",
				"oracle_scoring"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 4,
			"metadata": {},
			"outputs": [
				{
					"data": {
						"text/html": [
							"<div>\n",
							"<style scoped>\n",
							"    .dataframe tbody tr th:only-of-type {\n",
							"        vertical-align: middle;\n",
							"    }\n",
							"\n",
							"    .dataframe tbody tr th {\n",
							"        vertical-align: top;\n",
							"    }\n",
							"\n",
							"    .dataframe thead th {\n",
							"        text-align: right;\n",
							"    }\n",
							"</style>\n",
							"<table border=\"1\" class=\"dataframe\">\n",
							"  <thead>\n",
							"    <tr style=\"text-align: right;\">\n",
							"      <th></th>\n",
							"      <th>A</th>\n",
							"      <th>B</th>\n",
							"      <th>TIE</th>\n",
							"    </tr>\n",
							"  </thead>\n",
							"  <tbody>\n",
							"    <tr>\n",
							"      <th>A</th>\n",
							"      <td>0</td>\n",
							"      <td>0</td>\n",
							"      <td>0</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>B</th>\n",
							"      <td>0</td>\n",
							"      <td>0</td>\n",
							"      <td>0</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>TIE</th>\n",
							"      <td>0</td>\n",
							"      <td>0</td>\n",
							"      <td>0</td>\n",
							"    </tr>\n",
							"  </tbody>\n",
							"</table>\n",
							"</div>"
						],
						"text/plain": [
							"     A  B  TIE\n",
							"A    0  0    0\n",
							"B    0  0    0\n",
							"TIE  0  0    0"
						]
					},
					"execution_count": 4,
					"metadata": {},
					"output_type": "execute_result"
				}
			],
			"source": [
				"def indexer(value):\n",
				"    mapping = {'ResponseQuality.A_BETTER': 0, 'ResponseQuality.B_BETTER': 1, 'ResponseQuality.TIE': 2}\n",
				"    return mapping[value.strip()]\n",
				"\n",
				"def create_table(df, label=None, pred=None, oracle=None, explain=None, judge=None):\n",
				"\tif oracle != None:\n",
				"\t\tdf = df[(df['oracle_class'] == oracle)]\n",
				"\tif explain != None:\n",
				"\t\tdf = df[(df['explain'] == explain)]\n",
				"\tif judge != None:\n",
				"\t\tdf = df[(df['judge_name'] == judge)]\n",
				"\n",
				"\tif label == \"A\":\n",
				"\t\tdf = df[(df['original_label'] == 'ResponseQuality.A_BETTER')]\n",
				"\telif label == \"B\":\n",
				"\t\tdf = df[(df['original_label'] == 'ResponseQuality.B_BETTER')]\n",
				"\telif label == \"TIE\":\n",
				"\t\tdf = df[(df['original_label'] == 'ResponseQuality.TIE')]\n",
				"\n",
				"\tif pred == 1:\n",
				"\t\tdf = df[(df['pred_correct'] == 1)]\n",
				"\telif pred == .5:\n",
				"\t\tdf = df[(df['pred_correct'] == .5)]\n",
				"\telif pred == 0:\n",
				"\t\tdf = df[(df['pred_correct'] == 0)]\n",
				"\n",
				"\tinit_data = [[0,0,0], [0,0,0], [0,0,0]]\n",
				"\tfor index, row in df.iterrows():\n",
				"\t\t\n",
				"\t\ti = indexer(row[\"original_pred\"])\n",
				"\t\tj = 0\n",
				"\t\tif row[\"oracle_class\"] not in [\"SoloOracle\", \"BinaryOracle\", \"Mutation1Oracle\", \"DiffOracle\"]:\n",
				"\t\t\tj = indexer(row[\"followup_pred\"])\n",
				"\t\tinit_data[i][j] += 1\n",
				"\treturn pd.DataFrame(data=init_data,index=['A', 'B', 'TIE'], columns=['A', 'B', 'TIE'])\n",
				"\t\n",
				"\n",
				"create_table(df,oracle='DiffOracle', explain=False, judge=\"Meta-Llama-3.1-70B-Instruct-q8_0\")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 5,
			"metadata": {},
			"outputs": [
				{
					"data": {
						"text/html": [
							"<div>\n",
							"<style scoped>\n",
							"    .dataframe tbody tr th:only-of-type {\n",
							"        vertical-align: middle;\n",
							"    }\n",
							"\n",
							"    .dataframe tbody tr th {\n",
							"        vertical-align: top;\n",
							"    }\n",
							"\n",
							"    .dataframe thead th {\n",
							"        text-align: right;\n",
							"    }\n",
							"</style>\n",
							"<table border=\"1\" class=\"dataframe\">\n",
							"  <thead>\n",
							"    <tr style=\"text-align: right;\">\n",
							"      <th></th>\n",
							"      <th>0</th>\n",
							"      <th>.5</th>\n",
							"      <th>1</th>\n",
							"    </tr>\n",
							"  </thead>\n",
							"  <tbody>\n",
							"    <tr>\n",
							"      <th>A</th>\n",
							"      <td>0</td>\n",
							"      <td>0</td>\n",
							"      <td>0</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>B</th>\n",
							"      <td>0</td>\n",
							"      <td>0</td>\n",
							"      <td>0</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>TIE</th>\n",
							"      <td>0</td>\n",
							"      <td>0</td>\n",
							"      <td>0</td>\n",
							"    </tr>\n",
							"  </tbody>\n",
							"</table>\n",
							"</div>"
						],
						"text/plain": [
							"     0  .5  1\n",
							"A    0   0  0\n",
							"B    0   0  0\n",
							"TIE  0   0  0"
						]
					},
					"execution_count": 5,
					"metadata": {},
					"output_type": "execute_result"
				}
			],
			"source": [
				"def create_table2(df, label=None, pred=None, oracle=None, explain=False, judge=None):\n",
				"\tif oracle != None:\n",
				"\t\tdf = df[(df['oracle_class'] == oracle)]\n",
				"\tif explain != None:\n",
				"\t\tdf = df[(df['explain'] == explain)]\n",
				"\tif judge != None:\n",
				"\t\tdf = df[(df['judge_name'] == judge)]\n",
				"\n",
				"\tif label == \"A\":\n",
				"\t\tdf = df[(df['original_label'] == 'ResponseQuality.A_BETTER')]\n",
				"\telif label == \"B\":\n",
				"\t\tdf = df[(df['original_label'] == 'ResponseQuality.B_BETTER')]\n",
				"\telif label == \"TIE\":\n",
				"\t\tdf = df[(df['original_label'] == 'ResponseQuality.TIE')]\n",
				"\n",
				"\tif pred == 1:\n",
				"\t\tdf = df[(df['pred_correct'] == 1)]\n",
				"\telif pred == .5:\n",
				"\t\tdf = df[(df['pred_correct'] == .5)]\n",
				"\telif pred == 0:\n",
				"\t\tdf = df[(df['pred_correct'] == 0)]\n",
				"\n",
				"\tinit_data = [[0,0,0], [0,0,0], [0,0,0]]\n",
				"\tfor index, row in df.iterrows():\n",
				"\t\ti = 0 if row['original_label'] == 'ResponseQuality.A_BETTER' else (1 if row['original_label'] == 'ResponseQuality.B_BETTER' else 2)\n",
				"\t\tj = int((row[\"pred_correct\"])*2)\n",
				"\t\tinit_data[i][j] += 1\n",
				"\treturn pd.DataFrame(data=init_data,index=['A', 'B', 'TIE'], columns=['0', '.5', '1'])\n",
				"\t\n",
				"\t\n",
				"create_table2(df,oracle='DiffOracle', explain=False, judge=\"Meta-Llama-3.1-70B-Instruct-q8_0\")"
			]
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "watermark",
			"language": "python",
			"name": "python3"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "ipython",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "python",
			"nbconvert_exporter": "python",
			"pygments_lexer": "ipython3",
			"version": "3.10.14"
		}
	},
	"nbformat": 4,
	"nbformat_minor": 2
}
