/local1/borito1907/anaconda3/envs/watermark/lib/python3.10/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
[nltk_data] Downloading package punkt to /home/borito1907/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[2024-08-20 04:21:55,470][__main__][INFO] - Getting the watermarker...
[2024-08-20 04:21:55,471][watermarker][INFO] - Using device: cuda:0
[2024-08-20 04:21:55,471][model_builders.pipeline][INFO] - Initializing hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4
[2024-08-20 04:21:56,269][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
/local1/borito1907/anaconda3/envs/watermark/lib/python3.10/site-packages/accelerate/utils/modeling.py:1365: UserWarning: Current model requires 12446862976 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.
  warnings.warn(
Error executing job with overrides: ['++partition=2']
Traceback (most recent call last):
  File "/local1/borito1907/impossibility-watermark/adaptive_test_gen.py", line 32, in test
    watermarker = get_watermarker(cfg, only_detect=False)
  File "/local1/borito1907/impossibility-watermark/watermarker_factory.py", line 15, in get_watermarker
    return AdaptiveWatermarker(cfg, **kwargs)
  File "/local1/borito1907/impossibility-watermark/watermarkers/adaptive.py", line 45, in __init__
    super().__init__(cfg, pipeline, n_attempts, **kwargs)
  File "/local1/borito1907/impossibility-watermark/watermarker.py", line 22, in __init__
    self.pipeline = PipeLineBuilder(self.cfg.generator_args)
  File "/local1/borito1907/impossibility-watermark/model_builders/pipeline.py", line 28, in __init__
    self._init_model(self.cfg)
  File "/local1/borito1907/impossibility-watermark/model_builders/pipeline.py", line 83, in _init_model
    self.model = AutoModelForCausalLM.from_pretrained(
  File "/local1/borito1907/anaconda3/envs/watermark/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
    return model_class.from_pretrained(
  File "/local1/borito1907/anaconda3/envs/watermark/lib/python3.10/site-packages/transformers/modeling_utils.py", line 3865, in from_pretrained
    hf_quantizer.validate_environment(device_map=device_map)
  File "/local1/borito1907/anaconda3/envs/watermark/lib/python3.10/site-packages/transformers/quantizers/quantizer_awq.py", line 65, in validate_environment
    raise ValueError(
ValueError: You are attempting to load an AWQ model with a device_map that contains a CPU or disk device. This is not supported. Please remove the CPU or disk device from the device_map.

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
