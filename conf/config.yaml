results_dir: "./eval/results"

watermark_args:
    watermarking_scheme: "umd"
    generative_model_name: "TheBloke/Llama-2-7B-Chat-GPTQ"
    generative_model_device: "auto"
    z_threshold: 0.5

oracle_args:
    use_query: True
    use_gpt: False
    check_quality: False
    choice_granularity: 5
    use_chat_arena_prompt: False
    reward_model: "OpenAssistant/reward-model-deberta-v3-large-v2"
    model_cache_dir: "./.cache"

mutator_args:
    model_name_or_path: "TheBloke/Mixtral-8x7B-Instruct-v0.1-GPTQ"
    revision: "main" # "gptq-3bit-128g-actorder_True" for 3-bit version
    max_new_tokens: 1024
    do_sample: True 
    temperature: 0.7 
    top_p: 0.95 
    top_k: 40
    repetition_penalty: 1.1
    model_cache_dir: "./.cache/"