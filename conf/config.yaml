defaults:
    - _self_
    - watermark_args: semstamp
    # - attack_args: c4_generation
    # - attack_args: prompt_based_generation
    # - attack_args: mixtral_regular_attack
    # - generator_args: large_mixtral
    # - oracle_args: llama3

attack_args:
    # prompt: "Provide a straightforward description of the Eiffel Tower's physical features without using complex or elaborate language."
    prompt : null
    # prompt_file: "./inputs/dynamic_prompts.csv" # only used if prompt is None
    # prompt_num: 6
    # prompt_file: './inputs/lotr_prompts.csv'
    # prompt_num: 3
    prompt_file: './inputs/mini_c4.csv'
    prompt_num: 3
    watermarked_text: null
    watermarked_text_path: './inputs/llama_semstamp_minic4_3.csv'
    watermarked_text_num: 1
    num_steps: 100 # how many mutations should the attack try to make
    patience: 50 # how many unsuccessful mutations in a row before we quit
    stop_at_removal: False # stop the attack after removing the watermark
    num_successful_steps: 20 # how many successful mutations before stopping
    results_dir: './semstamp_attacks'
    model_cache_dir: "/local1/borito1907/.cache/"
    save_name: 'llama_c4_semstamp_prompt3_merge.csv' # if None, it defaults to attack_{timestamp}.csv
    use_watermark: True # when running with GPT-4, disregard the watermark
    backtrack_patience: 50 # how many unsuccessful mutations before backtrack
    # For completion
    is_completion: True
    json_path: null
    json_index: 0
    # For continuations
    is_continuation: False
    prev_csv_file:  # If you're running a continuation, this should be the name of the previous CSV file.
    cuda: "4,5" # TODO: Does this really work?

generator_args:
    # model_name_or_path: "TheBloke/Mixtral-8x7B-Instruct-v0.1-GPTQ" # "gpt-4"
    model_name_or_path: "MaziyarPanahi/Meta-Llama-3-70B-Instruct-GPTQ"
    # model_name_or_path: "facebook/opt-1.3b"
    revision: "main" 
    model_cache_dir: "${attack_args.model_cache_dir}"
    device_map: "auto"
    trust_remote_code: True
    max_new_tokens: 1024
    min_new_tokens: 768
    do_sample: True 
    temperature: 1.0
    top_p: 0.95 
    top_k: 40
    repetition_penalty: 1.1
    watermark_score_threshold: 5.0
    diversity_penalty: 15.0 # default is 0.0. Increase to make the output more diverse. This helps with SemStamp generation.
    cuda: "${attack_args.cuda}"

oracle_args:
    num_retries: 5
    use_system_profile: True
    model_name_or_path: "TheBloke/Mixtral-8x7B-Instruct-v0.1-GPTQ" # "gpt-4"
    # model_name_or_path: "MaziyarPanahi/Meta-Llama-3-70B-Instruct-GPTQ"
    revision: "main" 
    model_cache_dir: "${attack_args.model_cache_dir}"
    device_map: "${generator_args.device_map}"
    trust_remote_code: "${generator_args.trust_remote_code}"
    max_new_tokens: "${generator_args.max_new_tokens}"
    do_sample: "${generator_args.do_sample}" 
    temperature: "${generator_args.temperature}"
    top_p: "${generator_args.top_p}"
    top_k: "${generator_args.top_k}"
    repetition_penalty: "${generator_args.repetition_penalty}"
    cuda: "${attack_args.cuda}"
    is_completion: ${attack_args.is_completion}
    num_formatting_retries: 1
    # system_profile: "You are an impartial judge tasked to evaluate the quality of two prompt responses."
    system_profile: "You are a helpful and precise assistant for checking the quality of the answer."
    template_dir: "./prompt_templates/quality_oracle/"
    template: "relative.sandpaper.3"

mutator_args:
    type: "llm" # llm, mask_fill, span_fill
    use_system_profile: True
    system_profile: "You are a copy editor tasked to enforce text quality."
    num_retries: 5
    model_name_or_path: "TheBloke/Mixtral-8x7B-Instruct-v0.1-GPTQ"
    # model_name_or_path: "grammarly/coedit-xl-composite"
    # model_name_or_path: "MaziyarPanahi/Meta-Llama-3-70B-Instruct-GPTQ"
    revision: "main" 
    model_cache_dir: "${attack_args.model_cache_dir}"
    device_map: "${generator_args.device_map}"
    trust_remote_code: "${generator_args.trust_remote_code}"
    max_new_tokens: "${generator_args.max_new_tokens}"
    do_sample: "${generator_args.do_sample}" 
    temperature: "${generator_args.temperature}"
    top_p: "${generator_args.top_p}"
    top_k: "${generator_args.top_k}"
    repetition_penalty: "${generator_args.repetition_penalty}"
    cuda: "${attack_args.cuda}"
    use_pydantic_parser: False
    consistency_check: False # whether or not to run the consistency check after altering the sentence.