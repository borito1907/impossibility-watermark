defaults:
    - _self_
    - watermark_args: semstamp
    # - attack_args: c4_generation
    # - attack_args: prompt_based_generation
    # - attack_args: mixtral_regular_attack
    # - generator_args: large_mixtrals
    # - oracle_args: llama3

cuda_visible_devices: "1,2" # TODO: Does this really work? FHC: Not at the moment
model_cache_dir: "../.cache" # "/data2/.shared_models"

attack_args:
    max_steps: 300           # how many mutations should the attack try to make
    backtrack_patience: 100   # how many unsuccessful mutations before backtrack (should always be lower than patience)
    length_variance: 0.05    # max percent the mutated text can grow / shrink (initial quality check), set to -1 to disable
    log_csv_path: "./results/attack_log.csv"
    verbose: True

# UMD still needs this to detect, so leaving this here.
generator_args:
    model_id: "TheBloke/Mixtral-8x7B-Instruct-v0.1-GPTQ" # "MaziyarPanahi/Meta-Llama-3-70B-Instruct-GPTQ" "TheBloke/Mixtral-8x7B-Instruct-v0.1-GPTQ" "gpt-4"
    revision: "main" 
    model_cache_dir: "${model_cache_dir}"
    device_map: "auto"
    trust_remote_code: True
    max_new_tokens: 1024
    min_new_tokens: 768
    do_sample: True 
    temperature: 1.0
    top_p: 0.95 
    top_k: 40
    repetition_penalty: 1.1
    watermark_score_threshold: 5.0

oracle_args:
    model_id: "gpt-3.5-turbo-0125" # "TechxGenus/Meta-Llama-3-70B-Instruct-GPTQ" # "gpt-4o"
    model_cache_dir: "${model_cache_dir}"
    max_retries: 5
    revision: "main" 
    device_map: "${generator_args.device_map}"
    trust_remote_code: "${generator_args.trust_remote_code}"
    max_new_tokens: "${generator_args.max_new_tokens}"
    do_sample: "${generator_args.do_sample}" 
    temperature: "${generator_args.temperature}"
    top_p: "${generator_args.top_p}"
    top_k: "${generator_args.top_k}"
    repetition_penalty: "${generator_args.repetition_penalty}"
    cuda_visible_devices: "${cuda_visible_devices}"
    is_completion: ${attack_args.is_completion}
    num_retries: 5
    num_formatting_retries: 1
    system_profile: "You are a helpful and precise assistant for checking the quality of the answer."
    template_dir: "./prompt_templates/quality_oracle/"
    template: "relative.sandpaper.3"
    num_gpus: 4 # for prometheus only

mutator_args:
    type: "sentence" # document, sentence, span, word
    model_id: "TechxGenus/Meta-Llama-3-8B-Instruct-GPTQ" 
    model_cache_dir: "${model_cache_dir}"
    device_map: "${generator_args.device_map}"
    max_retries: 5
