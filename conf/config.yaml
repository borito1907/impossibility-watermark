defaults:
    - _self_
    - watermark_args: umd
    - attack_args: mixtral_regular_attack
    # - generator_args: large_mixtral
    # - oracle_args: large_mixtral

attack_args:
    # prompt: "Provide a straightforward description of the Eiffel Tower's physical features without using complex or elaborate language."
    prompt : null
    prompt_file: "./inputs/dynamic_prompts.csv" # only used if prompt is None
    prompt_num: 6
    watermarked_text: null
    watermarked_text_path: null
    watermarked_text_num: 1
    num_steps: 2000 # how many mutations should the attack try to make
    patience: 250 # how many unsuccessful mutations in a row before we quit
    stop_at_removal: False # stop the attack after removing the watermark
    num_successful_steps: 100 # how many successful mutations before stopping
    results_dir: null
    model_cache_dir: "/local1/borito1907/.cache/"
    save_name: null # if None, it defaults to attack_{timestamp}.csv
    use_watermark: False # when running with GPT-4, disregard the watermark
    backtrack_patience: 50 # how many unsuccessful mutations before backtrack
    # For completion
    is_completion: False
    json_path: null
    json_index: 0
    # For continuations
    is_continuation: False
    prev_csv_file: null # If you're running a continuation, this should be the name of the previous CSV file.
    cuda: "1" # NOTE: This doesn't do anything.

generator_args:
    model_name_or_path: "TheBloke/Mixtral-8x7B-Instruct-v0.1-GPTQ" # "gpt-4"
    revision: "main" 
    model_cache_dir: "${attack_args.model_cache_dir}"
    device_map: "auto"
    trust_remote_code: True
    max_new_tokens: 1024
    do_sample: True 
    temperature: 0.7 
    top_p: 0.95 
    top_k: 40
    repetition_penalty: 1.1
    watermark_score_threshold: 5.0
    cuda: "${attack_args.cuda}"

oracle_args:
    num_retries: 5
    use_system_profile: True
    system_profile: "You are an impartial judge tasked to evaluate the quality of two prompt responses."
    model_name_or_path: "TheBloke/Mixtral-8x7B-Instruct-v0.1-GPTQ" # "gpt-4"
    revision: "main" 
    model_cache_dir: "${attack_args.model_cache_dir}"
    device_map: "${generator_args.device_map}"
    trust_remote_code: "${generator_args.trust_remote_code}"
    max_new_tokens: "${generator_args.max_new_tokens}"
    do_sample: "${generator_args.do_sample}" 
    temperature: "${generator_args.temperature}"
    top_p: "${generator_args.top_p}"
    top_k: "${generator_args.top_k}"
    repetition_penalty: "${generator_args.repetition_penalty}"
    cuda: "${attack_args.cuda}"
    is_completion: ${attack_args.is_completion}

mutator_args:
    use_old_mutator: False
    use_system_profile: True
    system_profile: "You are a copy editor tasked to enforce text quality."
    num_retries: 5
    model_name_or_path: "TheBloke/Mixtral-8x7B-Instruct-v0.1-GPTQ"
    # model_name_or_path: "grammarly/coedit-xl-composite"
    revision: "main" 
    model_cache_dir: "${attack_args.model_cache_dir}"
    device_map: "${generator_args.device_map}"
    trust_remote_code: "${generator_args.trust_remote_code}"
    max_new_tokens: "${generator_args.max_new_tokens}"
    do_sample: "${generator_args.do_sample}" 
    temperature: "${generator_args.temperature}"
    top_p: "${generator_args.top_p}"
    top_k: "${generator_args.top_k}"
    repetition_penalty: "${generator_args.repetition_penalty}"
    cuda: "${attack_args.cuda}"
    use_pydantic_parser: False