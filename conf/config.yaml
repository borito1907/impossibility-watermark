defaults:
    - _self_
    - watermark_args: umd

attack_args:
    # prompt: "Provide a straightforward description of the Eiffel Tower's physical features without using complex or elaborate language."
    prompt : null
    prompt_file: "./inputs/dynamic_prompts.csv" # only used if prompt is None
    prompt_num: 4
    watermarked_text: null
    watermarked_text_path: null
    watermarked_text_num: 1
    num_steps: 1000
    patience: 250
    stop_at_removal: False # stop the attack after removing the watermark
    num_successful_steps: 50
    results_dir: "./eval/results"
    model_cache_dir: "./.cache"
    save_name: '4_evan_1_1_1.csv' # if null, it defaults to attack_{timestamp}.csv
    use_watermark: False # when running with GPT-4, disregard the watermark
    cuda : "4"
    backtrack_patience: 50
    is_completion: False
    json_path: null
    json_index: 0
    is_continuation: True
    prev_csv_file: '4_evan_1_1.csv' # If you're running a continuation, this should be the name of the previous CSV file.

generator_args:
    # model_name_or_path: "TheBloke/Mistral-7B-Instruct-v0.2-GPTQ"
    model_name_or_path: "TheBloke/Mixtral-8x7B-Instruct-v0.1-GPTQ" # "gpt-4"
    # model_name_or_path: "MaziyarPanahi/Smaug-72B-v0.1-GPTQ"
    revision: "main" # "gptq-3bit-128g-actorder_True" for 3-bit version
    model_cache_dir: "${attack_args.model_cache_dir}"
    device_map: "auto"
    trust_remote_code: False
    max_new_tokens: 1024
    do_sample: True 
    temperature: 0.7 
    top_p: 0.95 
    top_k: 40
    repetition_penalty: 1.1
    watermark_score_threshold: 5.0
    cuda: "${attack_args.cuda}"

oracle_args:
    num_retries: 5
    use_system_profile: True
    system_profile: "You are an impartial judge tasked to evaluate the quality of two prompt responses."
    # model_name_or_path: "gpt-4"
    model_name_or_path: "TheBloke/Mixtral-8x7B-Instruct-v0.1-GPTQ" # "gpt-4"
    revision: "main" # "gptq-3bit-128g-actorder_True" for 3-bit version
    model_cache_dir: "${attack_args.model_cache_dir}"
    device_map: "${generator_args.device_map}"
    trust_remote_code: "${generator_args.trust_remote_code}"
    max_new_tokens: "${generator_args.max_new_tokens}"
    do_sample: "${generator_args.do_sample}" 
    temperature: "${generator_args.temperature}"
    top_p: "${generator_args.top_p}"
    top_k: "${generator_args.top_k}"
    repetition_penalty: "${generator_args.repetition_penalty}"
    cuda: "${attack_args.cuda}"
    is_completion: "${attack_args.is_completion}"

mutator_args:
    use_old_mutator: False
    use_system_profile: True
    system_profile: "You are a copy editor tasked to enforce text quality."
    num_retries: 5
    model_name_or_path: "TheBloke/Mixtral-8x7B-Instruct-v0.1-GPTQ"
    revision: "main" 
    model_cache_dir: "${attack_args.model_cache_dir}"
    device_map: "${generator_args.device_map}"
    trust_remote_code: "${generator_args.trust_remote_code}"
    max_new_tokens: "${generator_args.max_new_tokens}"
    do_sample: "${generator_args.do_sample}" 
    temperature: "${generator_args.temperature}"
    top_p: "${generator_args.top_p}"
    top_k: "${generator_args.top_k}"
    repetition_penalty: "${generator_args.repetition_penalty}"
    cuda: "${attack_args.cuda}"
    use_pydantic_parser: True